{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Final Project: 2021년 국립국어원 인공지능 언어능력 평가\n",
    "\n",
    "- [2021년 국립국어원 인공지능 언어능력 평가](https://corpus.korean.go.kr/task/taskList.do?taskId=1&clCd=END_TASK&subMenuId=sub01) 는 9월 1일부터 시작하여 11월 1일까지 마감된 [네 가지 과제에](https://corpus.korean.go.kr/task/taskDownload.do?taskId=1&clCd=END_TASK&subMenuId=sub02) 대한 언어능력 평가 대회\n",
    "- 여기서 제시된 과제를 그대로 수행하여 그 결과를 [최종 선정된 결과들](https://corpus.korean.go.kr/task/taskLeaderBoard.do?taskId=4&clCd=END_TASK&subMenuId=sub04)과 비교할 수 있도록 수행\n",
    "- 아직 테스트 셋의 정답이 공식적으로 공개되고 있지 않아, 네 가지 과제의 자료에서 evaluation dataset으로 가지고 성능을 비교할 계획\n",
    "- 기말 발표전까지 정답셋이 공개될 경우 이 정답셋을 가지고 성능 검증\n",
    "- Transformers 기반 방법론, 신경망 등 각자 생각한 방법대로 구현 가능\n",
    "- 현재 대회기간이 종료되어 자료가 다운로드 가능하지 않으니 첨부된 자료 참조\n",
    "- 개인적으로 하거나 최대 두명까지 그룹 허용. \n",
    "- 이 노트북 화일에 이름을 변경하여 작업하고 제출. 제출시 화일명을 FinalProject_[DS또는 CL]_학과_이름.ipynb\n",
    "- 마감 12월 6일(월) 23:59분까지.\n",
    "- 12월 7일, 9일 기말 발표 presentation 예정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 리더보드\n",
    "\n",
    "- 최종발표전까지 각조는 각 태스크별 실행성능을 **시도된 여러 방법의 결과들을 지속적으로**  [리더보드](https://docs.google.com/spreadsheets/d/1-uenfp5GolpY2Gf0TsFbODvj585IIiFKp9fvYxcfgkY/edit#gid=0)에 해당 팀명(구성원 이름 포함)을 입력하여 공개하여야 함. \n",
    "- 최종 마감일에 이 순위와 실제 제출한 프로그램의 수행 결과를 비교하여 성능을 확인"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BoolQ (판정 의문문, 정현진)"
   ],
   "metadata": {
    "id": "xYqodz4fUN51"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "outputs": [],
   "metadata": {
    "id": "7p1jid9et6-h"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ],
   "outputs": [],
   "metadata": {
    "id": "xXZuZLUDt7XP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xxQkaZIop9_",
    "outputId": "d8fd62b2-7252-45c7-895f-89913eca65e7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cur_path = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/\""
   ],
   "outputs": [],
   "metadata": {
    "id": "ARcVg_T5ET9Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Requirement"
   ],
   "metadata": {
    "id": "Iu0hfU4fpLQB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!pip install transformers\n",
    "!pip install wandb\n",
    "!pip install pytorch-lightning\n",
    "!pip install tqdm\n",
    "!pip install sentencepiece"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 60.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 63.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 71.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 677 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 87.0 MB/s \n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 91.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 8.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Building wheels for collected packages: subprocess32, pathtools\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=382e1145c76714ff75a74c0cbbcd3b5e6ebf4998cffce5e8220d984c44690f0f\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=9218ce46ad45d1a574026585f360c22cd9bb442e0e93da6af12982fda4134cf6\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built subprocess32 pathtools\n",
      "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.7 yaspin-2.1.0\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.5.5-py3-none-any.whl (525 kB)\n",
      "\u001b[K     |████████████████████████████████| 525 kB 4.0 MB/s \n",
      "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.6.1-py3-none-any.whl (332 kB)\n",
      "\u001b[K     |████████████████████████████████| 332 kB 70.6 MB/s \n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 72.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 55.7 MB/s \n",
      "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 64.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.42.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 80.0 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 82.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.8)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 99.2 MB/s \n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=d4b7f3e6e7c2caffcc1d8801f90a6ad7338bc77b5355882c2da741137f36c1e0\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, pyDeprecate, future, pytorch-lightning\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.5 torchmetrics-0.6.1 yarl-1.7.2\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjYaot57jdNQ",
    "outputId": "9c4acbfc-1fb8-4c14-c81b-590d84b83cc0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import packages"
   ],
   "metadata": {
    "id": "SFNdyYaLpPhS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {
    "id": "Coc0NRzFQ3aF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuration"
   ],
   "metadata": {
    "id": "zLOfhdZUpikO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class config():\n",
    "  \"\"\" Here type your configurations! \"\"\"\n",
    "  # paths\n",
    "  train_path = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/SKT_BoolQ_Train.tsv\"\n",
    "  dev_path = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/SKT_BoolQ_Dev.tsv\"\n",
    "  test_path = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/SKT_BoolQ_Test.tsv\"\n",
    "  cur_path = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/\"\n",
    "  train_dev_crop = False\n",
    "\n",
    "  # model\n",
    "  model_list = {\n",
    "      'roberta': \"klue/roberta-large\",\n",
    "      'bigbird': \"monologg/kobigbird-bert-base\",\n",
    "      'electra': 'monologg/koelectra-base-v3-discriminator',\n",
    "      'albert': \"kykim/albert-kor-base\"\n",
    "  }\n",
    "\n",
    "  num_classes = 2\n",
    "\n",
    "  # dataset\n",
    "  k_fold = 5\n",
    "  batch_size = 8\n",
    "  inf_batch_size = 2\n",
    "\n",
    "  # optimizer, schedular\n",
    "  learning_rate = 8e-6\n",
    "  weight_decay = 0.01\n",
    "  warmup_steps = 500\n",
    "\n",
    "  # Save\n",
    "  log_interval = 20\n",
    "  mode_wandb = True\n",
    "  save_dir = \"/content/drive/MyDrive/New Colab Notebooks/NLP/BoolQ/result/\"\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "LSpfbqTOp1l5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "id": "rpVbp8Dqp3tk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BoolQ_Dataset(Dataset):\n",
    "  def __init__(self, config, training=True):\n",
    "    \"\"\" Configuration \"\"\" \n",
    "    self.config = config\n",
    "\n",
    "    if training: # for K folding\n",
    "      self.dataset = self.load_data(config.train_path)\n",
    "    else: # test data\n",
    "      self.dataset = self.load_data(config.dev_path)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    ## Return text and label\n",
    "    return {\n",
    "        \"text\": self.pre_process(self.dataset[\"text\"].values[idx]), \n",
    "        \"question\": self.pre_process(self.dataset[\"question\"].values[idx]), \n",
    "        \"label\": self.dataset[\"label\"].values[idx]\n",
    "    }\n",
    "\n",
    "\n",
    "  def load_data(self, dataset_dir):\n",
    "    dataset = pd.read_csv(dataset_dir, delimiter='\\t', names=['ID', 'text', 'question', 'answer'], header=0)\n",
    "    dataset[\"label\"] = dataset[\"answer\"].astype(int)\n",
    "    dataset['text'] = dataset['text'].apply(self.pre_process)\n",
    "    return dataset\n",
    "\n",
    "  def pre_process(self, st):\n",
    "    st = re.sub('\\(.*\\)|\\s-\\s.*', '', st)\n",
    "    st = re.sub('\\[.*\\]|\\s-\\s.*', '', st)\n",
    "    st = st.lower()\n",
    "\n",
    "    st = re.sub('[”“]', '\\\"', st)\n",
    "    st = re.sub('[’‘]', '\\'', st)\n",
    "    st = re.sub('[≫〉》＞』」]', '>', st)\n",
    "    st = re.sub('[《「『〈≪＜]','<',st)\n",
    "    st = re.sub('[−–—]', '−', st)\n",
    "    st = re.sub('[･•・‧]','·', st)\n",
    "    st = re.sub('<', '', st)\n",
    "    st = re.sub('>', '', st)\n",
    "    st = re.sub('·', ', ', st)\n",
    "    st = st.replace('／', '/')\n",
    "    st = st.replace('℃', '도')\n",
    "    st = st.replace('→', '에서')\n",
    "    st = st.replace('!', '')\n",
    "    st = st.replace('，', ',')\n",
    "    st = st.replace('㎢', 'km')\n",
    "    st = st.replace('∼', '~')\n",
    "    st = st.replace('㎜', 'mm')\n",
    "    st = st.replace('×', '곱하기')\n",
    "    st = st.replace('=', '는')\n",
    "    st = st.replace('®', '')\n",
    "    st = st.replace('㎖', 'ml')\n",
    "    st = st.replace('ℓ', 'l')\n",
    "    st = st.replace('˚C', '도')\n",
    "    st = st.replace('˚', '도')\n",
    "    st = st.replace('°C', '도')\n",
    "    st = st.replace('°', '도')\n",
    "    st = st.replace('＋', '+')\n",
    "    st = st.replace('*', '')\n",
    "    st = st.replace(';', '.')\n",
    "    return st\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "id": "priphVDhp5ZJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {
    "id": "vMs_RsrR4yxu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from transformers import (\n",
    "    BigBirdModel,\n",
    "    BigBirdPreTrainedModel, \n",
    "    ElectraModel, \n",
    "    ElectraPreTrainedModel, \n",
    "    XLMRobertaModel, \n",
    "    BartModel, \n",
    "    BartPretrainedModel, \n",
    "    T5Model, \n",
    "    RobertaModel,\n",
    "    AlbertModel\n",
    ")\n",
    "\n",
    "\"\"\" KoBigBird Pre-trained Model \"\"\"\n",
    "\n",
    "class BigBird_BoolQ(BigBirdPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bigbird = BigBirdModel.from_pretrained(\n",
    "            \"monologg/kobigbird-bert-base\",\n",
    "            config=config\n",
    "        )  # Load pretrained bigbird\n",
    "        \n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1)\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bigbird(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        \n",
    "        pooled_output = outputs[0][:,0,:] #cls\n",
    "        \n",
    "\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "\n",
    "        # Concat -> fc_layer\n",
    "        logits = self.qa_classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" KoElectra Pre-trained Model \"\"\"\n",
    "\n",
    "class Electra_BoolQ(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        #self.num_labels = config.num_labels\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = ElectraModel.from_pretrained(\n",
    "            'monologg/koelectra-base-v3-discriminator', config=config)\n",
    "        self.pooling = PoolingHead(input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1)\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0][:,0,:] #cls\n",
    "        sequence_output = self.pooling(sequence_output)\n",
    "        logits = self.qa_classifier(sequence_output)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Roberta Pre-trained Model \"\"\"\n",
    "\n",
    "class Roberta_BoolQ(RobertaModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.roberta = RobertaModel.from_pretrained(\"klue/roberta-large\", config=config)  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1)\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        # pooled_output_cat = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "        \n",
    "        logits = self.qa_classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Roberta Ensemble Model \"\"\"\n",
    "\n",
    "class Roberta_ensemble_BoolQ(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.roberta_f = RobertaModel.from_pretrained(\"klue/roberta-large\", config=config)  # Input: [Question - Answering]\n",
    "    self.roberta_b = RobertaModel.from_pretrained(\"klue/roberta-large\", config=config)  # Input: [Answering - Question]\n",
    "\n",
    "    self.num_labels = config.num_labels\n",
    "\n",
    "    self.pooling_f = PoolingHead(input_dim=config.hidden_size,\n",
    "        inner_dim=config.hidden_size,\n",
    "        pooler_dropout=0.1)\n",
    "    self.pooling_b = PoolingHead(input_dim=config.hidden_size,\n",
    "        inner_dim=config.hidden_size,\n",
    "        pooler_dropout=0.1)\n",
    "    \n",
    "    self.qa_classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "\n",
    "\n",
    "  def forward(self, input_forward_dict, input_reverse_dict):\n",
    "    \"\"\"\n",
    "    ? input\n",
    "    - input_forward_dict : {input_ids, token_type_ids, attention_mask} \n",
    "      Input token has sequence of (question - answering)\n",
    "    - input_reverse_dict : {input_ids, token_type_ids, attention_mask}\n",
    "      Input token has sequence of (question - answering)\n",
    "    \"\"\"\n",
    "    outputs = self.roberta(\n",
    "        input_forward_dict['input_ids'], attention_mask=input_forward_dict['attention_mask']\n",
    "    )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "    pooled_output_1 = outputs[0][:, 0, :]  # [CLS]\n",
    "\n",
    "    outputs = self.roberta(\n",
    "        input_forward_dict['input_ids'], attention_mask=input_forward_dict['attention_mask']\n",
    "    )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "    pooled_output_2 = outputs[0][:, 0, :]  # [CLS]\n",
    "\n",
    "\n",
    "\n",
    "    pooled_output_1 = self.pooling_f(pooled_output_1)\n",
    "    pooled_output_2 = self.pooling_f(pooled_output_2)\n",
    "    pooled_output_cat = torch.cat([pooled_output_1, pooled_output_2], dim=1)\n",
    "    \n",
    "    logits = self.qa_classifier(pooled_output_cat)\n",
    "\n",
    "    outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "    return outputs  # logits, (hidden_states), (attentions)        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Albert Model\"\"\"\n",
    "\n",
    "class Albert_BoolQ(AlbertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.albert = AlbertModel.from_pretrained(\"kykim/albert-kor-base\", config=config)  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1)\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.albert(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        # pooled_output_cat = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "        \n",
    "        logits = self.qa_classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Additional Layers \"\"\"\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class PoolingHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        inner_dim: int,\n",
    "        pooler_dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, inner_dim)\n",
    "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = torch.tanh(hidden_states)\n",
    "        return hidden_states\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "RZtHIWPU4ybn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Center"
   ],
   "metadata": {
    "id": "MfYWAZVo2ag3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, BertTokenizerFast\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# https://visionhong.tistory.com/30\n",
    "# Here is the code for pl.\n",
    "\n",
    "class BoolQ_Model_Train():\n",
    "  def __init__(self, config, model_name):\n",
    "    super().__init__()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    self.device = device\n",
    "    self.config = config\n",
    "\n",
    "    #####################\n",
    "    ### Configuration ###\n",
    "    #####################\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "\n",
    "    assert model_name in config.model_list.keys(), \"[Training] Please Give Correct Model Name which have been listed.\"\n",
    "    self.model_name = model_name\n",
    "\n",
    "    # load configuration of pretrained model\n",
    "    MODEL_CONFIG = AutoConfig.from_pretrained(config.model_list[model_name])\n",
    "    MODEL_CONFIG.num_labels = 2\n",
    "\n",
    "    if model_name == \"roberta\":\n",
    "      self.model = Roberta_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"bigbird\":\n",
    "      self.model = BigBird_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"electra\":\n",
    "      self.model = Electra_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"albert\":\n",
    "      self.model = Albert_BoolQ(MODEL_CONFIG)\n",
    "\n",
    "    self.model.to(device)\n",
    "\n",
    "\n",
    "    \"\"\" Tokenizer \"\"\"\n",
    "    if model_name == 'albert':\n",
    "      self.tokenizer = BertTokenizerFast.from_pretrained(config.model_list[model_name])\n",
    "    else:\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(config.model_list[model_name])\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "\n",
    "    # train_dataset\n",
    "    self.train_dataset = BoolQ_Dataset(config)\n",
    "\n",
    "    # k_fold index\n",
    "    skf_iris = StratifiedKFold(n_splits=config.k_fold)\n",
    "    self.kfold = config.k_fold\n",
    "    self.KFold_index = list(skf_iris.split(\n",
    "        self.train_dataset.dataset['text'], self.train_dataset.dataset['label']))\n",
    "    \n",
    "    # batch_size\n",
    "    self.batch_size = config.batch_size\n",
    "\n",
    "\n",
    "    \"\"\" optimizer, scheduler (in fit() function), criterion \"\"\"\n",
    "\n",
    "    self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.learning_rate)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    \"\"\" Training Saving \"\"\"\n",
    "\n",
    "    self.log_interval = config.log_interval\n",
    "    self.load_step = 0\n",
    "    self.best_acc = 0\n",
    "    self.wandb = config.mode_wandb\n",
    "    self.save_dir = config.save_dir\n",
    "\n",
    "\n",
    "\n",
    "  def fit(self, epoch):\n",
    "    # schedular\n",
    "    self.scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "      self.optimizer, \n",
    "      num_warmup_steps=config.warmup_steps, \n",
    "      num_training_steps=len(self.train_dataset) * epoch, \n",
    "      last_epoch= -1\n",
    "    )\n",
    "\n",
    "    \n",
    "    \"\"\" GO TRAINING. \"\"\"\n",
    "    self.epoch = epoch\n",
    "\n",
    "    for epo in tqdm(range(epoch), position=0):\n",
    "      ### Stratified KFold\n",
    "      train_idx, val_idx = self.KFold_index[epo % self.kfold]\n",
    "\n",
    "      training_set = Subset(self.train_dataset, train_idx)\n",
    "      validation_set = Subset(self.train_dataset, val_idx)\n",
    "\n",
    "      ### make dataloader\n",
    "      train_loader = DataLoader(training_set, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "      val_loader = DataLoader(validation_set, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "      ### train\n",
    "      self.training_step(train_loader, epo)\n",
    "\n",
    "      ### val\n",
    "      self.validation_step(val_loader, epo)\n",
    "\n",
    "      ### Best model save\n",
    "      if self.best_acc < self.val_acc:\n",
    "        self.best_acc = self.val_acc\n",
    "\n",
    "        print(\"Best Model Saving!\")\n",
    "        print(f\"Current Best Accuracy: {self.best_acc}\")\n",
    "\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(f\"{self.save_dir}/best/{self.model_name}\")\n",
    "        torch.save(self.config, os.path.join(f\"{self.save_dir}/best/{self.model_name}\", \"training_config.bin\"))\n",
    "\n",
    "\n",
    "      \n",
    "      \n",
    "\n",
    "  def training_step(self, train_loader, epo):\n",
    "    # allocate model to train mode\n",
    "    self.model.train()\n",
    "    tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar = tqdm(total = len(train_loader), desc=\"[Training] Epoch {}\".format(epo+1), position=1)\n",
    "\n",
    "    for texts, labels in train_loader:\n",
    "      ### allocate to cuda or not.\n",
    "      # texts -> cpu tensor, labels -> array.\n",
    "      # texts: {input_ids, token_type_ids, attention_mask}\n",
    "      texts = {key: torch.tensor(value).to(self.device) for key, value in texts.items()}\n",
    "      labels = torch.tensor(labels).to(self.device)\n",
    "\n",
    "      ###########################################\n",
    "      # 1) zero_grad\n",
    "      self.optimizer.zero_grad()\n",
    "\n",
    "      # 2) forward\n",
    "      y_pred = self.model(**texts)[0]\n",
    "\n",
    "      # 3) calculate loss\n",
    "      loss = self.criterion(y_pred, labels)\n",
    "\n",
    "      # 4) backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5) optimier step\n",
    "      self.optimizer.step()\n",
    "\n",
    "      # 6) scheduler step\n",
    "      self.scheduler.step()\n",
    "\n",
    "      ###########################################\n",
    "\n",
    "\n",
    "      ### update, and cumulate match and loss\n",
    "      pbar.update()\n",
    "      self.load_step += 1\n",
    "\n",
    "      preds = torch.argmax(y_pred, dim=-1)\n",
    "      tot_loss += loss.item()\n",
    "      tot_acc += (preds == labels).sum().item() / self.batch_size\n",
    "\n",
    "      ### saving to log\n",
    "      if self.load_step % self.log_interval == 0:\n",
    "        train_loss = tot_loss / self.log_interval\n",
    "        train_acc = tot_acc / self.log_interval\n",
    "        current_lr = self.get_lr(self.optimizer)\n",
    "\n",
    "        pbar.set_description(f\"Epoch: [{epo}/{self.epoch}] || loss: {train_loss:4.4} || acc: {train_acc:4.2%} || lr {current_lr:4.4}\")\n",
    "\n",
    "        self.train_loss = train_loss\n",
    "        self.train_acc = train_acc\n",
    "        self.current_lr = current_lr\n",
    "\n",
    "        tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "\n",
    "  def validation_step(self, val_loader, epo):\n",
    "    # allocate model to eval mode\n",
    "    self.model.eval()\n",
    "    tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar = tqdm(total = len(val_loader), desc=\"[Validation] Epoch {}\".format(epo+1), position=1)\n",
    "    with torch.no_grad():\n",
    "      for texts, labels in val_loader:\n",
    "        ### allocate to cuda or not.\n",
    "        # texts -> cpu tensor, labels -> array.\n",
    "        # texts: {input_ids, token_type_ids, attention_mask}\n",
    "        texts = {key: torch.tensor(value).to(self.device) for key, value in texts.items()}\n",
    "        labels = torch.tensor(labels).to(self.device)\n",
    "\n",
    "        ###########################################\n",
    "        # 1) forward\n",
    "        y_pred = self.model(**texts)[0]\n",
    "\n",
    "        # 2) calculate loss\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "\n",
    "        ###########################################\n",
    "        \"\"\" Update and save loss \"\"\"\n",
    "\n",
    "        pbar.update()\n",
    "    \n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        tot_loss += loss.item()\n",
    "        tot_acc += (preds == labels).sum().item() / self.batch_size\n",
    "\n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    val_loss = tot_loss / len(val_loader)\n",
    "    val_acc = tot_acc / len(val_loader)\n",
    "\n",
    "    pbar.set_description(f\"Validation: [{epo}/{self.epoch}] || loss: {val_loss:4.4} || acc: {val_acc:4.2%}\")\n",
    "    pbar.close()\n",
    "\n",
    "    if self.wandb:\n",
    "        wandb.log({\"train_loss\": self.train_loss, \"train_acc\": self.train_acc,\n",
    "            \"lr\":self.current_lr, \"valid_loss\":val_loss, \"valid_acc\":val_acc\n",
    "        })\n",
    "\n",
    "    self.val_acc = val_acc\n",
    "\n",
    "\n",
    "\n",
    "  def collate_fn(self, batch):\n",
    "    \"\"\"\n",
    "      Collate a batch of dataset to same length of text.\n",
    "\n",
    "    ? INPUT\n",
    "    dataset: {text: string, question: string, label: int}\n",
    "\n",
    "    ? OUTPUT\n",
    "    padded token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # integrate from dataset (dict) into list\n",
    "    text_list = [b['text'] for b in batch]\n",
    "    query_list = [b['question'] for b in batch]\n",
    "    label_list = [b['label'] for b in batch]\n",
    "    \n",
    "    # tokenize\n",
    "    text_query_list = list(zip(text_list, query_list))\n",
    "\n",
    "    if self.model_name == 'bigbird':\n",
    "      max_length = 1024\n",
    "    else:\n",
    "      max_length = 512\n",
    "\n",
    "    tokenized_sentence = self.tokenizer(\n",
    "        text_query_list,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = False\n",
    "    )\n",
    "\n",
    "    # output of tokenized_sentence: {input_ids, token_type_ids, attention_mask}\n",
    "    return tokenized_sentence, label_list\n",
    "\n",
    "  def get_lr(self, optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "      return param_group['lr']\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "5301TGQkqSdC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class Inference():\n",
    "  def __init__(self, config, model_name, ensemble=False):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    self.device = device\n",
    "    self.config = config\n",
    "\n",
    "    #####################\n",
    "    ### Configuration ###\n",
    "    #####################\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "\n",
    "    assert model_name in config.model_list.keys(), \"[Inference] Please Give Correct Model Name which have been listed.\"\n",
    "    self.model_name = model_name\n",
    "\n",
    "    # load configuration of pretrained model\n",
    "    MODEL_CONFIG = AutoConfig.from_pretrained(config.model_list[model_name])\n",
    "    MODEL_CONFIG.num_labels = 2\n",
    "\n",
    "    save_model_path = os.path.join(config.cur_path, 'result/best', model_name)\n",
    "    if model_name == \"roberta\":\n",
    "      self.model = Roberta_BoolQ.from_pretrained(save_model_path, config=MODEL_CONFIG)\n",
    "    elif model_name == \"bigbird\":\n",
    "      self.model = BigBird_BoolQ.from_pretrained(save_model_path, config=MODEL_CONFIG)\n",
    "    elif model_name == \"electra\":\n",
    "      self.model = Electra_BoolQ.from_pretrained(save_model_path, config=MODEL_CONFIG)\n",
    "    elif model_name == \"albert\":\n",
    "      self.model = Albert_BoolQ.from_pretrained(save_model_path, config=MODEL_CONFIG)\n",
    "\n",
    "    self.model.to(device)\n",
    "    self.model.eval()\n",
    "\n",
    "    \"\"\" Tokenizer \"\"\"\n",
    "\n",
    "    if model_name == 'albert':\n",
    "      self.tokenizer = BertTokenizerFast.from_pretrained(config.model_list[model_name])\n",
    "    else:\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(config.model_list[model_name])\n",
    "\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "\n",
    "    # train_dataset\n",
    "    self.test_dataset = BoolQ_Dataset(config, False)\n",
    "    \n",
    "    # batch_size\n",
    "    self.batch_size = config.inf_batch_size\n",
    "\n",
    "\n",
    "\n",
    "  def inference(self):\n",
    "    ### test dataloader\n",
    "    test_loader = DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        collate_fn = self.collate_fn\n",
    "    )\n",
    "\n",
    "    # get accuracy.\n",
    "    tot_acc = 0.\n",
    "    with torch.no_grad():\n",
    "      pbar = tqdm(total = len(test_loader), desc = \"Inference\")\n",
    "      for texts, labels in test_loader:\n",
    "        texts = {key: torch.tensor(value).to(self.device) for key, value in texts.items()}\n",
    "        labels = torch.tensor(labels).to(self.device)\n",
    "\n",
    "        y_pred = self.model(**texts)[0]\n",
    "\n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        tot_acc += (preds == labels).sum().item() / self.batch_size\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "    tot_acc /= len(test_loader)\n",
    "    print(f\"Test Accuracy is {tot_acc:4.2%}. Congrats!\")\n",
    "      \n",
    "\n",
    "  def collate_fn(self, batch):\n",
    "    \"\"\"\n",
    "      Collate a batch of dataset to same length of text.\n",
    "\n",
    "    ? INPUT\n",
    "    dataset: {text: string, question: string, label: int}\n",
    "\n",
    "    ? OUTPUT\n",
    "    padded token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # integrate from dataset (dict) into list\n",
    "    text_list = [b['text'] for b in batch]\n",
    "    query_list = [b['question'] for b in batch]\n",
    "    label_list = [b['label'] for b in batch]\n",
    "    \n",
    "    # tokenize\n",
    "    text_query_list = list(zip(text_list, query_list))\n",
    "\n",
    "    if self.model_name == 'bigbird':\n",
    "      max_length = 1024\n",
    "    else:\n",
    "      max_length = 512\n",
    "\n",
    "    tokenized_sentence = self.tokenizer(\n",
    "        text_query_list,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = False\n",
    "    )\n",
    "\n",
    "    # output of tokenized_sentence: {input_ids, token_type_ids, attention_mask}\n",
    "    return tokenized_sentence, label_list\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "QCrB8CW8KAth"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result!!"
   ],
   "metadata": {
    "id": "oeryF4_DWeZc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Bigbird!"
   ],
   "metadata": {
    "id": "frRq0bcoV2cn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'bigbird'\n",
    "\n",
    "if config.mode_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project='HyunJin-BoolQ', name=f\"hello_{model_name}\")\n",
    "\n",
    "Trainer = BoolQ_Model_Train(config, model_name)\n",
    "Trainer.fit(epoch = 30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Finishing last run (ID:3sfxb9gk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 970... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54946c2456d9451e8b394f6d3bcb43d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁██████▇▇▇</td></tr><tr><td>train_acc</td><td>▁▂▄▆▆▇▇███</td></tr><tr><td>train_loss</td><td>██▇▄▅▂▂▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▂▄▆▇▇████</td></tr><tr><td>valid_loss</td><td>██▆▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_acc</td><td>0.96875</td></tr><tr><td>train_loss</td><td>0.11205</td></tr><tr><td>valid_acc</td><td>0.99049</td></tr><tr><td>valid_loss</td><td>0.02583</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hello_bigbird</strong>: <a href=\"https://wandb.ai/jesper_jung/HyunJin-BoolQ/runs/3sfxb9gk\" target=\"_blank\">https://wandb.ai/jesper_jung/HyunJin-BoolQ/runs/3sfxb9gk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211208_094258-3sfxb9gk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3sfxb9gk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jesper_jung/HyunJin-BoolQ/runs/3prw1998\" target=\"_blank\">hello_bigbird</a></strong> to <a href=\"https://wandb.ai/jesper_jung/HyunJin-BoolQ\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "[Training] Epoch 1:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[AAttention type 'block_sparse' is not possible if sequence_length: 143 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "\n",
      "[Training] Epoch 1:   0%|          | 1/367 [00:00<02:32,  2.39it/s]\u001b[A\n",
      "[Training] Epoch 1:   1%|          | 2/367 [00:00<01:41,  3.60it/s]\u001b[A\n",
      "[Training] Epoch 1:   1%|          | 3/367 [00:00<01:20,  4.54it/s]\u001b[A\n",
      "[Training] Epoch 1:   1%|          | 4/367 [00:00<01:11,  5.04it/s]\u001b[A\n",
      "[Training] Epoch 1:   1%|▏         | 5/367 [00:01<01:11,  5.05it/s]\u001b[A\n",
      "[Training] Epoch 1:   2%|▏         | 6/367 [00:01<01:06,  5.45it/s]\u001b[A\n",
      "[Training] Epoch 1:   2%|▏         | 7/367 [00:01<01:01,  5.83it/s]\u001b[A\n",
      "[Training] Epoch 1:   2%|▏         | 8/367 [00:01<01:05,  5.45it/s]\u001b[A\n",
      "[Training] Epoch 1:   2%|▏         | 9/367 [00:01<01:00,  5.89it/s]\u001b[A\n",
      "[Training] Epoch 1:   3%|▎         | 10/367 [00:01<01:07,  5.27it/s]\u001b[A\n",
      "[Training] Epoch 1:   3%|▎         | 11/367 [00:02<01:02,  5.74it/s]\u001b[A\n",
      "[Training] Epoch 1:   3%|▎         | 12/367 [00:02<01:05,  5.38it/s]\u001b[A\n",
      "[Training] Epoch 1:   4%|▎         | 13/367 [00:02<01:07,  5.23it/s]\u001b[A\n",
      "[Training] Epoch 1:   4%|▍         | 14/367 [00:02<01:04,  5.46it/s]\u001b[A\n",
      "[Training] Epoch 1:   4%|▍         | 15/367 [00:02<01:03,  5.54it/s]\u001b[A\n",
      "[Training] Epoch 1:   4%|▍         | 16/367 [00:03<01:04,  5.41it/s]\u001b[A\n",
      "[Training] Epoch 1:   5%|▍         | 17/367 [00:03<00:59,  5.88it/s]\u001b[A\n",
      "[Training] Epoch 1:   5%|▍         | 18/367 [00:03<00:59,  5.87it/s]\u001b[A\n",
      "[Training] Epoch 1:   5%|▌         | 19/367 [00:03<00:57,  6.09it/s]\u001b[A\n",
      "[Training] Epoch 1:   5%|▌         | 20/367 [00:03<00:58,  5.90it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   5%|▌         | 20/367 [00:03<00:58,  5.90it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   6%|▌         | 21/367 [00:03<01:01,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   6%|▌         | 22/367 [00:04<01:04,  5.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   6%|▋         | 23/367 [00:04<00:58,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   7%|▋         | 24/367 [00:04<00:57,  5.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   7%|▋         | 25/367 [00:04<01:01,  5.54it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   7%|▋         | 26/367 [00:04<00:58,  5.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   7%|▋         | 27/367 [00:04<00:59,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   8%|▊         | 28/367 [00:05<00:56,  5.98it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   8%|▊         | 29/367 [00:05<00:54,  6.20it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   8%|▊         | 30/367 [00:05<00:55,  6.03it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   8%|▊         | 31/367 [00:05<00:57,  5.85it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   9%|▊         | 32/367 [00:05<00:59,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   9%|▉         | 33/367 [00:05<00:56,  5.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:   9%|▉         | 34/367 [00:06<01:01,  5.44it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  10%|▉         | 35/367 [00:06<00:56,  5.85it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  10%|▉         | 36/367 [00:06<00:58,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  10%|█         | 37/367 [00:06<00:56,  5.89it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  10%|█         | 38/367 [00:06<00:53,  6.10it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  11%|█         | 39/367 [00:06<00:55,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6938 || acc: 51.25% || lr 3.2e-07:  11%|█         | 40/367 [00:07<00:52,  6.21it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  11%|█         | 40/367 [00:07<00:52,  6.21it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  11%|█         | 41/367 [00:07<00:52,  6.23it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  11%|█▏        | 42/367 [00:07<00:53,  6.02it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  12%|█▏        | 43/367 [00:07<00:54,  5.94it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  12%|█▏        | 44/367 [00:07<00:56,  5.71it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  12%|█▏        | 45/367 [00:08<00:55,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  13%|█▎        | 46/367 [00:08<00:53,  6.05it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  13%|█▎        | 47/367 [00:08<00:53,  6.03it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  13%|█▎        | 48/367 [00:08<00:50,  6.26it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  13%|█▎        | 49/367 [00:08<00:54,  5.80it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  14%|█▎        | 50/367 [00:08<00:58,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  14%|█▍        | 51/367 [00:09<00:57,  5.45it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  14%|█▍        | 52/367 [00:09<01:00,  5.20it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  14%|█▍        | 53/367 [00:09<01:02,  5.01it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  15%|█▍        | 54/367 [00:09<01:00,  5.21it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  15%|█▍        | 55/367 [00:09<00:59,  5.23it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  15%|█▌        | 56/367 [00:10<00:57,  5.43it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  16%|█▌        | 57/367 [00:10<00:52,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  16%|█▌        | 58/367 [00:10<00:49,  6.26it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  16%|█▌        | 59/367 [00:10<00:50,  6.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7002 || acc: 50.62% || lr 6.4e-07:  16%|█▋        | 60/367 [00:10<00:56,  5.48it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  16%|█▋        | 60/367 [00:10<00:56,  5.48it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  17%|█▋        | 61/367 [00:10<00:53,  5.73it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  17%|█▋        | 62/367 [00:11<00:53,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  17%|█▋        | 63/367 [00:11<00:51,  5.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  17%|█▋        | 64/367 [00:11<00:55,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  18%|█▊        | 65/367 [00:11<00:53,  5.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  18%|█▊        | 66/367 [00:11<00:54,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  18%|█▊        | 67/367 [00:11<00:53,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  19%|█▊        | 68/367 [00:12<00:52,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  19%|█▉        | 69/367 [00:12<00:51,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  19%|█▉        | 70/367 [00:12<00:48,  6.10it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  19%|█▉        | 71/367 [00:12<00:47,  6.28it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  20%|█▉        | 72/367 [00:12<00:48,  6.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  20%|█▉        | 73/367 [00:12<00:46,  6.39it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  20%|██        | 74/367 [00:13<00:49,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  20%|██        | 75/367 [00:13<00:46,  6.33it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  21%|██        | 76/367 [00:13<00:47,  6.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  21%|██        | 77/367 [00:13<00:51,  5.60it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  21%|██▏       | 78/367 [00:13<00:50,  5.67it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  22%|██▏       | 79/367 [00:13<00:52,  5.43it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7039 || acc: 51.25% || lr 9.6e-07:  22%|██▏       | 80/367 [00:14<00:53,  5.38it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  22%|██▏       | 80/367 [00:14<00:53,  5.38it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  22%|██▏       | 81/367 [00:14<00:53,  5.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  22%|██▏       | 82/367 [00:14<00:51,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  23%|██▎       | 83/367 [00:14<00:50,  5.58it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  23%|██▎       | 84/367 [00:14<00:50,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  23%|██▎       | 85/367 [00:15<00:51,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  23%|██▎       | 86/367 [00:15<00:50,  5.57it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  24%|██▎       | 87/367 [00:15<00:51,  5.46it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  24%|██▍       | 88/367 [00:15<00:50,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  24%|██▍       | 89/367 [00:15<00:50,  5.49it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  25%|██▍       | 90/367 [00:15<00:50,  5.53it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  25%|██▍       | 91/367 [00:16<00:46,  5.93it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  25%|██▌       | 92/367 [00:16<00:48,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.68it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  26%|██▌       | 94/367 [00:16<00:47,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  26%|██▌       | 95/367 [00:16<00:49,  5.47it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  26%|██▌       | 96/367 [00:17<00:48,  5.57it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  26%|██▋       | 97/367 [00:17<00:47,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  27%|██▋       | 98/367 [00:17<00:46,  5.75it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  27%|██▋       | 99/367 [00:17<00:49,  5.44it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6957 || acc: 51.88% || lr 1.28e-06:  27%|██▋       | 100/367 [00:17<00:49,  5.43it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  27%|██▋       | 100/367 [00:17<00:49,  5.43it/s] \u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  28%|██▊       | 101/367 [00:17<00:46,  5.70it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  28%|██▊       | 102/367 [00:18<00:50,  5.29it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  28%|██▊       | 103/367 [00:18<00:48,  5.42it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  28%|██▊       | 104/367 [00:18<00:48,  5.46it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  29%|██▊       | 105/367 [00:18<00:48,  5.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  29%|██▉       | 106/367 [00:18<00:46,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  29%|██▉       | 107/367 [00:19<00:47,  5.45it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  29%|██▉       | 108/367 [00:19<00:46,  5.51it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  30%|██▉       | 109/367 [00:19<00:44,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  30%|██▉       | 110/367 [00:19<00:41,  6.16it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  30%|███       | 111/367 [00:19<00:41,  6.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  31%|███       | 112/367 [00:19<00:43,  5.83it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  31%|███       | 113/367 [00:19<00:41,  6.07it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  31%|███       | 114/367 [00:20<00:44,  5.72it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  31%|███▏      | 115/367 [00:20<00:43,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  32%|███▏      | 116/367 [00:20<00:47,  5.24it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  32%|███▏      | 117/367 [00:20<00:44,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  32%|███▏      | 118/367 [00:20<00:43,  5.68it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  32%|███▏      | 119/367 [00:21<00:44,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7041 || acc: 45.00% || lr 1.6e-06:  33%|███▎      | 120/367 [00:21<00:45,  5.49it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  33%|███▎      | 120/367 [00:21<00:45,  5.49it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  33%|███▎      | 121/367 [00:21<00:47,  5.15it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  33%|███▎      | 122/367 [00:21<00:47,  5.19it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  34%|███▎      | 123/367 [00:21<00:43,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  34%|███▍      | 124/367 [00:22<00:43,  5.57it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  34%|███▍      | 125/367 [00:22<00:44,  5.46it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  34%|███▍      | 126/367 [00:22<00:42,  5.73it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  35%|███▍      | 127/367 [00:22<00:39,  6.10it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  35%|███▍      | 128/367 [00:22<00:39,  6.07it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  35%|███▌      | 129/367 [00:22<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  35%|███▌      | 130/367 [00:23<00:38,  6.11it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  36%|███▌      | 131/367 [00:23<00:41,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  36%|███▌      | 132/367 [00:23<00:41,  5.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  36%|███▌      | 133/367 [00:23<00:43,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  37%|███▋      | 134/367 [00:23<00:42,  5.53it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  37%|███▋      | 135/367 [00:23<00:41,  5.60it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  37%|███▋      | 136/367 [00:24<00:40,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  37%|███▋      | 137/367 [00:24<00:39,  5.79it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  38%|███▊      | 138/367 [00:24<00:41,  5.58it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  38%|███▊      | 139/367 [00:24<00:38,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7044 || acc: 41.25% || lr 1.92e-06:  38%|███▊      | 140/367 [00:24<00:39,  5.77it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  38%|███▊      | 140/367 [00:24<00:39,  5.77it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  38%|███▊      | 141/367 [00:24<00:37,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  39%|███▊      | 142/367 [00:25<00:38,  5.88it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  39%|███▉      | 143/367 [00:25<00:39,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  39%|███▉      | 144/367 [00:25<00:40,  5.51it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  40%|███▉      | 145/367 [00:25<00:38,  5.77it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  40%|███▉      | 146/367 [00:25<00:37,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  40%|████      | 147/367 [00:26<00:40,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  40%|████      | 148/367 [00:26<00:39,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  41%|████      | 149/367 [00:26<00:41,  5.22it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  41%|████      | 150/367 [00:26<00:40,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  41%|████      | 151/367 [00:26<00:38,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  41%|████▏     | 152/367 [00:26<00:39,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  42%|████▏     | 153/367 [00:27<00:39,  5.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  42%|████▏     | 154/367 [00:27<00:40,  5.32it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  42%|████▏     | 155/367 [00:27<00:36,  5.78it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  43%|████▎     | 156/367 [00:27<00:34,  6.05it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  43%|████▎     | 157/367 [00:27<00:33,  6.34it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  43%|████▎     | 158/367 [00:27<00:31,  6.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  43%|████▎     | 159/367 [00:28<00:30,  6.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6993 || acc: 49.38% || lr 2.24e-06:  44%|████▎     | 160/367 [00:28<00:31,  6.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  44%|████▎     | 160/367 [00:28<00:31,  6.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  44%|████▍     | 161/367 [00:28<00:32,  6.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  44%|████▍     | 162/367 [00:28<00:35,  5.80it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  44%|████▍     | 163/367 [00:28<00:35,  5.68it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  45%|████▍     | 164/367 [00:28<00:35,  5.68it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  45%|████▍     | 165/367 [00:29<00:33,  5.95it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  45%|████▌     | 166/367 [00:29<00:35,  5.63it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  46%|████▌     | 167/367 [00:29<00:35,  5.60it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  46%|████▌     | 168/367 [00:29<00:36,  5.46it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  46%|████▌     | 169/367 [00:29<00:35,  5.51it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  46%|████▋     | 170/367 [00:30<00:35,  5.57it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  47%|████▋     | 171/367 [00:30<00:32,  5.95it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  47%|████▋     | 172/367 [00:30<00:33,  5.89it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  47%|████▋     | 173/367 [00:30<00:32,  5.88it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  47%|████▋     | 174/367 [00:30<00:33,  5.72it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  48%|████▊     | 175/367 [00:30<00:36,  5.33it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  48%|████▊     | 176/367 [00:31<00:33,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  48%|████▊     | 177/367 [00:31<00:35,  5.32it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  49%|████▊     | 178/367 [00:31<00:37,  5.08it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  49%|████▉     | 179/367 [00:31<00:36,  5.19it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6923 || acc: 53.75% || lr 2.56e-06:  49%|████▉     | 180/367 [00:31<00:35,  5.20it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  49%|████▉     | 180/367 [00:31<00:35,  5.20it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  49%|████▉     | 181/367 [00:32<00:33,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  50%|████▉     | 182/367 [00:32<00:32,  5.67it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  50%|████▉     | 183/367 [00:32<00:33,  5.52it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  50%|█████     | 184/367 [00:32<00:33,  5.52it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  50%|█████     | 185/367 [00:32<00:33,  5.47it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  51%|█████     | 186/367 [00:32<00:32,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  51%|█████     | 187/367 [00:33<00:31,  5.73it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  51%|█████     | 188/367 [00:33<00:31,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  51%|█████▏    | 189/367 [00:33<00:34,  5.20it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  52%|█████▏    | 190/367 [00:33<00:34,  5.11it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  52%|█████▏    | 191/367 [00:33<00:35,  5.03it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  52%|█████▏    | 192/367 [00:34<00:33,  5.27it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  53%|█████▎    | 193/367 [00:34<00:30,  5.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  53%|█████▎    | 194/367 [00:34<00:32,  5.37it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  53%|█████▎    | 195/367 [00:34<00:27,  6.17it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  53%|█████▎    | 196/367 [00:34<00:29,  5.71it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  54%|█████▎    | 197/367 [00:34<00:29,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  54%|█████▍    | 198/367 [00:35<00:29,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  54%|█████▍    | 199/367 [00:35<00:29,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6951 || acc: 48.75% || lr 2.88e-06:  54%|█████▍    | 200/367 [00:35<00:28,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  54%|█████▍    | 200/367 [00:35<00:28,  5.76it/s] \u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  55%|█████▍    | 201/367 [00:35<00:30,  5.37it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  55%|█████▌    | 202/367 [00:35<00:30,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  55%|█████▌    | 203/367 [00:35<00:28,  5.73it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  56%|█████▌    | 204/367 [00:36<00:28,  5.75it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  56%|█████▌    | 205/367 [00:36<00:28,  5.72it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  56%|█████▌    | 206/367 [00:36<00:27,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  56%|█████▋    | 207/367 [00:36<00:27,  5.91it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  57%|█████▋    | 208/367 [00:36<00:26,  5.89it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  57%|█████▋    | 209/367 [00:37<00:26,  5.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  57%|█████▋    | 210/367 [00:37<00:26,  5.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  57%|█████▋    | 211/367 [00:37<00:27,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  58%|█████▊    | 212/367 [00:37<00:31,  4.89it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  58%|█████▊    | 213/367 [00:37<00:29,  5.15it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  58%|█████▊    | 214/367 [00:37<00:29,  5.21it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  59%|█████▊    | 215/367 [00:38<00:28,  5.39it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  59%|█████▉    | 216/367 [00:38<00:30,  4.99it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  59%|█████▉    | 217/367 [00:38<00:30,  4.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  59%|█████▉    | 218/367 [00:38<00:28,  5.18it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  60%|█████▉    | 219/367 [00:38<00:29,  5.06it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7065 || acc: 41.88% || lr 3.2e-06:  60%|█████▉    | 220/367 [00:39<00:29,  4.91it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  60%|█████▉    | 220/367 [00:39<00:29,  4.91it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  60%|██████    | 221/367 [00:39<00:28,  5.16it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  60%|██████    | 222/367 [00:39<00:26,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  61%|██████    | 223/367 [00:39<00:24,  5.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  61%|██████    | 224/367 [00:39<00:25,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  61%|██████▏   | 225/367 [00:40<00:25,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  62%|██████▏   | 226/367 [00:40<00:24,  5.87it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  62%|██████▏   | 227/367 [00:40<00:24,  5.70it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  62%|██████▏   | 228/367 [00:40<00:25,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  62%|██████▏   | 229/367 [00:40<00:23,  5.78it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  63%|██████▎   | 230/367 [00:40<00:23,  5.77it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  63%|██████▎   | 231/367 [00:41<00:22,  6.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  63%|██████▎   | 232/367 [00:41<00:23,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  63%|██████▎   | 233/367 [00:41<00:25,  5.29it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  64%|██████▍   | 234/367 [00:41<00:24,  5.35it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  64%|██████▍   | 235/367 [00:41<00:22,  5.80it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  64%|██████▍   | 236/367 [00:41<00:22,  5.72it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  65%|██████▍   | 237/367 [00:42<00:20,  6.25it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  65%|██████▍   | 238/367 [00:42<00:20,  6.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  65%|██████▌   | 239/367 [00:42<00:21,  5.99it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.7062 || acc: 42.50% || lr 3.52e-06:  65%|██████▌   | 240/367 [00:42<00:21,  5.80it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  65%|██████▌   | 240/367 [00:42<00:21,  5.80it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  66%|██████▌   | 241/367 [00:42<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  66%|██████▌   | 242/367 [00:42<00:22,  5.67it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  66%|██████▌   | 243/367 [00:43<00:21,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  66%|██████▋   | 244/367 [00:43<00:23,  5.27it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  67%|██████▋   | 245/367 [00:43<00:22,  5.39it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  67%|██████▋   | 246/367 [00:43<00:21,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  67%|██████▋   | 247/367 [00:43<00:21,  5.69it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  68%|██████▊   | 248/367 [00:44<00:19,  5.97it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  68%|██████▊   | 249/367 [00:44<00:19,  6.02it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  68%|██████▊   | 250/367 [00:44<00:20,  5.78it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  68%|██████▊   | 251/367 [00:44<00:22,  5.25it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  69%|██████▊   | 252/367 [00:44<00:21,  5.37it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  69%|██████▉   | 253/367 [00:44<00:19,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  69%|██████▉   | 254/367 [00:45<00:20,  5.63it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  69%|██████▉   | 255/367 [00:45<00:20,  5.35it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  70%|██████▉   | 256/367 [00:45<00:19,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  70%|███████   | 257/367 [00:45<00:17,  6.23it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  70%|███████   | 258/367 [00:45<00:18,  6.02it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  71%|███████   | 259/367 [00:45<00:18,  5.96it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6927 || acc: 52.50% || lr 3.84e-06:  71%|███████   | 260/367 [00:46<00:20,  5.31it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  71%|███████   | 260/367 [00:46<00:20,  5.31it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  71%|███████   | 261/367 [00:46<00:20,  5.25it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  71%|███████▏  | 262/367 [00:46<00:18,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  72%|███████▏  | 263/367 [00:46<00:18,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  72%|███████▏  | 265/367 [00:47<00:17,  5.69it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.60it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.64it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  73%|███████▎  | 269/367 [00:47<00:16,  5.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  74%|███████▎  | 270/367 [00:47<00:16,  5.88it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  74%|███████▍  | 271/367 [00:48<00:16,  5.93it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  74%|███████▍  | 272/367 [00:48<00:15,  6.11it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  74%|███████▍  | 273/367 [00:48<00:16,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  75%|███████▍  | 274/367 [00:48<00:15,  6.03it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  75%|███████▍  | 275/367 [00:48<00:15,  6.01it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  75%|███████▌  | 276/367 [00:48<00:16,  5.49it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  75%|███████▌  | 277/367 [00:49<00:17,  5.18it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.31it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  76%|███████▌  | 279/367 [00:49<00:17,  5.17it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6965 || acc: 50.00% || lr 4.16e-06:  76%|███████▋  | 280/367 [00:49<00:15,  5.53it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  76%|███████▋  | 280/367 [00:49<00:15,  5.53it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  77%|███████▋  | 281/367 [00:49<00:15,  5.45it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  77%|███████▋  | 282/367 [00:50<00:15,  5.48it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  77%|███████▋  | 284/367 [00:50<00:13,  6.10it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  78%|███████▊  | 285/367 [00:50<00:13,  6.28it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  78%|███████▊  | 286/367 [00:50<00:14,  5.61it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  78%|███████▊  | 287/367 [00:50<00:13,  5.91it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  78%|███████▊  | 288/367 [00:51<00:13,  5.95it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  79%|███████▊  | 289/367 [00:51<00:12,  6.26it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  79%|███████▉  | 290/367 [00:51<00:12,  6.16it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  79%|███████▉  | 291/367 [00:51<00:13,  5.47it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  80%|███████▉  | 292/367 [00:51<00:12,  5.86it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  80%|███████▉  | 293/367 [00:51<00:12,  5.87it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  80%|████████  | 294/367 [00:52<00:12,  5.92it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  80%|████████  | 295/367 [00:52<00:11,  6.15it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  81%|████████  | 296/367 [00:52<00:12,  5.87it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  81%|████████  | 297/367 [00:52<00:12,  5.55it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  81%|████████  | 298/367 [00:52<00:13,  5.28it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  81%|████████▏ | 299/367 [00:53<00:13,  5.08it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6962 || acc: 47.50% || lr 4.48e-06:  82%|████████▏ | 300/367 [00:53<00:13,  5.12it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  82%|████████▏ | 300/367 [00:53<00:13,  5.12it/s] \u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.32it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  82%|████████▏ | 302/367 [00:53<00:12,  5.11it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  83%|████████▎ | 303/367 [00:53<00:12,  5.13it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  83%|████████▎ | 304/367 [00:53<00:11,  5.35it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.33it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.78it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  84%|████████▎ | 307/367 [00:54<00:11,  5.43it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  84%|████████▍ | 308/367 [00:54<00:11,  5.14it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  84%|████████▍ | 309/367 [00:54<00:10,  5.40it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.52it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.83it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  85%|████████▌ | 312/367 [00:55<00:10,  5.42it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  85%|████████▌ | 313/367 [00:55<00:10,  5.00it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  86%|████████▌ | 314/367 [00:55<00:10,  5.23it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.31it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.12it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  86%|████████▋ | 317/367 [00:56<00:09,  5.25it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  87%|████████▋ | 318/367 [00:56<00:09,  5.40it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  87%|████████▋ | 319/367 [00:56<00:08,  5.59it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6958 || acc: 48.75% || lr 4.8e-06:  87%|████████▋ | 320/367 [00:56<00:08,  5.35it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  87%|████████▋ | 320/367 [00:56<00:08,  5.35it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  87%|████████▋ | 321/367 [00:57<00:09,  5.10it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.41it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  88%|████████▊ | 323/367 [00:57<00:07,  5.58it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  88%|████████▊ | 324/367 [00:57<00:07,  5.66it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  89%|████████▊ | 325/367 [00:57<00:08,  5.14it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.39it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.51it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  89%|████████▉ | 328/367 [00:58<00:06,  5.75it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  90%|████████▉ | 329/367 [00:58<00:06,  6.05it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.60it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.51it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  90%|█████████ | 332/367 [00:59<00:07,  4.95it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.19it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.07it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.81it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  92%|█████████▏| 337/367 [01:00<00:04,  6.00it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  92%|█████████▏| 338/367 [01:00<00:05,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  92%|█████████▏| 339/367 [01:00<00:04,  6.36it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.00% || lr 5.12e-06:  93%|█████████▎| 340/367 [01:00<00:04,  6.26it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  93%|█████████▎| 340/367 [01:00<00:04,  6.26it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  93%|█████████▎| 341/367 [01:00<00:04,  6.02it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  93%|█████████▎| 342/367 [01:00<00:04,  6.22it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.69it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  94%|█████████▍| 345/367 [01:01<00:03,  5.62it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.56it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.65it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  95%|█████████▍| 348/367 [01:01<00:03,  5.50it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.53it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.18it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.76it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  96%|█████████▌| 352/367 [01:02<00:02,  6.01it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.75it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  96%|█████████▋| 354/367 [01:02<00:02,  6.12it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  97%|█████████▋| 355/367 [01:03<00:01,  6.08it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  97%|█████████▋| 356/367 [01:03<00:01,  6.30it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.67it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.88it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  98%|█████████▊| 359/367 [01:03<00:01,  5.70it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6924 || acc: 50.62% || lr 5.44e-06:  98%|█████████▊| 360/367 [01:03<00:01,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  98%|█████████▊| 360/367 [01:03<00:01,  5.82it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.40it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.74it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.67it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06:  99%|█████████▉| 365/367 [01:04<00:00,  5.93it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06: 100%|█████████▉| 366/367 [01:05<00:00,  5.84it/s]\u001b[A\n",
      "Epoch: [0/30] || loss: 0.6882 || acc: 55.00% || lr 5.76e-06: 100%|██████████| 367/367 [01:05<00:00,  5.63it/s]\n",
      "\n",
      "[Validation] Epoch 1:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 1:   3%|▎         | 3/92 [00:00<00:03, 22.73it/s]\u001b[A\n",
      "[Validation] Epoch 1:   7%|▋         | 6/92 [00:00<00:04, 18.96it/s]\u001b[A\n",
      "[Validation] Epoch 1:   9%|▊         | 8/92 [00:00<00:04, 18.71it/s]\u001b[A\n",
      "[Validation] Epoch 1:  11%|█         | 10/92 [00:00<00:04, 18.39it/s]\u001b[A\n",
      "[Validation] Epoch 1:  14%|█▍        | 13/92 [00:00<00:04, 18.74it/s]\u001b[A\n",
      "[Validation] Epoch 1:  17%|█▋        | 16/92 [00:00<00:03, 19.82it/s]\u001b[A\n",
      "[Validation] Epoch 1:  20%|█▉        | 18/92 [00:00<00:03, 19.61it/s]\u001b[A\n",
      "[Validation] Epoch 1:  23%|██▎       | 21/92 [00:01<00:03, 19.75it/s]\u001b[A\n",
      "[Validation] Epoch 1:  25%|██▌       | 23/92 [00:01<00:03, 19.68it/s]\u001b[A\n",
      "[Validation] Epoch 1:  27%|██▋       | 25/92 [00:01<00:03, 18.66it/s]\u001b[A\n",
      "[Validation] Epoch 1:  30%|███       | 28/92 [00:01<00:03, 18.99it/s]\u001b[A\n",
      "[Validation] Epoch 1:  33%|███▎      | 30/92 [00:01<00:03, 18.94it/s]\u001b[A\n",
      "[Validation] Epoch 1:  36%|███▌      | 33/92 [00:01<00:03, 19.01it/s]\u001b[A\n",
      "[Validation] Epoch 1:  39%|███▉      | 36/92 [00:01<00:02, 19.93it/s]\u001b[A\n",
      "[Validation] Epoch 1:  41%|████▏     | 38/92 [00:01<00:02, 19.23it/s]\u001b[A\n",
      "[Validation] Epoch 1:  45%|████▍     | 41/92 [00:02<00:02, 20.21it/s]\u001b[A\n",
      "[Validation] Epoch 1:  48%|████▊     | 44/92 [00:02<00:02, 19.92it/s]\u001b[A\n",
      "[Validation] Epoch 1:  50%|█████     | 46/92 [00:02<00:02, 19.53it/s]\u001b[A\n",
      "[Validation] Epoch 1:  52%|█████▏    | 48/92 [00:02<00:02, 19.36it/s]\u001b[A\n",
      "[Validation] Epoch 1:  54%|█████▍    | 50/92 [00:02<00:02, 18.56it/s]\u001b[A\n",
      "[Validation] Epoch 1:  57%|█████▋    | 52/92 [00:02<00:02, 18.68it/s]\u001b[A\n",
      "[Validation] Epoch 1:  59%|█████▊    | 54/92 [00:02<00:02, 18.40it/s]\u001b[A\n",
      "[Validation] Epoch 1:  62%|██████▏   | 57/92 [00:02<00:01, 18.79it/s]\u001b[A\n",
      "[Validation] Epoch 1:  64%|██████▍   | 59/92 [00:03<00:01, 18.39it/s]\u001b[A\n",
      "[Validation] Epoch 1:  66%|██████▋   | 61/92 [00:03<00:01, 18.23it/s]\u001b[A\n",
      "[Validation] Epoch 1:  70%|██████▉   | 64/92 [00:03<00:01, 18.78it/s]\u001b[A\n",
      "[Validation] Epoch 1:  72%|███████▏  | 66/92 [00:03<00:01, 18.41it/s]\u001b[A\n",
      "[Validation] Epoch 1:  74%|███████▍  | 68/92 [00:03<00:01, 17.72it/s]\u001b[A\n",
      "[Validation] Epoch 1:  76%|███████▌  | 70/92 [00:03<00:01, 17.71it/s]\u001b[A\n",
      "[Validation] Epoch 1:  79%|███████▉  | 73/92 [00:03<00:00, 19.02it/s]\u001b[A\n",
      "[Validation] Epoch 1:  82%|████████▏ | 75/92 [00:03<00:00, 18.03it/s]\u001b[A\n",
      "[Validation] Epoch 1:  84%|████████▎ | 77/92 [00:04<00:00, 17.72it/s]\u001b[A\n",
      "[Validation] Epoch 1:  86%|████████▌ | 79/92 [00:04<00:00, 17.51it/s]\u001b[A\n",
      "[Validation] Epoch 1:  88%|████████▊ | 81/92 [00:04<00:00, 17.93it/s]\u001b[A\n",
      "[Validation] Epoch 1:  91%|█████████▏| 84/92 [00:04<00:00, 18.56it/s]\u001b[A\n",
      "[Validation] Epoch 1:  95%|█████████▍| 87/92 [00:04<00:00, 18.82it/s]\u001b[A\n",
      "[Validation] Epoch 1:  97%|█████████▋| 89/92 [00:04<00:00, 18.51it/s]\u001b[A\n",
      "[Validation] Epoch 1:  99%|█████████▉| 91/92 [00:04<00:00, 17.72it/s]\u001b[A\n",
      "Validation: [0/30] || loss: 0.6945 || acc: 51.22%: 100%|██████████| 92/92 [00:04<00:00, 18.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.5122282608695652\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 1/30 [01:11<34:43, 71.85s/it]\n",
      "[Training] Epoch 2:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 2:   0%|          | 1/367 [00:00<01:03,  5.72it/s]\u001b[A\n",
      "[Training] Epoch 2:   1%|          | 2/367 [00:00<01:07,  5.38it/s]\u001b[A\n",
      "[Training] Epoch 2:   1%|          | 3/367 [00:00<01:08,  5.31it/s]\u001b[A\n",
      "[Training] Epoch 2:   1%|          | 4/367 [00:00<01:10,  5.14it/s]\u001b[A\n",
      "[Training] Epoch 2:   1%|▏         | 5/367 [00:00<01:08,  5.31it/s]\u001b[A\n",
      "[Training] Epoch 2:   2%|▏         | 6/367 [00:01<01:06,  5.47it/s]\u001b[A\n",
      "[Training] Epoch 2:   2%|▏         | 7/367 [00:01<01:03,  5.64it/s]\u001b[A\n",
      "[Training] Epoch 2:   2%|▏         | 8/367 [00:01<01:02,  5.72it/s]\u001b[A\n",
      "[Training] Epoch 2:   2%|▏         | 9/367 [00:01<01:03,  5.67it/s]\u001b[A\n",
      "[Training] Epoch 2:   3%|▎         | 10/367 [00:01<01:05,  5.43it/s]\u001b[A\n",
      "[Training] Epoch 2:   3%|▎         | 11/367 [00:02<01:07,  5.29it/s]\u001b[A\n",
      "[Training] Epoch 2:   3%|▎         | 12/367 [00:02<01:02,  5.67it/s]\u001b[A\n",
      "[Training] Epoch 2:   4%|▎         | 13/367 [00:02<00:59,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   4%|▎         | 13/367 [00:02<00:59,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   4%|▍         | 14/367 [00:02<01:05,  5.37it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   4%|▍         | 15/367 [00:02<01:03,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   4%|▍         | 16/367 [00:02<01:02,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   5%|▍         | 17/367 [00:03<01:01,  5.68it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   5%|▍         | 18/367 [00:03<01:04,  5.38it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   5%|▌         | 19/367 [00:03<01:03,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   5%|▌         | 20/367 [00:03<00:59,  5.79it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   6%|▌         | 21/367 [00:03<01:01,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   6%|▌         | 22/367 [00:03<01:01,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   6%|▋         | 23/367 [00:04<00:58,  5.91it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   7%|▋         | 24/367 [00:04<00:59,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   7%|▋         | 25/367 [00:04<01:04,  5.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   7%|▋         | 26/367 [00:04<01:05,  5.17it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   7%|▋         | 27/367 [00:04<01:00,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   8%|▊         | 28/367 [00:05<01:01,  5.55it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   8%|▊         | 29/367 [00:05<01:01,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   8%|▊         | 30/367 [00:05<01:00,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   8%|▊         | 31/367 [00:05<00:56,  5.92it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   9%|▊         | 32/367 [00:05<00:56,  5.91it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.4419 || acc: 36.88% || lr 6.08e-06:   9%|▉         | 33/367 [00:05<01:01,  5.42it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:   9%|▉         | 33/367 [00:05<01:01,  5.42it/s] \u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:   9%|▉         | 34/367 [00:06<00:59,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  10%|▉         | 35/367 [00:06<00:58,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  10%|▉         | 36/367 [00:06<00:59,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  10%|█         | 37/367 [00:06<00:55,  5.99it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  10%|█         | 38/367 [00:06<00:52,  6.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  11%|█         | 39/367 [00:06<00:51,  6.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  11%|█         | 40/367 [00:07<00:52,  6.17it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  11%|█         | 41/367 [00:07<00:54,  5.99it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  11%|█▏        | 42/367 [00:07<00:52,  6.14it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  12%|█▏        | 43/367 [00:07<00:52,  6.13it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  12%|█▏        | 44/367 [00:07<00:54,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  12%|█▏        | 45/367 [00:07<00:50,  6.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  13%|█▎        | 46/367 [00:08<00:54,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  13%|█▎        | 47/367 [00:08<00:53,  5.95it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  13%|█▎        | 48/367 [00:08<00:54,  5.85it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  13%|█▎        | 49/367 [00:08<00:53,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  14%|█▎        | 50/367 [00:08<00:54,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  14%|█▍        | 51/367 [00:08<00:59,  5.31it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  14%|█▍        | 52/367 [00:09<00:59,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6821 || acc: 55.00% || lr 6.4e-06:  14%|█▍        | 53/367 [00:09<00:59,  5.27it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  14%|█▍        | 53/367 [00:09<00:59,  5.27it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  15%|█▍        | 54/367 [00:09<00:58,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  15%|█▍        | 55/367 [00:09<00:55,  5.67it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  15%|█▌        | 56/367 [00:09<00:55,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  16%|█▌        | 57/367 [00:10<00:53,  5.80it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  16%|█▌        | 58/367 [00:10<00:55,  5.56it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  16%|█▌        | 59/367 [00:10<00:57,  5.36it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  16%|█▋        | 60/367 [00:10<00:59,  5.16it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  17%|█▋        | 61/367 [00:10<00:59,  5.13it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  17%|█▋        | 62/367 [00:11<00:57,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  17%|█▋        | 63/367 [00:11<00:57,  5.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  17%|█▋        | 64/367 [00:11<00:54,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  18%|█▊        | 65/367 [00:11<00:54,  5.55it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  18%|█▊        | 66/367 [00:11<00:54,  5.51it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  18%|█▊        | 67/367 [00:11<00:51,  5.83it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  19%|█▊        | 68/367 [00:12<00:50,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  19%|█▉        | 69/367 [00:12<00:51,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  19%|█▉        | 70/367 [00:12<00:50,  5.86it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  19%|█▉        | 71/367 [00:12<00:51,  5.70it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  20%|█▉        | 72/367 [00:12<00:54,  5.45it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6729 || acc: 59.38% || lr 6.72e-06:  20%|█▉        | 73/367 [00:12<00:54,  5.36it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  20%|█▉        | 73/367 [00:12<00:54,  5.36it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  20%|██        | 74/367 [00:13<00:53,  5.51it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  20%|██        | 75/367 [00:13<00:51,  5.62it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  21%|██        | 76/367 [00:13<00:51,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  21%|██        | 77/367 [00:13<00:52,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  21%|██▏       | 78/367 [00:13<00:51,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  22%|██▏       | 79/367 [00:14<00:50,  5.73it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  22%|██▏       | 80/367 [00:14<00:50,  5.72it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  22%|██▏       | 81/367 [00:14<00:49,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  22%|██▏       | 82/367 [00:14<00:53,  5.36it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  23%|██▎       | 83/367 [00:14<00:50,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  23%|██▎       | 84/367 [00:14<00:50,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  23%|██▎       | 85/367 [00:15<00:47,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  23%|██▎       | 86/367 [00:15<00:48,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  24%|██▎       | 87/367 [00:15<00:49,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  24%|██▍       | 88/367 [00:15<00:45,  6.11it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  24%|██▍       | 89/367 [00:15<00:44,  6.27it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  25%|██▍       | 90/367 [00:15<00:45,  6.04it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  25%|██▍       | 91/367 [00:16<00:47,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  25%|██▌       | 92/367 [00:16<00:48,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6816 || acc: 55.62% || lr 7.04e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  26%|██▌       | 94/367 [00:16<00:48,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  26%|██▌       | 95/367 [00:16<00:49,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  26%|██▌       | 96/367 [00:17<00:50,  5.38it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  26%|██▋       | 97/367 [00:17<00:48,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  27%|██▋       | 98/367 [00:17<00:48,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  27%|██▋       | 99/367 [00:17<00:47,  5.67it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  27%|██▋       | 100/367 [00:17<00:44,  5.94it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  28%|██▊       | 101/367 [00:17<00:46,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  28%|██▊       | 102/367 [00:18<00:47,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  28%|██▊       | 103/367 [00:18<00:47,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  28%|██▊       | 104/367 [00:18<00:49,  5.27it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  29%|██▊       | 105/367 [00:18<00:52,  5.03it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  29%|██▉       | 106/367 [00:18<00:48,  5.41it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  29%|██▉       | 107/367 [00:19<00:48,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  29%|██▉       | 108/367 [00:19<00:47,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  30%|██▉       | 109/367 [00:19<00:47,  5.39it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  30%|██▉       | 110/367 [00:19<00:45,  5.68it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  30%|███       | 111/367 [00:19<00:44,  5.76it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  31%|███       | 112/367 [00:19<00:44,  5.71it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6928 || acc: 56.25% || lr 7.36e-06:  31%|███       | 113/367 [00:20<00:45,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  31%|███       | 113/367 [00:20<00:45,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  31%|███       | 114/367 [00:20<00:45,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  31%|███▏      | 115/367 [00:20<00:43,  5.84it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  32%|███▏      | 116/367 [00:20<00:43,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  32%|███▏      | 117/367 [00:20<00:43,  5.69it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  32%|███▏      | 118/367 [00:20<00:47,  5.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  32%|███▏      | 119/367 [00:21<00:46,  5.32it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  33%|███▎      | 120/367 [00:21<00:49,  5.04it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  33%|███▎      | 121/367 [00:21<00:48,  5.10it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  33%|███▎      | 122/367 [00:21<00:45,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  34%|███▎      | 123/367 [00:21<00:42,  5.69it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  34%|███▍      | 124/367 [00:22<00:42,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  34%|███▍      | 125/367 [00:22<00:44,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  34%|███▍      | 126/367 [00:22<00:42,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  35%|███▍      | 127/367 [00:22<00:43,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  35%|███▍      | 128/367 [00:22<00:41,  5.83it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  35%|███▌      | 129/367 [00:22<00:39,  6.08it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  35%|███▌      | 130/367 [00:23<00:39,  6.03it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  36%|███▌      | 131/367 [00:23<00:40,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  36%|███▌      | 132/367 [00:23<00:40,  5.86it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6982 || acc: 55.00% || lr 7.68e-06:  36%|███▌      | 133/367 [00:23<00:39,  5.91it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  36%|███▌      | 133/367 [00:23<00:39,  5.91it/s]   \u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  37%|███▋      | 134/367 [00:23<00:43,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  37%|███▋      | 135/367 [00:24<00:45,  5.12it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  37%|███▋      | 136/367 [00:24<00:43,  5.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  37%|███▋      | 137/367 [00:24<00:43,  5.23it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  38%|███▊      | 138/367 [00:24<00:43,  5.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  38%|███▊      | 139/367 [00:24<00:45,  5.04it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  38%|███▊      | 140/367 [00:25<00:47,  4.79it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  38%|███▊      | 141/367 [00:25<00:46,  4.91it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  39%|███▊      | 142/367 [00:25<00:46,  4.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  39%|███▉      | 143/367 [00:25<00:45,  4.94it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  39%|███▉      | 144/367 [00:25<00:41,  5.38it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  40%|███▉      | 145/367 [00:25<00:40,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  40%|███▉      | 146/367 [00:26<00:39,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  40%|████      | 147/367 [00:26<00:41,  5.29it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  40%|████      | 148/367 [00:26<00:39,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  41%|████      | 149/367 [00:26<00:37,  5.89it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  41%|████      | 150/367 [00:26<00:38,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  41%|████      | 151/367 [00:27<00:38,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  41%|████▏     | 152/367 [00:27<00:38,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6886 || acc: 55.00% || lr 8e-06:  42%|████▏     | 153/367 [00:27<00:36,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  42%|████▏     | 153/367 [00:27<00:36,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  42%|████▏     | 154/367 [00:27<00:37,  5.71it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  42%|████▏     | 155/367 [00:27<00:39,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  43%|████▎     | 156/367 [00:27<00:39,  5.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  43%|████▎     | 157/367 [00:28<00:38,  5.39it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  43%|████▎     | 158/367 [00:28<00:38,  5.43it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  43%|████▎     | 159/367 [00:28<00:39,  5.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  44%|████▎     | 160/367 [00:28<00:40,  5.17it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  44%|████▍     | 161/367 [00:28<00:41,  4.95it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  44%|████▍     | 162/367 [00:29<00:40,  5.01it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  44%|████▍     | 163/367 [00:29<00:40,  5.06it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  45%|████▍     | 164/367 [00:29<00:38,  5.30it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  45%|████▍     | 165/367 [00:29<00:38,  5.31it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  45%|████▌     | 166/367 [00:29<00:36,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  46%|████▌     | 167/367 [00:30<00:35,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  46%|████▌     | 168/367 [00:30<00:36,  5.48it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  46%|████▌     | 169/367 [00:30<00:36,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  46%|████▋     | 170/367 [00:30<00:34,  5.77it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  47%|████▋     | 171/367 [00:30<00:36,  5.37it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  47%|████▋     | 172/367 [00:30<00:34,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6889 || acc: 47.50% || lr 7.999e-06:  47%|████▋     | 173/367 [00:31<00:34,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  47%|████▋     | 173/367 [00:31<00:34,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  47%|████▋     | 174/367 [00:31<00:33,  5.77it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  48%|████▊     | 175/367 [00:31<00:35,  5.39it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  48%|████▊     | 176/367 [00:31<00:34,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  48%|████▊     | 177/367 [00:31<00:32,  5.76it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  49%|████▊     | 178/367 [00:31<00:31,  5.94it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  49%|████▉     | 179/367 [00:32<00:35,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  49%|████▉     | 180/367 [00:32<00:34,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  49%|████▉     | 181/367 [00:32<00:32,  5.79it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  50%|████▉     | 182/367 [00:32<00:34,  5.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  50%|████▉     | 183/367 [00:32<00:31,  5.78it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  50%|█████     | 184/367 [00:33<00:31,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  50%|█████     | 185/367 [00:33<00:29,  6.22it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  51%|█████     | 186/367 [00:33<00:31,  5.69it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  51%|█████     | 187/367 [00:33<00:31,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  51%|█████     | 188/367 [00:33<00:30,  5.78it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  51%|█████▏    | 189/367 [00:33<00:29,  6.00it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  52%|█████▏    | 190/367 [00:34<00:29,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  52%|█████▏    | 191/367 [00:34<00:29,  5.92it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  52%|█████▏    | 192/367 [00:34<00:28,  6.25it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6918 || acc: 54.37% || lr 7.997e-06:  53%|█████▎    | 193/367 [00:34<00:29,  5.89it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  53%|█████▎    | 193/367 [00:34<00:29,  5.89it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  53%|█████▎    | 194/367 [00:34<00:29,  5.77it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  53%|█████▎    | 195/367 [00:34<00:29,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  53%|█████▎    | 196/367 [00:35<00:28,  6.04it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  54%|█████▎    | 197/367 [00:35<00:28,  5.93it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  54%|█████▍    | 198/367 [00:35<00:26,  6.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  54%|█████▍    | 199/367 [00:35<00:27,  6.03it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  54%|█████▍    | 200/367 [00:35<00:28,  5.96it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  55%|█████▍    | 201/367 [00:35<00:29,  5.71it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  55%|█████▌    | 202/367 [00:36<00:29,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  55%|█████▌    | 203/367 [00:36<00:28,  5.72it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  56%|█████▌    | 204/367 [00:36<00:27,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  56%|█████▌    | 205/367 [00:36<00:28,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  56%|█████▌    | 206/367 [00:36<00:26,  6.00it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  56%|█████▋    | 207/367 [00:36<00:26,  6.01it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  57%|█████▋    | 208/367 [00:37<00:25,  6.30it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  57%|█████▋    | 209/367 [00:37<00:26,  6.05it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  57%|█████▋    | 210/367 [00:37<00:27,  5.80it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  57%|█████▋    | 211/367 [00:37<00:26,  5.83it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  58%|█████▊    | 212/367 [00:37<00:27,  5.73it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6771 || acc: 55.00% || lr 7.996e-06:  58%|█████▊    | 213/367 [00:37<00:25,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  58%|█████▊    | 213/367 [00:37<00:25,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  58%|█████▊    | 214/367 [00:38<00:25,  6.09it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  59%|█████▊    | 215/367 [00:38<00:25,  5.98it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  59%|█████▉    | 216/367 [00:38<00:25,  5.86it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  59%|█████▉    | 217/367 [00:38<00:26,  5.67it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  59%|█████▉    | 218/367 [00:38<00:29,  5.13it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  60%|█████▉    | 219/367 [00:39<00:29,  5.01it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  60%|█████▉    | 220/367 [00:39<00:28,  5.23it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  60%|██████    | 221/367 [00:39<00:26,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  60%|██████    | 222/367 [00:39<00:27,  5.32it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  61%|██████    | 223/367 [00:39<00:25,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  61%|██████    | 224/367 [00:39<00:25,  5.51it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  61%|██████▏   | 225/367 [00:40<00:26,  5.45it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  62%|██████▏   | 226/367 [00:40<00:25,  5.53it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  62%|██████▏   | 227/367 [00:40<00:24,  5.69it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  62%|██████▏   | 228/367 [00:40<00:25,  5.46it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  62%|██████▏   | 229/367 [00:40<00:25,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  63%|██████▎   | 230/367 [00:41<00:25,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  63%|██████▎   | 231/367 [00:41<00:24,  5.56it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6945 || acc: 51.88% || lr 7.994e-06:  63%|██████▎   | 233/367 [00:41<00:23,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  63%|██████▎   | 233/367 [00:41<00:23,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  64%|██████▍   | 234/367 [00:41<00:23,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  64%|██████▍   | 235/367 [00:41<00:23,  5.71it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  64%|██████▍   | 236/367 [00:42<00:22,  5.78it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  65%|██████▍   | 237/367 [00:42<00:24,  5.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  65%|██████▍   | 238/367 [00:42<00:23,  5.44it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  65%|██████▌   | 239/367 [00:42<00:22,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  65%|██████▌   | 240/367 [00:42<00:22,  5.62it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  66%|██████▌   | 241/367 [00:43<00:21,  5.76it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  66%|██████▌   | 242/367 [00:43<00:21,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  66%|██████▌   | 243/367 [00:43<00:20,  6.01it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  66%|██████▋   | 244/367 [00:43<00:22,  5.57it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  67%|██████▋   | 245/367 [00:43<00:21,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  67%|██████▋   | 246/367 [00:43<00:22,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  67%|██████▋   | 247/367 [00:44<00:21,  5.65it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  68%|██████▊   | 248/367 [00:44<00:22,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  68%|██████▊   | 249/367 [00:44<00:20,  5.86it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.46it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  68%|██████▊   | 251/367 [00:44<00:22,  5.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  69%|██████▊   | 252/367 [00:45<00:21,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6946 || acc: 50.62% || lr 7.993e-06:  69%|██████▉   | 253/367 [00:45<00:21,  5.32it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  69%|██████▉   | 253/367 [00:45<00:21,  5.32it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  69%|██████▉   | 254/367 [00:45<00:20,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  69%|██████▉   | 255/367 [00:45<00:20,  5.43it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  70%|██████▉   | 256/367 [00:45<00:20,  5.51it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  70%|███████   | 257/367 [00:45<00:20,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  70%|███████   | 258/367 [00:46<00:20,  5.25it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  71%|███████   | 259/367 [00:46<00:20,  5.38it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  71%|███████   | 260/367 [00:46<00:20,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  71%|███████   | 261/367 [00:46<00:20,  5.19it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  71%|███████▏  | 262/367 [00:46<00:18,  5.57it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  72%|███████▏  | 263/367 [00:47<00:17,  5.85it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  72%|███████▏  | 264/367 [00:47<00:16,  6.07it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  72%|███████▏  | 265/367 [00:47<00:16,  6.00it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.72it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  73%|███████▎  | 267/367 [00:47<00:16,  5.97it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  73%|███████▎  | 268/367 [00:47<00:18,  5.35it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  73%|███████▎  | 269/367 [00:48<00:17,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  74%|███████▎  | 270/367 [00:48<00:17,  5.52it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  74%|███████▍  | 271/367 [00:48<00:18,  5.14it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  74%|███████▍  | 272/367 [00:48<00:18,  5.27it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6826 || acc: 53.12% || lr 7.991e-06:  74%|███████▍  | 273/367 [00:48<00:17,  5.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  74%|███████▍  | 273/367 [00:48<00:17,  5.34it/s] \u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  75%|███████▍  | 274/367 [00:49<00:17,  5.30it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  75%|███████▍  | 275/367 [00:49<00:17,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  75%|███████▌  | 276/367 [00:49<00:16,  5.41it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  76%|███████▌  | 278/367 [00:49<00:17,  5.13it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  76%|███████▌  | 279/367 [00:50<00:17,  5.05it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  76%|███████▋  | 280/367 [00:50<00:16,  5.12it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  77%|███████▋  | 281/367 [00:50<00:17,  5.00it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  77%|███████▋  | 282/367 [00:50<00:16,  5.15it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  77%|███████▋  | 283/367 [00:50<00:16,  5.17it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  77%|███████▋  | 284/367 [00:50<00:15,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  78%|███████▊  | 285/367 [00:51<00:14,  5.62it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  78%|███████▊  | 286/367 [00:51<00:13,  6.06it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  78%|███████▊  | 287/367 [00:51<00:13,  5.91it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  78%|███████▊  | 288/367 [00:51<00:13,  5.86it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.73it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  79%|███████▉  | 290/367 [00:51<00:13,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  79%|███████▉  | 291/367 [00:52<00:12,  6.00it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  80%|███████▉  | 292/367 [00:52<00:13,  5.74it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.7017 || acc: 55.00% || lr 7.99e-06:  80%|███████▉  | 293/367 [00:52<00:13,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  80%|███████▉  | 293/367 [00:52<00:13,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  80%|████████  | 294/367 [00:52<00:12,  5.67it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  80%|████████  | 295/367 [00:52<00:13,  5.50it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  81%|████████  | 296/367 [00:53<00:12,  5.78it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  81%|████████  | 297/367 [00:53<00:12,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  81%|████████  | 298/367 [00:53<00:11,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  81%|████████▏ | 299/367 [00:53<00:12,  5.51it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  82%|████████▏ | 300/367 [00:53<00:12,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.49it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  82%|████████▏ | 302/367 [00:54<00:11,  5.45it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  83%|████████▎ | 303/367 [00:54<00:12,  5.23it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  83%|████████▎ | 304/367 [00:54<00:11,  5.44it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.48it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.75it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  84%|████████▎ | 307/367 [00:55<00:10,  5.73it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  84%|████████▍ | 308/367 [00:55<00:10,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  84%|████████▍ | 309/367 [00:55<00:09,  6.32it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  84%|████████▍ | 310/367 [00:55<00:09,  5.80it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  85%|████████▍ | 311/367 [00:55<00:09,  6.03it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.96it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.685 || acc: 55.00% || lr 7.988e-06:  85%|████████▌ | 313/367 [00:56<00:09,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  85%|████████▌ | 313/367 [00:56<00:09,  5.82it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  86%|████████▌ | 314/367 [00:56<00:09,  5.81it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  86%|████████▌ | 315/367 [00:56<00:08,  6.04it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.58it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  86%|████████▋ | 317/367 [00:56<00:08,  5.68it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.90it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  87%|████████▋ | 319/367 [00:57<00:08,  5.72it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  87%|████████▋ | 320/367 [00:57<00:08,  5.80it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  87%|████████▋ | 321/367 [00:57<00:07,  6.12it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  88%|████████▊ | 322/367 [00:57<00:07,  5.79it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  88%|████████▊ | 323/367 [00:57<00:07,  5.80it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  88%|████████▊ | 324/367 [00:57<00:07,  6.08it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  89%|████████▊ | 325/367 [00:58<00:07,  5.54it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.18it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.40it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  89%|████████▉ | 328/367 [00:58<00:07,  5.12it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  90%|████████▉ | 329/367 [00:58<00:06,  5.48it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  90%|████████▉ | 330/367 [00:59<00:07,  5.20it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  90%|█████████ | 331/367 [00:59<00:06,  5.64it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.60it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6949 || acc: 50.62% || lr 7.987e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.33it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.61it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  92%|█████████▏| 336/367 [01:00<00:05,  5.30it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.79it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  92%|█████████▏| 338/367 [01:00<00:04,  6.01it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  92%|█████████▏| 339/367 [01:00<00:04,  5.66it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.98it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.89it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  93%|█████████▎| 342/367 [01:01<00:04,  6.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  93%|█████████▎| 343/367 [01:01<00:03,  6.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.70it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  94%|█████████▍| 345/367 [01:01<00:03,  5.59it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  94%|█████████▍| 346/367 [01:01<00:04,  5.16it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  95%|█████████▍| 347/367 [01:02<00:03,  5.31it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.37it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.47it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.28it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.38it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.46it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6709 || acc: 62.50% || lr 7.985e-06:  96%|█████████▌| 353/367 [01:03<00:02,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  96%|█████████▌| 353/367 [01:03<00:02,  5.63it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.48it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.87it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  97%|█████████▋| 356/367 [01:03<00:02,  5.34it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.08it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  98%|█████████▊| 358/367 [01:04<00:01,  5.09it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  98%|█████████▊| 359/367 [01:04<00:01,  4.70it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  98%|█████████▊| 360/367 [01:04<00:01,  4.71it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  98%|█████████▊| 361/367 [01:04<00:01,  4.94it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.02it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  99%|█████████▉| 363/367 [01:05<00:00,  5.57it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  99%|█████████▉| 364/367 [01:05<00:00,  5.26it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.21it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06: 100%|█████████▉| 366/367 [01:05<00:00,  5.56it/s]\u001b[A\n",
      "Epoch: [1/30] || loss: 0.6633 || acc: 63.75% || lr 7.984e-06: 100%|██████████| 367/367 [01:05<00:00,  5.58it/s]\n",
      "\n",
      "[Validation] Epoch 2:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 2:   3%|▎         | 3/92 [00:00<00:03, 23.60it/s]\u001b[A\n",
      "[Validation] Epoch 2:   7%|▋         | 6/92 [00:00<00:04, 20.12it/s]\u001b[A\n",
      "[Validation] Epoch 2:  10%|▉         | 9/92 [00:00<00:04, 19.17it/s]\u001b[A\n",
      "[Validation] Epoch 2:  12%|█▏        | 11/92 [00:00<00:04, 18.81it/s]\u001b[A\n",
      "[Validation] Epoch 2:  15%|█▌        | 14/92 [00:00<00:03, 20.02it/s]\u001b[A\n",
      "[Validation] Epoch 2:  18%|█▊        | 17/92 [00:00<00:03, 19.40it/s]\u001b[A\n",
      "[Validation] Epoch 2:  21%|██        | 19/92 [00:00<00:03, 18.69it/s]\u001b[A\n",
      "[Validation] Epoch 2:  23%|██▎       | 21/92 [00:01<00:03, 18.60it/s]\u001b[A\n",
      "[Validation] Epoch 2:  25%|██▌       | 23/92 [00:01<00:03, 18.84it/s]\u001b[A\n",
      "[Validation] Epoch 2:  27%|██▋       | 25/92 [00:01<00:03, 18.31it/s]\u001b[A\n",
      "[Validation] Epoch 2:  29%|██▉       | 27/92 [00:01<00:03, 18.34it/s]\u001b[A\n",
      "[Validation] Epoch 2:  33%|███▎      | 30/92 [00:01<00:03, 19.22it/s]\u001b[A\n",
      "[Validation] Epoch 2:  36%|███▌      | 33/92 [00:01<00:02, 20.50it/s]\u001b[A\n",
      "[Validation] Epoch 2:  39%|███▉      | 36/92 [00:01<00:02, 20.06it/s]\u001b[A\n",
      "[Validation] Epoch 2:  42%|████▏     | 39/92 [00:02<00:02, 19.74it/s]\u001b[A\n",
      "[Validation] Epoch 2:  45%|████▍     | 41/92 [00:02<00:02, 18.33it/s]\u001b[A\n",
      "[Validation] Epoch 2:  47%|████▋     | 43/92 [00:02<00:02, 18.41it/s]\u001b[A\n",
      "[Validation] Epoch 2:  49%|████▉     | 45/92 [00:02<00:02, 18.76it/s]\u001b[A\n",
      "[Validation] Epoch 2:  51%|█████     | 47/92 [00:02<00:02, 18.34it/s]\u001b[A\n",
      "[Validation] Epoch 2:  54%|█████▍    | 50/92 [00:02<00:02, 18.98it/s]\u001b[A\n",
      "[Validation] Epoch 2:  58%|█████▊    | 53/92 [00:02<00:02, 18.27it/s]\u001b[A\n",
      "[Validation] Epoch 2:  60%|█████▉    | 55/92 [00:02<00:02, 18.34it/s]\u001b[A\n",
      "[Validation] Epoch 2:  62%|██████▏   | 57/92 [00:03<00:01, 18.38it/s]\u001b[A\n",
      "[Validation] Epoch 2:  64%|██████▍   | 59/92 [00:03<00:01, 18.65it/s]\u001b[A\n",
      "[Validation] Epoch 2:  66%|██████▋   | 61/92 [00:03<00:01, 17.83it/s]\u001b[A\n",
      "[Validation] Epoch 2:  68%|██████▊   | 63/92 [00:03<00:01, 17.19it/s]\u001b[A\n",
      "[Validation] Epoch 2:  71%|███████   | 65/92 [00:03<00:01, 17.45it/s]\u001b[A\n",
      "[Validation] Epoch 2:  73%|███████▎  | 67/92 [00:03<00:01, 17.18it/s]\u001b[A\n",
      "[Validation] Epoch 2:  76%|███████▌  | 70/92 [00:03<00:01, 18.56it/s]\u001b[A\n",
      "[Validation] Epoch 2:  78%|███████▊  | 72/92 [00:03<00:01, 18.91it/s]\u001b[A\n",
      "[Validation] Epoch 2:  80%|████████  | 74/92 [00:03<00:00, 19.12it/s]\u001b[A\n",
      "[Validation] Epoch 2:  84%|████████▎ | 77/92 [00:04<00:00, 19.57it/s]\u001b[A\n",
      "[Validation] Epoch 2:  86%|████████▌ | 79/92 [00:04<00:00, 19.49it/s]\u001b[A\n",
      "[Validation] Epoch 2:  88%|████████▊ | 81/92 [00:04<00:00, 19.37it/s]\u001b[A\n",
      "[Validation] Epoch 2:  90%|█████████ | 83/92 [00:04<00:00, 18.80it/s]\u001b[A\n",
      "[Validation] Epoch 2:  92%|█████████▏| 85/92 [00:04<00:00, 17.02it/s]\u001b[A\n",
      "[Validation] Epoch 2:  95%|█████████▍| 87/92 [00:04<00:00, 16.63it/s]\u001b[A\n",
      "[Validation] Epoch 2:  97%|█████████▋| 89/92 [00:04<00:00, 16.18it/s]\u001b[A\n",
      "[Validation] Epoch 2:  99%|█████████▉| 91/92 [00:04<00:00, 16.86it/s]\u001b[A\n",
      "Validation: [1/30] || loss: 0.6768 || acc: 53.80%: 100%|██████████| 92/92 [00:04<00:00, 18.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.5380434782608695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  7%|▋         | 2/30 [02:25<33:55, 72.69s/it]\n",
      "[Training] Epoch 3:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 3:   0%|          | 1/367 [00:00<00:54,  6.76it/s]\u001b[A\n",
      "[Training] Epoch 3:   1%|          | 2/367 [00:00<00:58,  6.29it/s]\u001b[A\n",
      "[Training] Epoch 3:   1%|          | 3/367 [00:00<01:04,  5.66it/s]\u001b[A\n",
      "[Training] Epoch 3:   1%|          | 4/367 [00:00<01:04,  5.67it/s]\u001b[A\n",
      "[Training] Epoch 3:   1%|▏         | 5/367 [00:00<01:08,  5.25it/s]\u001b[A\n",
      "[Training] Epoch 3:   2%|▏         | 6/367 [00:01<01:03,  5.66it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   2%|▏         | 6/367 [00:01<01:03,  5.66it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   2%|▏         | 7/367 [00:01<01:03,  5.65it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   2%|▏         | 8/367 [00:01<01:06,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   2%|▏         | 9/367 [00:01<01:10,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   3%|▎         | 10/367 [00:01<01:03,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   3%|▎         | 11/367 [00:02<01:06,  5.32it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   3%|▎         | 12/367 [00:02<01:05,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   4%|▎         | 13/367 [00:02<01:05,  5.38it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   4%|▍         | 14/367 [00:02<01:04,  5.43it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   4%|▍         | 15/367 [00:02<01:01,  5.77it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   4%|▍         | 16/367 [00:02<01:00,  5.79it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   5%|▍         | 17/367 [00:03<00:58,  6.01it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   5%|▍         | 18/367 [00:03<00:59,  5.87it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   5%|▌         | 19/367 [00:03<00:59,  5.84it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   5%|▌         | 20/367 [00:03<00:57,  6.06it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   6%|▌         | 21/367 [00:03<00:55,  6.26it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   6%|▌         | 22/367 [00:03<00:58,  5.93it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   6%|▋         | 23/367 [00:04<00:54,  6.26it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   7%|▋         | 24/367 [00:04<00:56,  6.05it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   7%|▋         | 25/367 [00:04<00:56,  6.00it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.2036 || acc: 15.62% || lr 7.982e-06:   7%|▋         | 26/367 [00:04<01:02,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   7%|▋         | 26/367 [00:04<01:02,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   7%|▋         | 27/367 [00:04<01:01,  5.53it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   8%|▊         | 28/367 [00:04<01:00,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   8%|▊         | 29/367 [00:05<00:59,  5.71it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   8%|▊         | 30/367 [00:05<01:00,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   8%|▊         | 31/367 [00:05<00:59,  5.69it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   9%|▊         | 32/367 [00:05<00:59,  5.67it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   9%|▉         | 33/367 [00:05<00:58,  5.75it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:   9%|▉         | 34/367 [00:05<00:56,  5.86it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  10%|▉         | 35/367 [00:06<00:54,  6.08it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  10%|▉         | 36/367 [00:06<00:52,  6.31it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  10%|█         | 37/367 [00:06<00:57,  5.70it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  10%|█         | 38/367 [00:06<00:57,  5.70it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  11%|█         | 39/367 [00:06<00:56,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  11%|█         | 40/367 [00:07<01:02,  5.23it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  11%|█         | 41/367 [00:07<01:04,  5.08it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  11%|█▏        | 42/367 [00:07<01:00,  5.33it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  12%|█▏        | 43/367 [00:07<00:59,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  12%|█▏        | 44/367 [00:07<00:56,  5.68it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  12%|█▏        | 45/367 [00:07<01:02,  5.15it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6479 || acc: 62.50% || lr 7.981e-06:  13%|█▎        | 46/367 [00:08<00:59,  5.40it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  13%|█▎        | 46/367 [00:08<00:59,  5.40it/s] \u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  13%|█▎        | 47/367 [00:08<01:04,  4.99it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  13%|█▎        | 48/367 [00:08<00:59,  5.36it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  13%|█▎        | 49/367 [00:08<00:54,  5.83it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  14%|█▎        | 50/367 [00:08<00:55,  5.76it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  14%|█▍        | 51/367 [00:09<00:53,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  14%|█▍        | 52/367 [00:09<00:54,  5.79it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  14%|█▍        | 53/367 [00:09<00:59,  5.30it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  15%|█▍        | 54/367 [00:09<00:59,  5.30it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  15%|█▍        | 55/367 [00:09<00:54,  5.76it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  15%|█▌        | 56/367 [00:09<00:56,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  16%|█▌        | 57/367 [00:10<00:56,  5.52it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  16%|█▌        | 58/367 [00:10<00:54,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  16%|█▌        | 59/367 [00:10<00:57,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  16%|█▋        | 60/367 [00:10<00:56,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  17%|█▋        | 61/367 [00:10<00:57,  5.37it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  17%|█▋        | 62/367 [00:11<00:59,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  17%|█▋        | 63/367 [00:11<00:59,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  17%|█▋        | 64/367 [00:11<01:00,  5.03it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  18%|█▊        | 65/367 [00:11<00:56,  5.34it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6734 || acc: 53.75% || lr 7.98e-06:  18%|█▊        | 66/367 [00:11<00:55,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  18%|█▊        | 66/367 [00:11<00:55,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  18%|█▊        | 67/367 [00:12<00:58,  5.14it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  19%|█▊        | 68/367 [00:12<00:54,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  19%|█▉        | 69/367 [00:12<00:55,  5.42it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  19%|█▉        | 70/367 [00:12<00:54,  5.45it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  19%|█▉        | 71/367 [00:12<00:56,  5.21it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  20%|█▉        | 72/367 [00:12<00:52,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  20%|█▉        | 73/367 [00:13<00:50,  5.87it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  20%|██        | 74/367 [00:13<00:46,  6.34it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  20%|██        | 75/367 [00:13<00:48,  6.05it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  21%|██        | 76/367 [00:13<00:48,  6.06it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  21%|██        | 77/367 [00:13<00:52,  5.48it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  21%|██▏       | 78/367 [00:13<00:51,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  22%|██▏       | 79/367 [00:14<00:51,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  22%|██▏       | 80/367 [00:14<00:47,  6.05it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  22%|██▏       | 81/367 [00:14<00:45,  6.26it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  22%|██▏       | 82/367 [00:14<00:48,  5.92it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  23%|██▎       | 83/367 [00:14<00:53,  5.33it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  23%|██▎       | 84/367 [00:14<00:49,  5.67it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  23%|██▎       | 85/367 [00:15<00:51,  5.48it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6343 || acc: 65.00% || lr 7.978e-06:  23%|██▎       | 86/367 [00:15<00:51,  5.43it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  23%|██▎       | 86/367 [00:15<00:51,  5.43it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  24%|██▎       | 87/367 [00:15<00:51,  5.46it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  24%|██▍       | 88/367 [00:15<00:49,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  24%|██▍       | 89/367 [00:15<00:53,  5.23it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  25%|██▍       | 90/367 [00:16<00:51,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  25%|██▍       | 91/367 [00:16<00:51,  5.32it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  25%|██▌       | 92/367 [00:16<00:52,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  26%|██▌       | 94/367 [00:16<00:47,  5.75it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  26%|██▌       | 95/367 [00:16<00:45,  5.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  26%|██▌       | 96/367 [00:17<00:45,  5.92it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  26%|██▋       | 97/367 [00:17<00:43,  6.17it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  27%|██▋       | 98/367 [00:17<00:46,  5.81it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  27%|██▋       | 99/367 [00:17<00:45,  5.85it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  27%|██▋       | 100/367 [00:17<00:45,  5.82it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  28%|██▊       | 101/367 [00:18<00:46,  5.71it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  28%|██▊       | 102/367 [00:18<00:46,  5.67it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  28%|██▊       | 103/367 [00:18<00:51,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  28%|██▊       | 104/367 [00:18<00:49,  5.37it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  29%|██▊       | 105/367 [00:18<00:45,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6549 || acc: 61.25% || lr 7.977e-06:  29%|██▉       | 106/367 [00:18<00:43,  5.99it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  29%|██▉       | 106/367 [00:18<00:43,  5.99it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  29%|██▉       | 107/367 [00:19<00:45,  5.70it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  29%|██▉       | 108/367 [00:19<00:48,  5.32it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  30%|██▉       | 109/367 [00:19<00:48,  5.27it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  30%|██▉       | 110/367 [00:19<00:48,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  30%|███       | 111/367 [00:19<00:47,  5.40it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  31%|███       | 112/367 [00:20<00:46,  5.51it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  31%|███       | 113/367 [00:20<00:43,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  31%|███       | 114/367 [00:20<00:42,  6.02it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  31%|███▏      | 115/367 [00:20<00:44,  5.72it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  32%|███▏      | 116/367 [00:20<00:42,  5.90it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  32%|███▏      | 117/367 [00:20<00:42,  5.84it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  32%|███▏      | 118/367 [00:20<00:39,  6.23it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  32%|███▏      | 119/367 [00:21<00:42,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  33%|███▎      | 120/367 [00:21<00:38,  6.36it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  33%|███▎      | 121/367 [00:21<00:44,  5.54it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  33%|███▎      | 122/367 [00:21<00:46,  5.27it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  34%|███▎      | 123/367 [00:21<00:46,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  34%|███▍      | 124/367 [00:22<00:44,  5.49it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  34%|███▍      | 125/367 [00:22<00:41,  5.81it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6082 || acc: 65.62% || lr 7.975e-06:  34%|███▍      | 126/367 [00:22<00:41,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  34%|███▍      | 126/367 [00:22<00:41,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  35%|███▍      | 127/367 [00:22<00:40,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  35%|███▍      | 128/367 [00:22<00:40,  5.86it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  35%|███▌      | 129/367 [00:22<00:41,  5.67it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  35%|███▌      | 130/367 [00:23<00:38,  6.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  36%|███▌      | 131/367 [00:23<00:39,  6.03it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  36%|███▌      | 132/367 [00:23<00:36,  6.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  36%|███▌      | 133/367 [00:23<00:36,  6.37it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  37%|███▋      | 134/367 [00:23<00:39,  5.94it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  37%|███▋      | 135/367 [00:23<00:43,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  37%|███▋      | 136/367 [00:24<00:39,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  37%|███▋      | 137/367 [00:24<00:39,  5.77it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  38%|███▊      | 138/367 [00:24<00:38,  5.94it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  38%|███▊      | 139/367 [00:24<00:38,  5.92it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  38%|███▊      | 140/367 [00:24<00:37,  6.11it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  38%|███▊      | 141/367 [00:24<00:37,  6.02it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  39%|███▊      | 142/367 [00:25<00:41,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  39%|███▉      | 143/367 [00:25<00:43,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  39%|███▉      | 144/367 [00:25<00:42,  5.28it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  40%|███▉      | 145/367 [00:25<00:43,  5.12it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5858 || acc: 68.12% || lr 7.974e-06:  40%|███▉      | 146/367 [00:25<00:41,  5.30it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  40%|███▉      | 146/367 [00:25<00:41,  5.30it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  40%|████      | 147/367 [00:26<00:40,  5.37it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  40%|████      | 148/367 [00:26<00:41,  5.24it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  41%|████      | 149/367 [00:26<00:41,  5.20it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  41%|████      | 150/367 [00:26<00:40,  5.38it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  41%|████      | 151/367 [00:26<00:39,  5.51it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  41%|████▏     | 152/367 [00:27<00:36,  5.93it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  42%|████▏     | 153/367 [00:27<00:37,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  42%|████▏     | 154/367 [00:27<00:38,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  42%|████▏     | 155/367 [00:27<00:37,  5.72it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  43%|████▎     | 156/367 [00:27<00:39,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  43%|████▎     | 157/367 [00:27<00:41,  5.11it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  43%|████▎     | 158/367 [00:28<00:43,  4.82it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  43%|████▎     | 159/367 [00:28<00:40,  5.12it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  44%|████▎     | 160/367 [00:28<00:39,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  44%|████▍     | 161/367 [00:28<00:36,  5.64it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  44%|████▍     | 162/367 [00:28<00:36,  5.62it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  44%|████▍     | 163/367 [00:29<00:36,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  45%|████▍     | 164/367 [00:29<00:36,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  45%|████▍     | 165/367 [00:29<00:34,  5.85it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6233 || acc: 67.50% || lr 7.972e-06:  45%|████▌     | 166/367 [00:29<00:33,  5.92it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  45%|████▌     | 166/367 [00:29<00:33,  5.92it/s] \u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  46%|████▌     | 167/367 [00:29<00:35,  5.71it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  46%|████▌     | 168/367 [00:29<00:36,  5.40it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  46%|████▌     | 169/367 [00:30<00:35,  5.51it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  46%|████▋     | 170/367 [00:30<00:36,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  47%|████▋     | 171/367 [00:30<00:36,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  47%|████▋     | 172/367 [00:30<00:35,  5.48it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  47%|████▋     | 173/367 [00:30<00:34,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  47%|████▋     | 174/367 [00:31<00:35,  5.48it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  48%|████▊     | 175/367 [00:31<00:37,  5.10it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  48%|████▊     | 176/367 [00:31<00:36,  5.25it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  48%|████▊     | 177/367 [00:31<00:35,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  49%|████▊     | 178/367 [00:31<00:35,  5.34it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  49%|████▉     | 179/367 [00:32<00:34,  5.45it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  49%|████▉     | 180/367 [00:32<00:36,  5.19it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  49%|████▉     | 181/367 [00:32<00:33,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  50%|████▉     | 182/367 [00:32<00:35,  5.19it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  50%|████▉     | 183/367 [00:32<00:35,  5.18it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  50%|█████     | 184/367 [00:33<00:36,  4.96it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  50%|█████     | 185/367 [00:33<00:34,  5.33it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.665 || acc: 62.50% || lr 7.971e-06:  51%|█████     | 186/367 [00:33<00:34,  5.24it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  51%|█████     | 186/367 [00:33<00:34,  5.24it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  51%|█████     | 187/367 [00:33<00:32,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  51%|█████     | 188/367 [00:33<00:31,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  51%|█████▏    | 189/367 [00:33<00:30,  5.84it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  52%|█████▏    | 190/367 [00:34<00:30,  5.86it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  52%|█████▏    | 191/367 [00:34<00:30,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  52%|█████▏    | 192/367 [00:34<00:30,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  53%|█████▎    | 193/367 [00:34<00:31,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  53%|█████▎    | 194/367 [00:34<00:30,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  53%|█████▎    | 195/367 [00:34<00:30,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  53%|█████▎    | 196/367 [00:35<00:32,  5.25it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  54%|█████▎    | 197/367 [00:35<00:30,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  54%|█████▍    | 198/367 [00:35<00:32,  5.26it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  54%|█████▍    | 199/367 [00:35<00:31,  5.33it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  54%|█████▍    | 200/367 [00:35<00:30,  5.46it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  55%|█████▍    | 201/367 [00:36<00:30,  5.50it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  55%|█████▌    | 202/367 [00:36<00:29,  5.64it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  55%|█████▌    | 203/367 [00:36<00:30,  5.36it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  56%|█████▌    | 204/367 [00:36<00:31,  5.24it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  56%|█████▌    | 205/367 [00:36<00:29,  5.41it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5974 || acc: 67.50% || lr 7.969e-06:  56%|█████▌    | 206/367 [00:36<00:28,  5.74it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  56%|█████▌    | 206/367 [00:36<00:28,  5.74it/s] \u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  56%|█████▋    | 207/367 [00:37<00:28,  5.67it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  57%|█████▋    | 208/367 [00:37<00:29,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  57%|█████▋    | 209/367 [00:37<00:27,  5.68it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  57%|█████▋    | 210/367 [00:37<00:27,  5.75it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  57%|█████▋    | 211/367 [00:37<00:28,  5.41it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  58%|█████▊    | 212/367 [00:38<00:26,  5.75it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  58%|█████▊    | 213/367 [00:38<00:27,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  58%|█████▊    | 214/367 [00:38<00:26,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  59%|█████▊    | 215/367 [00:38<00:25,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  59%|█████▉    | 216/367 [00:38<00:26,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  59%|█████▉    | 217/367 [00:38<00:26,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  59%|█████▉    | 218/367 [00:39<00:27,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  60%|█████▉    | 219/367 [00:39<00:27,  5.33it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  60%|█████▉    | 220/367 [00:39<00:27,  5.40it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  60%|██████    | 221/367 [00:39<00:26,  5.45it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  60%|██████    | 222/367 [00:39<00:26,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  61%|██████    | 223/367 [00:39<00:25,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  61%|██████    | 224/367 [00:40<00:25,  5.68it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  61%|██████▏   | 225/367 [00:40<00:25,  5.65it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.579 || acc: 71.88% || lr 7.968e-06:  62%|██████▏   | 226/367 [00:40<00:25,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  62%|██████▏   | 226/367 [00:40<00:25,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  62%|██████▏   | 227/367 [00:40<00:25,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  62%|██████▏   | 228/367 [00:40<00:25,  5.51it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  62%|██████▏   | 229/367 [00:41<00:25,  5.52it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  63%|██████▎   | 230/367 [00:41<00:24,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  63%|██████▎   | 231/367 [00:41<00:24,  5.66it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.50it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  63%|██████▎   | 233/367 [00:41<00:24,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  64%|██████▍   | 234/367 [00:41<00:22,  5.82it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  64%|██████▍   | 235/367 [00:42<00:21,  6.15it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  64%|██████▍   | 236/367 [00:42<00:22,  5.87it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  65%|██████▍   | 237/367 [00:42<00:23,  5.49it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  65%|██████▍   | 238/367 [00:42<00:22,  5.62it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  65%|██████▌   | 239/367 [00:42<00:22,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  65%|██████▌   | 240/367 [00:43<00:22,  5.57it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  66%|██████▌   | 241/367 [00:43<00:21,  5.86it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  66%|██████▌   | 242/367 [00:43<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  66%|██████▌   | 243/367 [00:43<00:21,  5.76it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  66%|██████▋   | 244/367 [00:43<00:21,  5.69it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  67%|██████▋   | 245/367 [00:43<00:20,  5.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6019 || acc: 68.75% || lr 7.966e-06:  67%|██████▋   | 246/367 [00:44<00:21,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  67%|██████▋   | 246/367 [00:44<00:21,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  67%|██████▋   | 247/367 [00:44<00:21,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  68%|██████▊   | 248/367 [00:44<00:22,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  68%|██████▊   | 249/367 [00:44<00:21,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.55it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  68%|██████▊   | 251/367 [00:44<00:20,  5.71it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  69%|██████▊   | 252/367 [00:45<00:19,  5.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  69%|██████▉   | 253/367 [00:45<00:18,  6.25it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  69%|██████▉   | 254/367 [00:45<00:20,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  69%|██████▉   | 255/367 [00:45<00:20,  5.38it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  70%|██████▉   | 256/367 [00:45<00:21,  5.26it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  70%|███████   | 257/367 [00:46<00:19,  5.53it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  70%|███████   | 258/367 [00:46<00:20,  5.43it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  71%|███████   | 259/367 [00:46<00:21,  5.12it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  71%|███████   | 260/367 [00:46<00:19,  5.58it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  71%|███████   | 261/367 [00:46<00:19,  5.51it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  71%|███████▏  | 262/367 [00:46<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  72%|███████▏  | 263/367 [00:47<00:17,  6.00it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  72%|███████▏  | 264/367 [00:47<00:16,  6.14it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  72%|███████▏  | 265/367 [00:47<00:17,  5.98it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5244 || acc: 76.88% || lr 7.965e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.85it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.85it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.58it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  73%|███████▎  | 269/367 [00:48<00:17,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  74%|███████▎  | 270/367 [00:48<00:16,  5.97it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  74%|███████▍  | 271/367 [00:48<00:15,  6.12it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  74%|███████▍  | 273/367 [00:48<00:16,  5.76it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  75%|███████▍  | 274/367 [00:48<00:16,  5.80it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  75%|███████▍  | 275/367 [00:49<00:16,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  75%|███████▌  | 276/367 [00:49<00:15,  6.01it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  75%|███████▌  | 277/367 [00:49<00:14,  6.11it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  76%|███████▌  | 278/367 [00:49<00:15,  5.68it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  76%|███████▌  | 279/367 [00:49<00:15,  5.54it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  76%|███████▋  | 280/367 [00:50<00:15,  5.64it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  77%|███████▋  | 281/367 [00:50<00:15,  5.61it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  77%|███████▋  | 282/367 [00:50<00:14,  5.68it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  77%|███████▋  | 284/367 [00:50<00:16,  5.11it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  78%|███████▊  | 285/367 [00:50<00:14,  5.52it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6304 || acc: 63.12% || lr 7.963e-06:  78%|███████▊  | 286/367 [00:51<00:14,  5.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  78%|███████▊  | 286/367 [00:51<00:14,  5.47it/s] \u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  78%|███████▊  | 287/367 [00:51<00:14,  5.42it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  78%|███████▊  | 288/367 [00:51<00:14,  5.43it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.86it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  79%|███████▉  | 290/367 [00:51<00:12,  6.02it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  79%|███████▉  | 291/367 [00:52<00:13,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  80%|███████▉  | 292/367 [00:52<00:12,  6.14it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  80%|███████▉  | 293/367 [00:52<00:12,  5.87it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  80%|████████  | 294/367 [00:52<00:11,  6.47it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  80%|████████  | 295/367 [00:52<00:11,  6.06it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  81%|████████  | 296/367 [00:52<00:11,  5.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  81%|████████  | 297/367 [00:52<00:12,  5.80it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  81%|████████  | 298/367 [00:53<00:11,  6.00it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  81%|████████▏ | 299/367 [00:53<00:11,  5.72it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  82%|████████▏ | 300/367 [00:53<00:11,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  82%|████████▏ | 301/367 [00:53<00:11,  5.73it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  82%|████████▏ | 302/367 [00:53<00:11,  5.72it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  83%|████████▎ | 303/367 [00:54<00:11,  5.65it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  83%|████████▎ | 304/367 [00:54<00:10,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  83%|████████▎ | 305/367 [00:54<00:10,  6.13it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.569 || acc: 75.00% || lr 7.962e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.94it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.94it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  84%|████████▎ | 307/367 [00:54<00:09,  6.23it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  84%|████████▍ | 308/367 [00:54<00:09,  6.05it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  84%|████████▍ | 309/367 [00:55<00:09,  5.88it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  84%|████████▍ | 310/367 [00:55<00:09,  5.87it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.66it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.54it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.53it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  86%|████████▌ | 314/367 [00:55<00:10,  5.19it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.45it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  86%|████████▌ | 316/367 [00:56<00:08,  5.77it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  86%|████████▋ | 317/367 [00:56<00:08,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.48it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  87%|████████▋ | 319/367 [00:56<00:09,  5.29it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  87%|████████▋ | 320/367 [00:57<00:09,  5.03it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  87%|████████▋ | 321/367 [00:57<00:09,  4.98it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.25it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  88%|████████▊ | 323/367 [00:57<00:08,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  88%|████████▊ | 324/367 [00:57<00:08,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  89%|████████▊ | 325/367 [00:58<00:08,  5.15it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5605 || acc: 75.62% || lr 7.961e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.31it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.31it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  89%|████████▉ | 327/367 [00:58<00:08,  4.98it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  89%|████████▉ | 328/367 [00:58<00:07,  4.97it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  90%|████████▉ | 329/367 [00:58<00:07,  5.41it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.74it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  90%|█████████ | 331/367 [00:59<00:06,  5.78it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  90%|█████████ | 332/367 [00:59<00:07,  4.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.22it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.00it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  91%|█████████▏| 335/367 [00:59<00:06,  4.95it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  92%|█████████▏| 336/367 [01:00<00:05,  5.23it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  92%|█████████▏| 338/367 [01:00<00:05,  5.49it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  92%|█████████▏| 339/367 [01:00<00:05,  5.15it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.49it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  93%|█████████▎| 341/367 [01:01<00:04,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  93%|█████████▎| 342/367 [01:01<00:04,  5.63it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.50it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.50it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.39it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5944 || acc: 68.75% || lr 7.959e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.44it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  95%|█████████▍| 347/367 [01:02<00:03,  5.76it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.28it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.66it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.90it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  96%|█████████▌| 352/367 [01:03<00:02,  5.79it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  96%|█████████▌| 353/367 [01:03<00:02,  5.80it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.83it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.24it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.60it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.72it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  98%|█████████▊| 358/367 [01:04<00:01,  5.97it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.97it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.79it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.75it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.59it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.45it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  99%|█████████▉| 364/367 [01:05<00:00,  5.13it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.35it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.6068 || acc: 67.50% || lr 7.958e-06: 100%|█████████▉| 366/367 [01:05<00:00,  5.53it/s]\u001b[A\n",
      "Epoch: [2/30] || loss: 0.5545 || acc: 73.12% || lr 7.956e-06: 100%|██████████| 367/367 [01:05<00:00,  5.59it/s]\n",
      "\n",
      "[Validation] Epoch 3:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 3:   3%|▎         | 3/92 [00:00<00:04, 21.12it/s]\u001b[A\n",
      "[Validation] Epoch 3:   7%|▋         | 6/92 [00:00<00:04, 18.13it/s]\u001b[A\n",
      "[Validation] Epoch 3:   9%|▊         | 8/92 [00:00<00:04, 17.77it/s]\u001b[A\n",
      "[Validation] Epoch 3:  11%|█         | 10/92 [00:00<00:04, 17.65it/s]\u001b[A\n",
      "[Validation] Epoch 3:  13%|█▎        | 12/92 [00:00<00:04, 16.67it/s]\u001b[A\n",
      "[Validation] Epoch 3:  15%|█▌        | 14/92 [00:00<00:04, 16.71it/s]\u001b[A\n",
      "[Validation] Epoch 3:  17%|█▋        | 16/92 [00:00<00:04, 17.52it/s]\u001b[A\n",
      "[Validation] Epoch 3:  20%|█▉        | 18/92 [00:01<00:04, 17.51it/s]\u001b[A\n",
      "[Validation] Epoch 3:  22%|██▏       | 20/92 [00:01<00:04, 17.86it/s]\u001b[A\n",
      "[Validation] Epoch 3:  24%|██▍       | 22/92 [00:01<00:04, 16.89it/s]\u001b[A\n",
      "[Validation] Epoch 3:  27%|██▋       | 25/92 [00:01<00:03, 17.69it/s]\u001b[A\n",
      "[Validation] Epoch 3:  29%|██▉       | 27/92 [00:01<00:03, 16.78it/s]\u001b[A\n",
      "[Validation] Epoch 3:  32%|███▏      | 29/92 [00:01<00:03, 16.96it/s]\u001b[A\n",
      "[Validation] Epoch 3:  34%|███▎      | 31/92 [00:01<00:03, 17.19it/s]\u001b[A\n",
      "[Validation] Epoch 3:  37%|███▋      | 34/92 [00:01<00:03, 17.90it/s]\u001b[A\n",
      "[Validation] Epoch 3:  39%|███▉      | 36/92 [00:02<00:03, 17.45it/s]\u001b[A\n",
      "[Validation] Epoch 3:  41%|████▏     | 38/92 [00:02<00:03, 17.42it/s]\u001b[A\n",
      "[Validation] Epoch 3:  43%|████▎     | 40/92 [00:02<00:02, 17.39it/s]\u001b[A\n",
      "[Validation] Epoch 3:  46%|████▌     | 42/92 [00:02<00:02, 17.59it/s]\u001b[A\n",
      "[Validation] Epoch 3:  48%|████▊     | 44/92 [00:02<00:02, 17.47it/s]\u001b[A\n",
      "[Validation] Epoch 3:  51%|█████     | 47/92 [00:02<00:02, 17.82it/s]\u001b[A\n",
      "[Validation] Epoch 3:  53%|█████▎    | 49/92 [00:02<00:02, 17.11it/s]\u001b[A\n",
      "[Validation] Epoch 3:  55%|█████▌    | 51/92 [00:02<00:02, 17.08it/s]\u001b[A\n",
      "[Validation] Epoch 3:  58%|█████▊    | 53/92 [00:03<00:02, 17.79it/s]\u001b[A\n",
      "[Validation] Epoch 3:  61%|██████    | 56/92 [00:03<00:01, 19.27it/s]\u001b[A\n",
      "[Validation] Epoch 3:  63%|██████▎   | 58/92 [00:03<00:01, 18.77it/s]\u001b[A\n",
      "[Validation] Epoch 3:  65%|██████▌   | 60/92 [00:03<00:01, 19.04it/s]\u001b[A\n",
      "[Validation] Epoch 3:  67%|██████▋   | 62/92 [00:03<00:01, 18.96it/s]\u001b[A\n",
      "[Validation] Epoch 3:  70%|██████▉   | 64/92 [00:03<00:01, 19.04it/s]\u001b[A\n",
      "[Validation] Epoch 3:  72%|███████▏  | 66/92 [00:03<00:01, 18.72it/s]\u001b[A\n",
      "[Validation] Epoch 3:  74%|███████▍  | 68/92 [00:03<00:01, 17.39it/s]\u001b[A\n",
      "[Validation] Epoch 3:  77%|███████▋  | 71/92 [00:03<00:01, 18.24it/s]\u001b[A\n",
      "[Validation] Epoch 3:  79%|███████▉  | 73/92 [00:04<00:01, 18.37it/s]\u001b[A\n",
      "[Validation] Epoch 3:  82%|████████▏ | 75/92 [00:04<00:00, 18.26it/s]\u001b[A\n",
      "[Validation] Epoch 3:  84%|████████▎ | 77/92 [00:04<00:00, 18.09it/s]\u001b[A\n",
      "[Validation] Epoch 3:  86%|████████▌ | 79/92 [00:04<00:00, 17.76it/s]\u001b[A\n",
      "[Validation] Epoch 3:  88%|████████▊ | 81/92 [00:04<00:00, 18.13it/s]\u001b[A\n",
      "[Validation] Epoch 3:  91%|█████████▏| 84/92 [00:04<00:00, 19.09it/s]\u001b[A\n",
      "[Validation] Epoch 3:  93%|█████████▎| 86/92 [00:04<00:00, 17.96it/s]\u001b[A\n",
      "[Validation] Epoch 3:  96%|█████████▌| 88/92 [00:04<00:00, 17.55it/s]\u001b[A\n",
      "[Validation] Epoch 3:  99%|█████████▉| 91/92 [00:05<00:00, 18.26it/s]\u001b[A\n",
      "Validation: [2/30] || loss: 0.5878 || acc: 69.43%: 100%|██████████| 92/92 [00:05<00:00, 17.79it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.6942934782608695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 3/30 [03:37<32:41, 72.63s/it]\n",
      "[Training] Epoch 4:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 4:   0%|          | 1/367 [00:00<01:08,  5.34it/s]\u001b[A\n",
      "[Training] Epoch 4:   1%|          | 2/367 [00:00<01:04,  5.64it/s]\u001b[A\n",
      "[Training] Epoch 4:   1%|          | 3/367 [00:00<00:58,  6.20it/s]\u001b[A\n",
      "[Training] Epoch 4:   1%|          | 4/367 [00:00<01:00,  6.03it/s]\u001b[A\n",
      "[Training] Epoch 4:   1%|▏         | 5/367 [00:00<01:02,  5.80it/s]\u001b[A\n",
      "[Training] Epoch 4:   2%|▏         | 6/367 [00:01<01:02,  5.74it/s]\u001b[A\n",
      "[Training] Epoch 4:   2%|▏         | 7/367 [00:01<01:04,  5.55it/s]\u001b[A\n",
      "[Training] Epoch 4:   2%|▏         | 8/367 [00:01<01:11,  5.00it/s]\u001b[A\n",
      "[Training] Epoch 4:   2%|▏         | 9/367 [00:01<01:07,  5.30it/s]\u001b[A\n",
      "[Training] Epoch 4:   3%|▎         | 10/367 [00:01<01:10,  5.09it/s]\u001b[A\n",
      "[Training] Epoch 4:   3%|▎         | 11/367 [00:02<01:06,  5.34it/s]\u001b[A\n",
      "[Training] Epoch 4:   3%|▎         | 12/367 [00:02<01:04,  5.54it/s]\u001b[A\n",
      "[Training] Epoch 4:   4%|▎         | 13/367 [00:02<00:58,  6.06it/s]\u001b[A\n",
      "[Training] Epoch 4:   4%|▍         | 14/367 [00:02<01:00,  5.88it/s]\u001b[A\n",
      "[Training] Epoch 4:   4%|▍         | 15/367 [00:02<00:59,  5.87it/s]\u001b[A\n",
      "[Training] Epoch 4:   4%|▍         | 16/367 [00:02<01:01,  5.71it/s]\u001b[A\n",
      "[Training] Epoch 4:   5%|▍         | 17/367 [00:02<00:56,  6.18it/s]\u001b[A\n",
      "[Training] Epoch 4:   5%|▍         | 18/367 [00:03<00:55,  6.34it/s]\u001b[A\n",
      "[Training] Epoch 4:   5%|▌         | 19/367 [00:03<00:55,  6.24it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   5%|▌         | 19/367 [00:03<00:55,  6.24it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   5%|▌         | 20/367 [00:03<00:58,  5.96it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   6%|▌         | 21/367 [00:03<00:56,  6.08it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   6%|▌         | 22/367 [00:03<00:55,  6.19it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   6%|▋         | 23/367 [00:03<00:54,  6.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   7%|▋         | 24/367 [00:04<00:55,  6.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   7%|▋         | 25/367 [00:04<00:56,  6.07it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   7%|▋         | 26/367 [00:04<00:57,  5.93it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   7%|▋         | 27/367 [00:04<01:01,  5.51it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   8%|▊         | 28/367 [00:04<01:00,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   8%|▊         | 29/367 [00:05<01:00,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   8%|▊         | 30/367 [00:05<01:00,  5.57it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   8%|▊         | 31/367 [00:05<00:59,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   9%|▊         | 32/367 [00:05<01:02,  5.39it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   9%|▉         | 33/367 [00:05<01:01,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:   9%|▉         | 34/367 [00:05<01:03,  5.24it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:  10%|▉         | 35/367 [00:06<01:03,  5.21it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:  10%|▉         | 36/367 [00:06<00:59,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:  10%|█         | 37/367 [00:06<00:56,  5.83it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:  10%|█         | 38/367 [00:06<00:56,  5.81it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4683 || acc: 71.88% || lr 7.955e-06:  11%|█         | 39/367 [00:06<00:54,  6.02it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  11%|█         | 39/367 [00:06<00:54,  6.02it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  11%|█         | 40/367 [00:07<01:00,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  11%|█         | 41/367 [00:07<01:04,  5.08it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  11%|█▏        | 42/367 [00:07<01:05,  4.97it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  12%|█▏        | 43/367 [00:07<01:00,  5.39it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  12%|█▏        | 44/367 [00:07<00:56,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  12%|█▏        | 45/367 [00:07<01:00,  5.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  13%|█▎        | 46/367 [00:08<00:58,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  13%|█▎        | 47/367 [00:08<00:59,  5.35it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  13%|█▎        | 48/367 [00:08<00:58,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  13%|█▎        | 49/367 [00:08<00:57,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  14%|█▎        | 50/367 [00:08<01:01,  5.17it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  14%|█▍        | 51/367 [00:09<00:59,  5.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  14%|█▍        | 52/367 [00:09<00:56,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  14%|█▍        | 53/367 [00:09<00:58,  5.40it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  15%|█▍        | 54/367 [00:09<01:01,  5.09it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  15%|█▍        | 55/367 [00:09<00:59,  5.26it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  15%|█▌        | 56/367 [00:10<00:58,  5.30it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  16%|█▌        | 57/367 [00:10<00:56,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  16%|█▌        | 58/367 [00:10<00:52,  5.84it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4632 || acc: 76.25% || lr 7.953e-06:  16%|█▌        | 59/367 [00:10<00:55,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  16%|█▌        | 59/367 [00:10<00:55,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  16%|█▋        | 60/367 [00:10<00:55,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  17%|█▋        | 61/367 [00:10<00:57,  5.30it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  17%|█▋        | 62/367 [00:11<00:54,  5.57it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  17%|█▋        | 63/367 [00:11<00:56,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  17%|█▋        | 64/367 [00:11<00:55,  5.47it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  18%|█▊        | 65/367 [00:11<00:52,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  18%|█▊        | 66/367 [00:11<00:54,  5.53it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  18%|█▊        | 67/367 [00:11<00:51,  5.78it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  19%|█▊        | 68/367 [00:12<00:53,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  19%|█▉        | 69/367 [00:12<00:53,  5.53it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  19%|█▉        | 70/367 [00:12<00:54,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  19%|█▉        | 71/367 [00:12<00:51,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  20%|█▉        | 72/367 [00:12<00:56,  5.26it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  20%|█▉        | 73/367 [00:13<00:54,  5.38it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  20%|██        | 74/367 [00:13<00:55,  5.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  20%|██        | 75/367 [00:13<00:52,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  21%|██        | 76/367 [00:13<00:56,  5.11it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  21%|██        | 77/367 [00:13<00:53,  5.42it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  21%|██▏       | 78/367 [00:14<00:51,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4244 || acc: 81.88% || lr 7.952e-06:  22%|██▏       | 79/367 [00:14<00:50,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  22%|██▏       | 79/367 [00:14<00:50,  5.75it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  22%|██▏       | 80/367 [00:14<00:51,  5.58it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  22%|██▏       | 81/367 [00:14<00:51,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  22%|██▏       | 82/367 [00:14<00:49,  5.82it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  23%|██▎       | 83/367 [00:14<00:46,  6.04it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  23%|██▎       | 84/367 [00:15<00:49,  5.69it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  23%|██▎       | 85/367 [00:15<00:50,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  23%|██▎       | 86/367 [00:15<00:48,  5.84it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  24%|██▎       | 87/367 [00:15<00:51,  5.47it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  24%|██▍       | 88/367 [00:15<00:53,  5.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  24%|██▍       | 89/367 [00:15<00:50,  5.49it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  25%|██▍       | 90/367 [00:16<00:48,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  25%|██▍       | 91/367 [00:16<00:51,  5.36it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  25%|██▌       | 92/367 [00:16<00:49,  5.53it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  25%|██▌       | 93/367 [00:16<00:49,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  26%|██▌       | 94/367 [00:16<00:47,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  26%|██▌       | 95/367 [00:17<00:46,  5.83it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  26%|██▌       | 96/367 [00:17<00:44,  6.04it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  26%|██▋       | 97/367 [00:17<00:45,  5.99it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  27%|██▋       | 98/367 [00:17<00:42,  6.31it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4754 || acc: 79.38% || lr 7.95e-06:  27%|██▋       | 99/367 [00:17<00:43,  6.20it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  27%|██▋       | 99/367 [00:17<00:43,  6.20it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  27%|██▋       | 100/367 [00:17<00:44,  6.06it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  28%|██▊       | 101/367 [00:17<00:42,  6.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  28%|██▊       | 102/367 [00:18<00:43,  6.11it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  28%|██▊       | 103/367 [00:18<00:42,  6.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  28%|██▊       | 104/367 [00:18<00:43,  6.09it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  29%|██▊       | 105/367 [00:18<00:41,  6.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  29%|██▉       | 106/367 [00:18<00:47,  5.54it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  29%|██▉       | 107/367 [00:19<00:47,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  29%|██▉       | 108/367 [00:19<00:49,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  30%|██▉       | 109/367 [00:19<00:47,  5.40it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  30%|██▉       | 110/367 [00:19<00:49,  5.24it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  30%|███       | 111/367 [00:19<00:47,  5.39it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  31%|███       | 112/367 [00:19<00:46,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  31%|███       | 113/367 [00:20<00:44,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  31%|███       | 114/367 [00:20<00:42,  5.97it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  31%|███▏      | 115/367 [00:20<00:41,  6.13it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  32%|███▏      | 116/367 [00:20<00:41,  6.02it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  32%|███▏      | 117/367 [00:20<00:43,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  32%|███▏      | 118/367 [00:20<00:41,  5.97it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5227 || acc: 75.62% || lr 7.949e-06:  32%|███▏      | 119/367 [00:21<00:42,  5.83it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  32%|███▏      | 119/367 [00:21<00:42,  5.83it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  33%|███▎      | 120/367 [00:21<00:42,  5.82it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  33%|███▎      | 121/367 [00:21<00:42,  5.77it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  33%|███▎      | 122/367 [00:21<00:42,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  34%|███▎      | 123/367 [00:21<00:42,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  34%|███▍      | 124/367 [00:22<00:42,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  34%|███▍      | 125/367 [00:22<00:40,  6.00it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  34%|███▍      | 126/367 [00:22<00:41,  5.76it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  35%|███▍      | 127/367 [00:22<00:42,  5.69it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  35%|███▍      | 128/367 [00:22<00:40,  5.97it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  35%|███▌      | 129/367 [00:22<00:40,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  35%|███▌      | 130/367 [00:23<00:40,  5.92it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  36%|███▌      | 131/367 [00:23<00:38,  6.13it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  36%|███▌      | 132/367 [00:23<00:39,  5.95it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  36%|███▌      | 133/367 [00:23<00:42,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  37%|███▋      | 134/367 [00:23<00:44,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  37%|███▋      | 135/367 [00:23<00:42,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  37%|███▋      | 136/367 [00:24<00:41,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  37%|███▋      | 137/367 [00:24<00:40,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  38%|███▊      | 138/367 [00:24<00:37,  6.04it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.439 || acc: 83.75% || lr 7.947e-06:  38%|███▊      | 139/367 [00:24<00:36,  6.33it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  38%|███▊      | 139/367 [00:24<00:36,  6.33it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  38%|███▊      | 140/367 [00:24<00:38,  5.89it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  38%|███▊      | 141/367 [00:24<00:38,  5.85it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  39%|███▊      | 142/367 [00:25<00:42,  5.26it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  39%|███▉      | 143/367 [00:25<00:39,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  39%|███▉      | 144/367 [00:25<00:38,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  40%|███▉      | 145/367 [00:25<00:37,  5.85it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  40%|███▉      | 146/367 [00:25<00:37,  5.83it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  40%|████      | 147/367 [00:25<00:38,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  40%|████      | 148/367 [00:26<00:39,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  41%|████      | 149/367 [00:26<00:38,  5.68it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  41%|████      | 150/367 [00:26<00:38,  5.57it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  41%|████      | 151/367 [00:26<00:39,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  41%|████▏     | 152/367 [00:26<00:39,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  42%|████▏     | 153/367 [00:27<00:36,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  42%|████▏     | 154/367 [00:27<00:39,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  42%|████▏     | 155/367 [00:27<00:37,  5.60it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  43%|████▎     | 156/367 [00:27<00:39,  5.38it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  43%|████▎     | 157/367 [00:27<00:38,  5.51it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  43%|████▎     | 158/367 [00:27<00:37,  5.55it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.574 || acc: 70.62% || lr 7.946e-06:  43%|████▎     | 159/367 [00:28<00:39,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  43%|████▎     | 159/367 [00:28<00:39,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.64it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  44%|████▍     | 161/367 [00:28<00:37,  5.54it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  44%|████▍     | 162/367 [00:28<00:40,  5.06it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  44%|████▍     | 163/367 [00:28<00:39,  5.20it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  45%|████▍     | 164/367 [00:29<00:36,  5.51it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  45%|████▍     | 165/367 [00:29<00:38,  5.26it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  45%|████▌     | 166/367 [00:29<00:34,  5.76it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  46%|████▌     | 167/367 [00:29<00:32,  6.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  46%|████▌     | 168/367 [00:29<00:35,  5.64it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  46%|████▌     | 169/367 [00:29<00:35,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  46%|████▋     | 170/367 [00:30<00:37,  5.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  47%|████▋     | 171/367 [00:30<00:36,  5.39it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  47%|████▋     | 172/367 [00:30<00:35,  5.54it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  47%|████▋     | 173/367 [00:30<00:34,  5.54it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  47%|████▋     | 174/367 [00:30<00:35,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  48%|████▊     | 175/367 [00:31<00:35,  5.39it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  48%|████▊     | 176/367 [00:31<00:34,  5.54it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  48%|████▊     | 177/367 [00:31<00:34,  5.53it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  49%|████▊     | 178/367 [00:31<00:33,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4972 || acc: 75.62% || lr 7.944e-06:  49%|████▉     | 179/367 [00:31<00:34,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  49%|████▉     | 179/367 [00:31<00:34,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  49%|████▉     | 180/367 [00:32<00:34,  5.35it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  49%|████▉     | 181/367 [00:32<00:34,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  50%|████▉     | 182/367 [00:32<00:35,  5.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  50%|████▉     | 183/367 [00:32<00:35,  5.12it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  50%|█████     | 184/367 [00:32<00:34,  5.29it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  50%|█████     | 185/367 [00:32<00:34,  5.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  51%|█████     | 186/367 [00:33<00:33,  5.42it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  51%|█████     | 187/367 [00:33<00:31,  5.80it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  51%|█████     | 188/367 [00:33<00:31,  5.61it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  51%|█████▏    | 189/367 [00:33<00:30,  5.88it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  52%|█████▏    | 190/367 [00:33<00:29,  5.95it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  52%|█████▏    | 191/367 [00:33<00:31,  5.65it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  52%|█████▏    | 192/367 [00:34<00:30,  5.76it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  53%|█████▎    | 193/367 [00:34<00:30,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  53%|█████▎    | 194/367 [00:34<00:32,  5.40it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  53%|█████▎    | 195/367 [00:34<00:33,  5.11it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  53%|█████▎    | 196/367 [00:34<00:33,  5.06it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  54%|█████▎    | 197/367 [00:35<00:30,  5.57it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  54%|█████▍    | 198/367 [00:35<00:28,  5.96it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4296 || acc: 80.62% || lr 7.943e-06:  54%|█████▍    | 199/367 [00:35<00:28,  5.81it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  54%|█████▍    | 199/367 [00:35<00:28,  5.81it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  54%|█████▍    | 200/367 [00:35<00:29,  5.60it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  55%|█████▍    | 201/367 [00:35<00:31,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  55%|█████▌    | 202/367 [00:35<00:29,  5.66it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  55%|█████▌    | 203/367 [00:36<00:29,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  56%|█████▌    | 204/367 [00:36<00:29,  5.61it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  56%|█████▌    | 205/367 [00:36<00:27,  5.91it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  56%|█████▌    | 206/367 [00:36<00:28,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  56%|█████▋    | 207/367 [00:36<00:29,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  57%|█████▋    | 208/367 [00:37<00:27,  5.69it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  57%|█████▋    | 209/367 [00:37<00:27,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  57%|█████▋    | 210/367 [00:37<00:27,  5.80it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  57%|█████▋    | 211/367 [00:37<00:25,  6.02it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  58%|█████▊    | 212/367 [00:37<00:26,  5.92it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  58%|█████▊    | 213/367 [00:37<00:24,  6.36it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  58%|█████▊    | 214/367 [00:38<00:25,  5.94it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  59%|█████▊    | 215/367 [00:38<00:25,  5.99it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  59%|█████▉    | 216/367 [00:38<00:25,  5.83it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  59%|█████▉    | 217/367 [00:38<00:28,  5.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.474 || acc: 76.88% || lr 7.942e-06:  60%|█████▉    | 219/367 [00:38<00:28,  5.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  60%|█████▉    | 219/367 [00:38<00:28,  5.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  60%|█████▉    | 220/367 [00:39<00:28,  5.18it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  60%|██████    | 221/367 [00:39<00:27,  5.37it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  60%|██████    | 222/367 [00:39<00:26,  5.52it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  61%|██████    | 223/367 [00:39<00:25,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  61%|██████    | 224/367 [00:39<00:25,  5.68it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  61%|██████▏   | 225/367 [00:40<00:25,  5.66it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  62%|██████▏   | 226/367 [00:40<00:25,  5.52it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  62%|██████▏   | 227/367 [00:40<00:23,  5.90it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  62%|██████▏   | 228/367 [00:40<00:25,  5.47it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  62%|██████▏   | 229/367 [00:40<00:25,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  63%|██████▎   | 230/367 [00:40<00:24,  5.51it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  63%|██████▎   | 231/367 [00:41<00:26,  5.10it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  63%|██████▎   | 233/367 [00:41<00:24,  5.49it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  64%|██████▍   | 234/367 [00:41<00:23,  5.77it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  64%|██████▍   | 235/367 [00:41<00:22,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  64%|██████▍   | 236/367 [00:42<00:22,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  65%|██████▍   | 237/367 [00:42<00:22,  5.66it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  65%|██████▍   | 238/367 [00:42<00:21,  6.04it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5708 || acc: 72.50% || lr 7.94e-06:  65%|██████▌   | 239/367 [00:42<00:23,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  65%|██████▌   | 239/367 [00:42<00:23,  5.50it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  65%|██████▌   | 240/367 [00:42<00:22,  5.74it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  66%|██████▌   | 241/367 [00:42<00:21,  5.84it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  66%|██████▌   | 242/367 [00:43<00:22,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  66%|██████▌   | 243/367 [00:43<00:21,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  66%|██████▋   | 244/367 [00:43<00:20,  6.00it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  67%|██████▋   | 245/367 [00:43<00:20,  6.00it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  67%|██████▋   | 246/367 [00:43<00:22,  5.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  67%|██████▋   | 247/367 [00:43<00:20,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  68%|██████▊   | 248/367 [00:44<00:19,  6.09it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  68%|██████▊   | 249/367 [00:44<00:20,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  68%|██████▊   | 250/367 [00:44<00:19,  6.11it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  68%|██████▊   | 251/367 [00:44<00:19,  5.93it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  69%|██████▊   | 252/367 [00:44<00:19,  5.86it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  69%|██████▉   | 253/367 [00:44<00:19,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  69%|██████▉   | 254/367 [00:45<00:18,  6.21it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  69%|██████▉   | 255/367 [00:45<00:17,  6.33it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  70%|██████▉   | 256/367 [00:45<00:17,  6.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  70%|███████   | 257/367 [00:45<00:19,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  70%|███████   | 258/367 [00:45<00:19,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4427 || acc: 82.50% || lr 7.939e-06:  71%|███████   | 259/367 [00:45<00:19,  5.68it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  71%|███████   | 259/367 [00:45<00:19,  5.68it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  71%|███████   | 260/367 [00:46<00:18,  5.72it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  71%|███████   | 261/367 [00:46<00:19,  5.41it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  71%|███████▏  | 262/367 [00:46<00:19,  5.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  72%|███████▏  | 263/367 [00:46<00:18,  5.51it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  72%|███████▏  | 265/367 [00:47<00:18,  5.61it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.74it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.79it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  73%|███████▎  | 269/367 [00:47<00:17,  5.45it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  74%|███████▎  | 270/367 [00:47<00:17,  5.47it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  74%|███████▍  | 271/367 [00:48<00:19,  4.93it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  74%|███████▍  | 272/367 [00:48<00:19,  4.85it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  74%|███████▍  | 273/367 [00:48<00:19,  4.85it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  75%|███████▍  | 274/367 [00:48<00:18,  5.07it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  75%|███████▍  | 275/367 [00:48<00:17,  5.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  75%|███████▌  | 276/367 [00:49<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.5105 || acc: 76.88% || lr 7.937e-06:  76%|███████▌  | 279/367 [00:49<00:14,  5.95it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  76%|███████▌  | 279/367 [00:49<00:14,  5.95it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  76%|███████▋  | 280/367 [00:49<00:14,  5.84it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  77%|███████▋  | 281/367 [00:49<00:14,  6.01it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  77%|███████▋  | 282/367 [00:50<00:14,  5.95it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  77%|███████▋  | 283/367 [00:50<00:14,  5.94it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  77%|███████▋  | 284/367 [00:50<00:15,  5.38it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  78%|███████▊  | 285/367 [00:50<00:15,  5.31it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  78%|███████▊  | 286/367 [00:50<00:14,  5.46it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  78%|███████▊  | 287/367 [00:51<00:14,  5.37it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  78%|███████▊  | 288/367 [00:51<00:14,  5.31it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  79%|███████▊  | 289/367 [00:51<00:16,  4.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  79%|███████▉  | 290/367 [00:51<00:16,  4.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  79%|███████▉  | 291/367 [00:51<00:15,  5.06it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  80%|███████▉  | 292/367 [00:52<00:14,  5.10it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  80%|███████▉  | 293/367 [00:52<00:14,  5.28it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  80%|████████  | 294/367 [00:52<00:13,  5.57it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  80%|████████  | 295/367 [00:52<00:13,  5.49it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  81%|████████  | 296/367 [00:52<00:12,  5.49it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  81%|████████  | 297/367 [00:53<00:13,  5.09it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  81%|████████  | 298/367 [00:53<00:13,  4.96it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.428 || acc: 82.50% || lr 7.936e-06:  81%|████████▏ | 299/367 [00:53<00:13,  5.03it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  81%|████████▏ | 299/367 [00:53<00:13,  5.03it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  82%|████████▏ | 300/367 [00:53<00:12,  5.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.18it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  82%|████████▏ | 302/367 [00:53<00:11,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  83%|████████▎ | 303/367 [00:54<00:10,  5.88it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  83%|████████▎ | 304/367 [00:54<00:10,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  83%|████████▎ | 305/367 [00:54<00:10,  5.67it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.71it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  84%|████████▎ | 307/367 [00:54<00:10,  5.56it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  84%|████████▍ | 308/367 [00:55<00:10,  5.82it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  84%|████████▍ | 309/367 [00:55<00:10,  5.49it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.55it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  85%|████████▍ | 311/367 [00:55<00:10,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.60it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.68it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  86%|████████▌ | 314/367 [00:56<00:09,  5.74it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  86%|████████▌ | 315/367 [00:56<00:08,  5.93it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  86%|████████▌ | 316/367 [00:56<00:08,  6.11it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  86%|████████▋ | 317/367 [00:56<00:08,  6.00it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  87%|████████▋ | 318/367 [00:56<00:08,  6.02it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4678 || acc: 81.25% || lr 7.934e-06:  87%|████████▋ | 319/367 [00:56<00:08,  5.72it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  87%|████████▋ | 319/367 [00:56<00:08,  5.72it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  87%|████████▋ | 320/367 [00:57<00:08,  5.61it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  87%|████████▋ | 321/367 [00:57<00:07,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  88%|████████▊ | 322/367 [00:57<00:07,  5.94it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  88%|████████▊ | 323/367 [00:57<00:08,  5.35it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  88%|████████▊ | 324/367 [00:57<00:08,  5.04it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  89%|████████▊ | 325/367 [00:58<00:08,  4.96it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.20it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.24it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  89%|████████▉ | 328/367 [00:58<00:07,  5.32it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  90%|████████▉ | 329/367 [00:58<00:06,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.98it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  90%|█████████ | 331/367 [00:59<00:06,  5.86it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  90%|█████████ | 332/367 [00:59<00:05,  5.84it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  91%|█████████ | 333/367 [00:59<00:05,  5.74it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  91%|█████████ | 334/367 [00:59<00:05,  5.81it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.80it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  92%|█████████▏| 336/367 [01:00<00:05,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.60it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  92%|█████████▏| 338/367 [01:00<00:05,  5.23it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.419 || acc: 82.50% || lr 7.933e-06:  92%|█████████▏| 339/367 [01:00<00:05,  5.21it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  92%|█████████▏| 339/367 [01:00<00:05,  5.21it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.48it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.43it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  93%|█████████▎| 342/367 [01:01<00:04,  5.73it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.66it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.42it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.34it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  95%|█████████▍| 347/367 [01:02<00:03,  5.27it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.44it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.60it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  95%|█████████▌| 350/367 [01:02<00:02,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.74it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.62it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  96%|█████████▌| 353/367 [01:03<00:02,  5.75it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.63it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  97%|█████████▋| 355/367 [01:03<00:01,  6.01it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.80it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  97%|█████████▋| 357/367 [01:03<00:01,  6.08it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.90it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4758 || acc: 75.00% || lr 7.931e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.81it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.81it/s] \u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.22it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.59it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.87it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  99%|█████████▉| 364/367 [01:05<00:00,  5.66it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.78it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06: 100%|█████████▉| 366/367 [01:05<00:00,  5.81it/s]\u001b[A\n",
      "Epoch: [3/30] || loss: 0.4816 || acc: 80.00% || lr 7.93e-06: 100%|██████████| 367/367 [01:05<00:00,  5.60it/s]\n",
      "\n",
      "[Validation] Epoch 4:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 4:   3%|▎         | 3/92 [00:00<00:03, 23.82it/s]\u001b[A\n",
      "[Validation] Epoch 4:   7%|▋         | 6/92 [00:00<00:04, 19.57it/s]\u001b[A\n",
      "[Validation] Epoch 4:  10%|▉         | 9/92 [00:00<00:04, 20.52it/s]\u001b[A\n",
      "[Validation] Epoch 4:  13%|█▎        | 12/92 [00:00<00:04, 19.19it/s]\u001b[A\n",
      "[Validation] Epoch 4:  16%|█▋        | 15/92 [00:00<00:03, 19.51it/s]\u001b[A\n",
      "[Validation] Epoch 4:  18%|█▊        | 17/92 [00:00<00:03, 18.81it/s]\u001b[A\n",
      "[Validation] Epoch 4:  21%|██        | 19/92 [00:00<00:03, 18.68it/s]\u001b[A\n",
      "[Validation] Epoch 4:  23%|██▎       | 21/92 [00:01<00:03, 18.65it/s]\u001b[A\n",
      "[Validation] Epoch 4:  26%|██▌       | 24/92 [00:01<00:03, 18.04it/s]\u001b[A\n",
      "[Validation] Epoch 4:  29%|██▉       | 27/92 [00:01<00:03, 17.90it/s]\u001b[A\n",
      "[Validation] Epoch 4:  32%|███▏      | 29/92 [00:01<00:03, 17.67it/s]\u001b[A\n",
      "[Validation] Epoch 4:  35%|███▍      | 32/92 [00:01<00:03, 19.16it/s]\u001b[A\n",
      "[Validation] Epoch 4:  37%|███▋      | 34/92 [00:01<00:03, 17.69it/s]\u001b[A\n",
      "[Validation] Epoch 4:  39%|███▉      | 36/92 [00:01<00:03, 17.19it/s]\u001b[A\n",
      "[Validation] Epoch 4:  41%|████▏     | 38/92 [00:02<00:03, 16.75it/s]\u001b[A\n",
      "[Validation] Epoch 4:  43%|████▎     | 40/92 [00:02<00:03, 17.01it/s]\u001b[A\n",
      "[Validation] Epoch 4:  46%|████▌     | 42/92 [00:02<00:02, 17.02it/s]\u001b[A\n",
      "[Validation] Epoch 4:  48%|████▊     | 44/92 [00:02<00:02, 16.61it/s]\u001b[A\n",
      "[Validation] Epoch 4:  50%|█████     | 46/92 [00:02<00:02, 17.17it/s]\u001b[A\n",
      "[Validation] Epoch 4:  52%|█████▏    | 48/92 [00:02<00:02, 16.99it/s]\u001b[A\n",
      "[Validation] Epoch 4:  54%|█████▍    | 50/92 [00:02<00:02, 17.44it/s]\u001b[A\n",
      "[Validation] Epoch 4:  57%|█████▋    | 52/92 [00:02<00:02, 17.54it/s]\u001b[A\n",
      "[Validation] Epoch 4:  59%|█████▊    | 54/92 [00:02<00:02, 18.11it/s]\u001b[A\n",
      "[Validation] Epoch 4:  62%|██████▏   | 57/92 [00:03<00:01, 18.42it/s]\u001b[A\n",
      "[Validation] Epoch 4:  64%|██████▍   | 59/92 [00:03<00:01, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 4:  67%|██████▋   | 62/92 [00:03<00:01, 18.15it/s]\u001b[A\n",
      "[Validation] Epoch 4:  70%|██████▉   | 64/92 [00:03<00:01, 18.10it/s]\u001b[A\n",
      "[Validation] Epoch 4:  72%|███████▏  | 66/92 [00:03<00:01, 18.05it/s]\u001b[A\n",
      "[Validation] Epoch 4:  75%|███████▌  | 69/92 [00:03<00:01, 18.80it/s]\u001b[A\n",
      "[Validation] Epoch 4:  77%|███████▋  | 71/92 [00:03<00:01, 18.35it/s]\u001b[A\n",
      "[Validation] Epoch 4:  79%|███████▉  | 73/92 [00:04<00:01, 18.58it/s]\u001b[A\n",
      "[Validation] Epoch 4:  82%|████████▏ | 75/92 [00:04<00:00, 18.18it/s]\u001b[A\n",
      "[Validation] Epoch 4:  84%|████████▎ | 77/92 [00:04<00:00, 18.37it/s]\u001b[A\n",
      "[Validation] Epoch 4:  86%|████████▌ | 79/92 [00:04<00:00, 17.75it/s]\u001b[A\n",
      "[Validation] Epoch 4:  88%|████████▊ | 81/92 [00:04<00:00, 17.31it/s]\u001b[A\n",
      "[Validation] Epoch 4:  90%|█████████ | 83/92 [00:04<00:00, 17.52it/s]\u001b[A\n",
      "[Validation] Epoch 4:  92%|█████████▏| 85/92 [00:04<00:00, 17.80it/s]\u001b[A\n",
      "[Validation] Epoch 4:  95%|█████████▍| 87/92 [00:04<00:00, 17.66it/s]\u001b[A\n",
      "[Validation] Epoch 4:  97%|█████████▋| 89/92 [00:04<00:00, 17.80it/s]\u001b[A\n",
      "[Validation] Epoch 4:  99%|█████████▉| 91/92 [00:05<00:00, 17.51it/s]\u001b[A\n",
      "Validation: [3/30] || loss: 0.3615 || acc: 84.24%: 100%|██████████| 92/92 [00:05<00:00, 17.93it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.842391304347826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 13%|█▎        | 4/30 [04:50<31:26, 72.54s/it]\n",
      "[Training] Epoch 5:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 5:   0%|          | 1/367 [00:00<01:35,  3.85it/s]\u001b[A\n",
      "[Training] Epoch 5:   1%|          | 2/367 [00:00<01:22,  4.45it/s]\u001b[A\n",
      "[Training] Epoch 5:   1%|          | 3/367 [00:00<01:17,  4.72it/s]\u001b[A\n",
      "[Training] Epoch 5:   1%|          | 4/367 [00:00<01:08,  5.32it/s]\u001b[A\n",
      "[Training] Epoch 5:   1%|▏         | 5/367 [00:00<01:03,  5.74it/s]\u001b[A\n",
      "[Training] Epoch 5:   2%|▏         | 6/367 [00:01<01:01,  5.84it/s]\u001b[A\n",
      "[Training] Epoch 5:   2%|▏         | 7/367 [00:01<01:00,  5.92it/s]\u001b[A\n",
      "[Training] Epoch 5:   2%|▏         | 8/367 [00:01<00:59,  6.05it/s]\u001b[A\n",
      "[Training] Epoch 5:   2%|▏         | 9/367 [00:01<01:01,  5.79it/s]\u001b[A\n",
      "[Training] Epoch 5:   3%|▎         | 10/367 [00:01<01:01,  5.81it/s]\u001b[A\n",
      "[Training] Epoch 5:   3%|▎         | 11/367 [00:02<01:05,  5.40it/s]\u001b[A\n",
      "[Training] Epoch 5:   3%|▎         | 12/367 [00:02<01:09,  5.10it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   3%|▎         | 12/367 [00:02<01:09,  5.10it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   4%|▎         | 13/367 [00:02<01:12,  4.88it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   4%|▍         | 14/367 [00:02<01:07,  5.20it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   4%|▍         | 15/367 [00:02<01:03,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   4%|▍         | 16/367 [00:02<01:03,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   5%|▍         | 17/367 [00:03<01:08,  5.10it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   5%|▍         | 18/367 [00:03<01:02,  5.60it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   5%|▌         | 19/367 [00:03<00:59,  5.88it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   5%|▌         | 20/367 [00:03<00:59,  5.85it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   6%|▌         | 21/367 [00:03<00:59,  5.83it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   6%|▌         | 22/367 [00:03<00:56,  6.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   6%|▋         | 23/367 [00:04<00:54,  6.33it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   7%|▋         | 24/367 [00:04<00:56,  6.09it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   7%|▋         | 25/367 [00:04<00:57,  5.95it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   7%|▋         | 26/367 [00:04<00:55,  6.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   7%|▋         | 27/367 [00:04<00:54,  6.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   8%|▊         | 28/367 [00:04<00:59,  5.73it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   8%|▊         | 29/367 [00:05<00:58,  5.75it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   8%|▊         | 30/367 [00:05<00:59,  5.68it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   8%|▊         | 31/367 [00:05<01:05,  5.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.1929 || acc: 53.12% || lr 7.928e-06:   9%|▊         | 32/367 [00:05<00:59,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:   9%|▊         | 32/367 [00:05<00:59,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:   9%|▉         | 33/367 [00:05<00:57,  5.76it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:   9%|▉         | 34/367 [00:06<00:57,  5.76it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  10%|▉         | 35/367 [00:06<00:57,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  10%|▉         | 36/367 [00:06<00:57,  5.72it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  10%|█         | 37/367 [00:06<00:57,  5.71it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  10%|█         | 38/367 [00:06<00:58,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  11%|█         | 39/367 [00:06<00:55,  5.87it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  11%|█         | 40/367 [00:07<00:57,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  11%|█         | 41/367 [00:07<00:57,  5.66it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  11%|█▏        | 42/367 [00:07<00:58,  5.55it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  12%|█▏        | 43/367 [00:07<00:55,  5.87it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  12%|█▏        | 44/367 [00:07<00:56,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  12%|█▏        | 45/367 [00:07<00:53,  5.97it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  13%|█▎        | 46/367 [00:08<00:51,  6.20it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  13%|█▎        | 47/367 [00:08<00:57,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  13%|█▎        | 48/367 [00:08<00:54,  5.83it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  13%|█▎        | 49/367 [00:08<00:58,  5.42it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  14%|█▎        | 50/367 [00:08<00:57,  5.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  14%|█▍        | 51/367 [00:09<00:55,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3225 || acc: 88.12% || lr 7.927e-06:  14%|█▍        | 52/367 [00:09<00:55,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  14%|█▍        | 52/367 [00:09<00:55,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  14%|█▍        | 53/367 [00:09<00:58,  5.40it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  15%|█▍        | 54/367 [00:09<00:56,  5.58it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  15%|█▍        | 55/367 [00:09<00:58,  5.37it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  15%|█▌        | 56/367 [00:09<00:58,  5.32it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  16%|█▌        | 57/367 [00:10<00:54,  5.66it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  16%|█▌        | 58/367 [00:10<00:55,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  16%|█▌        | 59/367 [00:10<00:55,  5.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  16%|█▋        | 60/367 [00:10<00:55,  5.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  17%|█▋        | 61/367 [00:10<00:52,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  17%|█▋        | 62/367 [00:10<00:50,  6.06it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  17%|█▋        | 63/367 [00:11<00:56,  5.39it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  17%|█▋        | 64/367 [00:11<00:54,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  18%|█▊        | 65/367 [00:11<00:54,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  18%|█▊        | 66/367 [00:11<00:54,  5.53it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  18%|█▊        | 67/367 [00:11<00:54,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  19%|█▊        | 68/367 [00:12<00:53,  5.55it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  19%|█▉        | 69/367 [00:12<00:53,  5.61it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  19%|█▉        | 70/367 [00:12<00:50,  5.88it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  19%|█▉        | 71/367 [00:12<00:52,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3528 || acc: 84.38% || lr 7.925e-06:  20%|█▉        | 72/367 [00:12<00:53,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  20%|█▉        | 72/367 [00:12<00:53,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  20%|█▉        | 73/367 [00:12<00:51,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  20%|██        | 74/367 [00:13<00:51,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  20%|██        | 75/367 [00:13<00:52,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  21%|██        | 76/367 [00:13<00:52,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  21%|██        | 77/367 [00:13<00:56,  5.16it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  21%|██▏       | 78/367 [00:13<00:54,  5.27it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  22%|██▏       | 79/367 [00:14<00:48,  5.89it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  22%|██▏       | 80/367 [00:14<00:46,  6.22it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  22%|██▏       | 81/367 [00:14<00:47,  5.99it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  22%|██▏       | 82/367 [00:14<00:49,  5.71it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  23%|██▎       | 83/367 [00:14<00:49,  5.79it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  23%|██▎       | 84/367 [00:14<00:49,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  23%|██▎       | 85/367 [00:15<00:50,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  23%|██▎       | 86/367 [00:15<00:49,  5.64it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  24%|██▎       | 87/367 [00:15<00:50,  5.53it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  24%|██▍       | 88/367 [00:15<00:50,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  24%|██▍       | 89/367 [00:15<00:50,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  25%|██▍       | 90/367 [00:16<00:52,  5.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  25%|██▍       | 91/367 [00:16<00:48,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4059 || acc: 84.38% || lr 7.924e-06:  25%|██▌       | 92/367 [00:16<00:45,  6.05it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  25%|██▌       | 92/367 [00:16<00:45,  6.05it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  25%|██▌       | 93/367 [00:16<00:43,  6.24it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  26%|██▌       | 94/367 [00:16<00:42,  6.44it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  26%|██▌       | 95/367 [00:16<00:40,  6.76it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  26%|██▌       | 96/367 [00:16<00:44,  6.15it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  26%|██▋       | 97/367 [00:17<00:47,  5.66it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  27%|██▋       | 99/367 [00:17<00:46,  5.76it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  27%|██▋       | 100/367 [00:17<00:51,  5.23it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  28%|██▊       | 101/367 [00:17<00:50,  5.25it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  28%|██▊       | 102/367 [00:18<00:52,  5.01it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  28%|██▊       | 103/367 [00:18<00:53,  4.93it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  28%|██▊       | 104/367 [00:18<00:49,  5.33it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  29%|██▊       | 105/367 [00:18<00:50,  5.20it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  29%|██▉       | 106/367 [00:18<00:49,  5.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  29%|██▉       | 107/367 [00:19<00:45,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  29%|██▉       | 108/367 [00:19<00:44,  5.82it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  30%|██▉       | 109/367 [00:19<00:42,  6.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  30%|██▉       | 110/367 [00:19<00:43,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  30%|███       | 111/367 [00:19<00:45,  5.66it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3048 || acc: 88.75% || lr 7.923e-06:  31%|███       | 112/367 [00:19<00:46,  5.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  31%|███       | 112/367 [00:19<00:46,  5.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  31%|███       | 113/367 [00:20<00:46,  5.45it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  31%|███       | 114/367 [00:20<00:46,  5.41it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  31%|███▏      | 115/367 [00:20<00:51,  4.91it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  32%|███▏      | 116/367 [00:20<00:46,  5.43it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  32%|███▏      | 117/367 [00:20<00:44,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  32%|███▏      | 118/367 [00:20<00:44,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  32%|███▏      | 119/367 [00:21<00:41,  5.93it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  33%|███▎      | 120/367 [00:21<00:40,  6.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  33%|███▎      | 121/367 [00:21<00:39,  6.25it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  33%|███▎      | 122/367 [00:21<00:40,  6.03it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  34%|███▎      | 123/367 [00:21<00:43,  5.60it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  34%|███▍      | 124/367 [00:22<00:46,  5.28it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  34%|███▍      | 125/367 [00:22<00:42,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  34%|███▍      | 126/367 [00:22<00:46,  5.23it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  35%|███▍      | 127/367 [00:22<00:42,  5.64it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  35%|███▍      | 128/367 [00:22<00:44,  5.37it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  35%|███▌      | 129/367 [00:22<00:43,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  35%|███▌      | 130/367 [00:23<00:40,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  36%|███▌      | 131/367 [00:23<00:40,  5.77it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2652 || acc: 89.38% || lr 7.921e-06:  36%|███▌      | 132/367 [00:23<00:40,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  36%|███▌      | 132/367 [00:23<00:40,  5.86it/s] \u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  36%|███▌      | 133/367 [00:23<00:44,  5.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  37%|███▋      | 134/367 [00:23<00:44,  5.18it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  37%|███▋      | 135/367 [00:24<00:43,  5.37it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  37%|███▋      | 136/367 [00:24<00:43,  5.35it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  37%|███▋      | 137/367 [00:24<00:41,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  38%|███▊      | 138/367 [00:24<00:39,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  38%|███▊      | 139/367 [00:24<00:39,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  38%|███▊      | 140/367 [00:24<00:37,  5.99it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  38%|███▊      | 141/367 [00:25<00:39,  5.72it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  39%|███▊      | 142/367 [00:25<00:39,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  39%|███▉      | 143/367 [00:25<00:40,  5.49it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  39%|███▉      | 144/367 [00:25<00:39,  5.58it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  40%|███▉      | 145/367 [00:25<00:41,  5.41it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  40%|███▉      | 146/367 [00:25<00:38,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  40%|████      | 147/367 [00:26<00:38,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  40%|████      | 148/367 [00:26<00:40,  5.47it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  41%|████      | 149/367 [00:26<00:40,  5.45it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  41%|████      | 150/367 [00:26<00:40,  5.29it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  41%|████      | 151/367 [00:26<00:39,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3092 || acc: 88.12% || lr 7.92e-06:  41%|████▏     | 152/367 [00:27<00:38,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  41%|████▏     | 152/367 [00:27<00:38,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  42%|████▏     | 153/367 [00:27<00:38,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  42%|████▏     | 154/367 [00:27<00:38,  5.58it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  42%|████▏     | 155/367 [00:27<00:37,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  43%|████▎     | 156/367 [00:27<00:36,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  43%|████▎     | 157/367 [00:27<00:36,  5.71it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  43%|████▎     | 158/367 [00:28<00:36,  5.71it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  43%|████▎     | 159/367 [00:28<00:34,  6.04it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  44%|████▍     | 161/367 [00:28<00:35,  5.79it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  44%|████▍     | 162/367 [00:28<00:33,  6.07it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  44%|████▍     | 163/367 [00:28<00:31,  6.40it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  45%|████▍     | 164/367 [00:29<00:34,  5.81it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  45%|████▍     | 165/367 [00:29<00:34,  5.79it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  45%|████▌     | 166/367 [00:29<00:35,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  46%|████▌     | 167/367 [00:29<00:34,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  46%|████▌     | 168/367 [00:29<00:36,  5.39it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  46%|████▌     | 169/367 [00:30<00:34,  5.72it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  46%|████▋     | 170/367 [00:30<00:34,  5.73it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  47%|████▋     | 171/367 [00:30<00:33,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3573 || acc: 85.00% || lr 7.918e-06:  47%|████▋     | 172/367 [00:30<00:31,  6.26it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  47%|████▋     | 172/367 [00:30<00:31,  6.26it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  47%|████▋     | 173/367 [00:30<00:33,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  47%|████▋     | 174/367 [00:30<00:30,  6.24it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  48%|████▊     | 175/367 [00:30<00:31,  6.12it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  48%|████▊     | 176/367 [00:31<00:32,  5.81it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  48%|████▊     | 177/367 [00:31<00:32,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  49%|████▊     | 178/367 [00:31<00:32,  5.91it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  49%|████▉     | 179/367 [00:31<00:32,  5.87it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  49%|████▉     | 180/367 [00:31<00:30,  6.10it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  49%|████▉     | 181/367 [00:31<00:29,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  50%|████▉     | 182/367 [00:32<00:29,  6.29it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  50%|████▉     | 183/367 [00:32<00:31,  5.92it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  50%|█████     | 184/367 [00:32<00:29,  6.23it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  50%|█████     | 185/367 [00:32<00:29,  6.13it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  51%|█████     | 186/367 [00:32<00:32,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  51%|█████     | 187/367 [00:33<00:31,  5.68it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  51%|█████     | 188/367 [00:33<00:31,  5.73it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  51%|█████▏    | 189/367 [00:33<00:30,  5.82it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  52%|█████▏    | 190/367 [00:33<00:30,  5.89it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  52%|█████▏    | 191/367 [00:33<00:28,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3437 || acc: 83.75% || lr 7.917e-06:  52%|█████▏    | 192/367 [00:33<00:30,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  52%|█████▏    | 192/367 [00:33<00:30,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  53%|█████▎    | 193/367 [00:34<00:30,  5.75it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  53%|█████▎    | 194/367 [00:34<00:31,  5.46it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  53%|█████▎    | 195/367 [00:34<00:33,  5.16it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  53%|█████▎    | 196/367 [00:34<00:33,  5.06it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  54%|█████▎    | 197/367 [00:34<00:32,  5.17it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  54%|█████▍    | 198/367 [00:34<00:29,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  54%|█████▍    | 199/367 [00:35<00:29,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  54%|█████▍    | 200/367 [00:35<00:30,  5.46it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  55%|█████▍    | 201/367 [00:35<00:30,  5.40it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  55%|█████▌    | 202/367 [00:35<00:32,  5.11it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  55%|█████▌    | 203/367 [00:35<00:32,  4.98it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  56%|█████▌    | 204/367 [00:36<00:31,  5.25it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  56%|█████▌    | 205/367 [00:36<00:32,  5.06it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  56%|█████▌    | 206/367 [00:36<00:31,  5.09it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  56%|█████▋    | 207/367 [00:36<00:29,  5.34it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  57%|█████▋    | 208/367 [00:36<00:31,  5.08it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  57%|█████▋    | 209/367 [00:37<00:29,  5.35it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  57%|█████▋    | 210/367 [00:37<00:28,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  57%|█████▋    | 211/367 [00:37<00:27,  5.76it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3955 || acc: 84.38% || lr 7.915e-06:  58%|█████▊    | 212/367 [00:37<00:24,  6.40it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  58%|█████▊    | 212/367 [00:37<00:24,  6.40it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  58%|█████▊    | 213/367 [00:37<00:27,  5.57it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  58%|█████▊    | 214/367 [00:37<00:28,  5.38it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  59%|█████▊    | 215/367 [00:38<00:28,  5.37it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  59%|█████▉    | 216/367 [00:38<00:26,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  59%|█████▉    | 217/367 [00:38<00:27,  5.37it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  59%|█████▉    | 218/367 [00:38<00:26,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  60%|█████▉    | 219/367 [00:38<00:28,  5.22it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  60%|█████▉    | 220/367 [00:39<00:26,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  60%|██████    | 221/367 [00:39<00:26,  5.60it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  60%|██████    | 222/367 [00:39<00:26,  5.57it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  61%|██████    | 223/367 [00:39<00:25,  5.55it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  61%|██████    | 224/367 [00:39<00:25,  5.55it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  61%|██████▏   | 225/367 [00:39<00:25,  5.61it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  62%|██████▏   | 226/367 [00:40<00:24,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  62%|██████▏   | 227/367 [00:40<00:25,  5.43it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  62%|██████▏   | 228/367 [00:40<00:27,  5.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  62%|██████▏   | 229/367 [00:40<00:26,  5.19it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  63%|██████▎   | 230/367 [00:40<00:26,  5.19it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  63%|██████▎   | 231/367 [00:41<00:24,  5.66it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3606 || acc: 82.50% || lr 7.914e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.61it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.61it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  63%|██████▎   | 233/367 [00:41<00:23,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  64%|██████▍   | 234/367 [00:41<00:22,  5.99it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  64%|██████▍   | 235/367 [00:41<00:22,  5.90it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  64%|██████▍   | 236/367 [00:41<00:23,  5.68it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  65%|██████▍   | 237/367 [00:42<00:21,  6.07it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  65%|██████▍   | 238/367 [00:42<00:23,  5.49it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  65%|██████▌   | 239/367 [00:42<00:22,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  65%|██████▌   | 240/367 [00:42<00:22,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  66%|██████▌   | 241/367 [00:42<00:22,  5.55it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  66%|██████▌   | 242/367 [00:42<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  66%|██████▌   | 243/367 [00:43<00:21,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  66%|██████▋   | 244/367 [00:43<00:21,  5.71it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  67%|██████▋   | 245/367 [00:43<00:21,  5.60it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  67%|██████▋   | 246/367 [00:43<00:21,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  67%|██████▋   | 247/367 [00:43<00:21,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  68%|██████▊   | 248/367 [00:44<00:20,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  68%|██████▊   | 249/367 [00:44<00:20,  5.79it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  68%|██████▊   | 250/367 [00:44<00:20,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  68%|██████▊   | 251/367 [00:44<00:21,  5.38it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3374 || acc: 87.50% || lr 7.912e-06:  69%|██████▊   | 252/367 [00:44<00:22,  5.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  69%|██████▊   | 252/367 [00:44<00:22,  5.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  69%|██████▉   | 253/367 [00:44<00:20,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  69%|██████▉   | 254/367 [00:45<00:18,  5.97it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  69%|██████▉   | 255/367 [00:45<00:19,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  70%|██████▉   | 256/367 [00:45<00:19,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  70%|███████   | 257/367 [00:45<00:19,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  70%|███████   | 258/367 [00:45<00:19,  5.46it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  71%|███████   | 259/367 [00:46<00:19,  5.47it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  71%|███████   | 260/367 [00:46<00:19,  5.44it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  71%|███████   | 261/367 [00:46<00:19,  5.53it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  71%|███████▏  | 262/367 [00:46<00:20,  5.20it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  72%|███████▏  | 263/367 [00:46<00:19,  5.27it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.48it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  72%|███████▏  | 265/367 [00:47<00:18,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  73%|███████▎  | 267/367 [00:47<00:18,  5.32it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  73%|███████▎  | 268/367 [00:47<00:18,  5.39it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  73%|███████▎  | 269/367 [00:47<00:18,  5.22it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  74%|███████▎  | 270/367 [00:48<00:18,  5.25it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  74%|███████▍  | 271/367 [00:48<00:16,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3401 || acc: 85.00% || lr 7.911e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.90it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.90it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  74%|███████▍  | 273/367 [00:48<00:17,  5.45it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  75%|███████▍  | 274/367 [00:48<00:16,  5.53it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  75%|███████▍  | 275/367 [00:48<00:16,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  75%|███████▌  | 276/367 [00:49<00:17,  5.09it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  75%|███████▌  | 277/367 [00:49<00:17,  5.15it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  76%|███████▌  | 278/367 [00:49<00:15,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  76%|███████▌  | 279/367 [00:49<00:15,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  76%|███████▋  | 280/367 [00:49<00:15,  5.68it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  77%|███████▋  | 281/367 [00:50<00:14,  6.07it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  77%|███████▋  | 282/367 [00:50<00:14,  6.04it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  77%|███████▋  | 283/367 [00:50<00:13,  6.00it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  77%|███████▋  | 284/367 [00:50<00:13,  5.95it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  78%|███████▊  | 285/367 [00:50<00:14,  5.75it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  78%|███████▊  | 286/367 [00:50<00:14,  5.74it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  78%|███████▊  | 287/367 [00:51<00:13,  5.99it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  78%|███████▊  | 288/367 [00:51<00:13,  5.75it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  79%|███████▉  | 290/367 [00:51<00:14,  5.38it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  79%|███████▉  | 291/367 [00:51<00:14,  5.16it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.2963 || acc: 89.38% || lr 7.909e-06:  80%|███████▉  | 292/367 [00:52<00:14,  5.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  80%|███████▉  | 292/367 [00:52<00:14,  5.30it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  80%|███████▉  | 293/367 [00:52<00:13,  5.61it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  80%|████████  | 294/367 [00:52<00:12,  5.70it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  80%|████████  | 295/367 [00:52<00:12,  5.94it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  81%|████████  | 296/367 [00:52<00:12,  5.65it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  81%|████████  | 297/367 [00:52<00:12,  5.60it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  81%|████████  | 298/367 [00:53<00:12,  5.63it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  81%|████████▏ | 299/367 [00:53<00:11,  5.92it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  82%|████████▏ | 300/367 [00:53<00:11,  5.90it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  82%|████████▏ | 301/367 [00:53<00:11,  5.83it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  82%|████████▏ | 302/367 [00:53<00:11,  5.83it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  83%|████████▎ | 303/367 [00:53<00:10,  5.91it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  83%|████████▎ | 304/367 [00:54<00:11,  5.68it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  83%|████████▎ | 305/367 [00:54<00:09,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  83%|████████▎ | 306/367 [00:54<00:09,  6.48it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  84%|████████▎ | 307/367 [00:54<00:09,  6.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  84%|████████▍ | 308/367 [00:54<00:09,  6.25it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  84%|████████▍ | 309/367 [00:54<00:09,  6.14it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  84%|████████▍ | 310/367 [00:54<00:09,  6.26it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3292 || acc: 85.00% || lr 7.908e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.98it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.98it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.81it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  86%|████████▌ | 314/367 [00:55<00:09,  5.89it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  86%|████████▌ | 315/367 [00:55<00:09,  5.75it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.38it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  86%|████████▋ | 317/367 [00:56<00:09,  5.36it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.84it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  87%|████████▋ | 319/367 [00:56<00:08,  5.80it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  87%|████████▋ | 320/367 [00:56<00:07,  6.03it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  87%|████████▋ | 321/367 [00:56<00:08,  5.41it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.27it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  88%|████████▊ | 323/367 [00:57<00:08,  5.29it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  88%|████████▊ | 324/367 [00:57<00:08,  5.28it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  89%|████████▊ | 325/367 [00:57<00:08,  5.03it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  89%|████████▉ | 326/367 [00:57<00:07,  5.38it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.35it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  89%|████████▉ | 328/367 [00:58<00:07,  5.11it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  90%|████████▉ | 329/367 [00:58<00:07,  5.09it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  90%|████████▉ | 330/367 [00:58<00:07,  5.12it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.47it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3683 || acc: 84.38% || lr 7.906e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.45it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.45it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.64it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  91%|█████████ | 334/367 [00:59<00:05,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.64it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  92%|█████████▏| 337/367 [00:59<00:05,  5.81it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  92%|█████████▏| 338/367 [01:00<00:05,  5.77it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  92%|█████████▏| 339/367 [01:00<00:05,  5.39it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.94it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.69it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  93%|█████████▎| 342/367 [01:00<00:04,  6.06it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  93%|█████████▎| 343/367 [01:00<00:04,  5.78it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  94%|█████████▎| 344/367 [01:01<00:03,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  94%|█████████▍| 345/367 [01:01<00:03,  6.17it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.97it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.97it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  95%|█████████▍| 348/367 [01:01<00:03,  5.67it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  95%|█████████▌| 349/367 [01:01<00:03,  5.62it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  95%|█████████▌| 350/367 [01:02<00:02,  5.88it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.86it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.4366 || acc: 79.38% || lr 7.905e-06:  96%|█████████▌| 352/367 [01:02<00:02,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  96%|█████████▌| 352/367 [01:02<00:02,  6.21it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  96%|█████████▌| 353/367 [01:02<00:02,  6.18it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  96%|█████████▋| 354/367 [01:02<00:01,  6.51it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  97%|█████████▋| 355/367 [01:02<00:02,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.59it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.50it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  98%|█████████▊| 359/367 [01:03<00:01,  5.52it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  98%|█████████▊| 360/367 [01:03<00:01,  5.11it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  98%|█████████▊| 361/367 [01:04<00:01,  4.94it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.17it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.33it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06:  99%|█████████▉| 365/367 [01:04<00:00,  5.49it/s]\u001b[A\n",
      "Epoch: [4/30] || loss: 0.3412 || acc: 87.50% || lr 7.904e-06: 100%|██████████| 367/367 [01:05<00:00,  5.64it/s]\n",
      "\n",
      "[Validation] Epoch 5:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 5:   3%|▎         | 3/92 [00:00<00:04, 21.54it/s]\u001b[A\n",
      "[Validation] Epoch 5:   7%|▋         | 6/92 [00:00<00:04, 21.17it/s]\u001b[A\n",
      "[Validation] Epoch 5:  10%|▉         | 9/92 [00:00<00:04, 19.33it/s]\u001b[A\n",
      "[Validation] Epoch 5:  12%|█▏        | 11/92 [00:00<00:04, 18.44it/s]\u001b[A\n",
      "[Validation] Epoch 5:  14%|█▍        | 13/92 [00:00<00:04, 18.03it/s]\u001b[A\n",
      "[Validation] Epoch 5:  16%|█▋        | 15/92 [00:00<00:04, 17.76it/s]\u001b[A\n",
      "[Validation] Epoch 5:  20%|█▉        | 18/92 [00:00<00:04, 18.28it/s]\u001b[A\n",
      "[Validation] Epoch 5:  22%|██▏       | 20/92 [00:01<00:03, 18.36it/s]\u001b[A\n",
      "[Validation] Epoch 5:  24%|██▍       | 22/92 [00:01<00:03, 17.77it/s]\u001b[A\n",
      "[Validation] Epoch 5:  26%|██▌       | 24/92 [00:01<00:03, 17.91it/s]\u001b[A\n",
      "[Validation] Epoch 5:  28%|██▊       | 26/92 [00:01<00:03, 17.70it/s]\u001b[A\n",
      "[Validation] Epoch 5:  30%|███       | 28/92 [00:01<00:03, 17.75it/s]\u001b[A\n",
      "[Validation] Epoch 5:  33%|███▎      | 30/92 [00:01<00:03, 17.76it/s]\u001b[A\n",
      "[Validation] Epoch 5:  35%|███▍      | 32/92 [00:01<00:03, 17.25it/s]\u001b[A\n",
      "[Validation] Epoch 5:  37%|███▋      | 34/92 [00:01<00:03, 17.09it/s]\u001b[A\n",
      "[Validation] Epoch 5:  39%|███▉      | 36/92 [00:01<00:03, 17.62it/s]\u001b[A\n",
      "[Validation] Epoch 5:  41%|████▏     | 38/92 [00:02<00:03, 17.50it/s]\u001b[A\n",
      "[Validation] Epoch 5:  43%|████▎     | 40/92 [00:02<00:02, 17.70it/s]\u001b[A\n",
      "[Validation] Epoch 5:  46%|████▌     | 42/92 [00:02<00:02, 17.64it/s]\u001b[A\n",
      "[Validation] Epoch 5:  48%|████▊     | 44/92 [00:02<00:02, 17.97it/s]\u001b[A\n",
      "[Validation] Epoch 5:  50%|█████     | 46/92 [00:02<00:02, 17.28it/s]\u001b[A\n",
      "[Validation] Epoch 5:  52%|█████▏    | 48/92 [00:02<00:02, 17.01it/s]\u001b[A\n",
      "[Validation] Epoch 5:  54%|█████▍    | 50/92 [00:02<00:02, 17.60it/s]\u001b[A\n",
      "[Validation] Epoch 5:  57%|█████▋    | 52/92 [00:02<00:02, 17.33it/s]\u001b[A\n",
      "[Validation] Epoch 5:  59%|█████▊    | 54/92 [00:03<00:02, 17.55it/s]\u001b[A\n",
      "[Validation] Epoch 5:  61%|██████    | 56/92 [00:03<00:02, 17.72it/s]\u001b[A\n",
      "[Validation] Epoch 5:  63%|██████▎   | 58/92 [00:03<00:01, 18.07it/s]\u001b[A\n",
      "[Validation] Epoch 5:  66%|██████▋   | 61/92 [00:03<00:01, 18.14it/s]\u001b[A\n",
      "[Validation] Epoch 5:  68%|██████▊   | 63/92 [00:03<00:01, 17.51it/s]\u001b[A\n",
      "[Validation] Epoch 5:  71%|███████   | 65/92 [00:03<00:01, 17.56it/s]\u001b[A\n",
      "[Validation] Epoch 5:  73%|███████▎  | 67/92 [00:03<00:01, 17.79it/s]\u001b[A\n",
      "[Validation] Epoch 5:  75%|███████▌  | 69/92 [00:03<00:01, 18.07it/s]\u001b[A\n",
      "[Validation] Epoch 5:  77%|███████▋  | 71/92 [00:03<00:01, 18.20it/s]\u001b[A\n",
      "[Validation] Epoch 5:  80%|████████  | 74/92 [00:04<00:00, 18.70it/s]\u001b[A\n",
      "[Validation] Epoch 5:  83%|████████▎ | 76/92 [00:04<00:00, 17.69it/s]\u001b[A\n",
      "[Validation] Epoch 5:  85%|████████▍ | 78/92 [00:04<00:00, 18.17it/s]\u001b[A\n",
      "[Validation] Epoch 5:  87%|████████▋ | 80/92 [00:04<00:00, 17.84it/s]\u001b[A\n",
      "[Validation] Epoch 5:  90%|█████████ | 83/92 [00:04<00:00, 18.52it/s]\u001b[A\n",
      "[Validation] Epoch 5:  92%|█████████▏| 85/92 [00:04<00:00, 18.48it/s]\u001b[A\n",
      "[Validation] Epoch 5:  95%|█████████▍| 87/92 [00:04<00:00, 17.48it/s]\u001b[A\n",
      "[Validation] Epoch 5:  97%|█████████▋| 89/92 [00:04<00:00, 17.36it/s]\u001b[A\n",
      "[Validation] Epoch 5:  99%|█████████▉| 91/92 [00:05<00:00, 17.53it/s]\u001b[A\n",
      "Validation: [4/30] || loss: 0.2579 || acc: 89.67%: 100%|██████████| 92/92 [00:05<00:00, 17.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.8967391304347826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 17%|█▋        | 5/30 [06:02<30:14, 72.58s/it]\n",
      "[Training] Epoch 6:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 6:   0%|          | 1/367 [00:00<01:29,  4.10it/s]\u001b[A\n",
      "[Training] Epoch 6:   1%|          | 2/367 [00:00<01:11,  5.09it/s]\u001b[A\n",
      "[Training] Epoch 6:   1%|          | 3/367 [00:00<01:14,  4.90it/s]\u001b[A\n",
      "[Training] Epoch 6:   1%|          | 4/367 [00:00<01:14,  4.88it/s]\u001b[A\n",
      "[Training] Epoch 6:   1%|▏         | 5/367 [00:01<01:12,  5.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   1%|▏         | 5/367 [00:01<01:12,  5.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   2%|▏         | 6/367 [00:01<01:12,  4.98it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   2%|▏         | 7/367 [00:01<01:11,  5.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   2%|▏         | 8/367 [00:01<01:07,  5.30it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   2%|▏         | 9/367 [00:01<01:08,  5.22it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   3%|▎         | 10/367 [00:01<01:05,  5.46it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   3%|▎         | 11/367 [00:02<01:05,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   3%|▎         | 12/367 [00:02<01:06,  5.33it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   4%|▎         | 13/367 [00:02<01:06,  5.29it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   4%|▍         | 14/367 [00:02<01:06,  5.28it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   4%|▍         | 15/367 [00:02<01:05,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   4%|▍         | 16/367 [00:03<01:07,  5.22it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   5%|▍         | 17/367 [00:03<01:05,  5.32it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   5%|▍         | 18/367 [00:03<01:07,  5.16it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   5%|▌         | 19/367 [00:03<01:09,  4.98it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   5%|▌         | 20/367 [00:03<01:09,  5.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   6%|▌         | 21/367 [00:04<01:06,  5.23it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   6%|▌         | 22/367 [00:04<01:09,  4.95it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   6%|▋         | 23/367 [00:04<01:10,  4.85it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   7%|▋         | 24/367 [00:04<01:05,  5.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.06717 || acc: 23.12% || lr 7.902e-06:   7%|▋         | 25/367 [00:04<01:03,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   7%|▋         | 25/367 [00:04<01:03,  5.41it/s] \u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   7%|▋         | 26/367 [00:04<01:00,  5.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   7%|▋         | 27/367 [00:05<01:01,  5.49it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   8%|▊         | 28/367 [00:05<01:05,  5.17it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   8%|▊         | 29/367 [00:05<01:07,  5.01it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   8%|▊         | 30/367 [00:05<01:06,  5.07it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   8%|▊         | 31/367 [00:06<01:06,  5.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   9%|▊         | 32/367 [00:06<01:03,  5.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   9%|▉         | 33/367 [00:06<01:01,  5.47it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:   9%|▉         | 34/367 [00:06<01:02,  5.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  10%|▉         | 35/367 [00:06<01:00,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  10%|▉         | 36/367 [00:06<00:57,  5.75it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  10%|█         | 37/367 [00:07<00:54,  6.03it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  10%|█         | 38/367 [00:07<00:55,  5.98it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  11%|█         | 39/367 [00:07<00:54,  5.97it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  11%|█         | 40/367 [00:07<00:51,  6.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  11%|█         | 41/367 [00:07<00:52,  6.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  11%|█▏        | 42/367 [00:07<00:55,  5.90it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  12%|█▏        | 43/367 [00:08<00:58,  5.54it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  12%|█▏        | 44/367 [00:08<01:00,  5.31it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3097 || acc: 86.88% || lr 7.901e-06:  12%|█▏        | 45/367 [00:08<00:59,  5.43it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  12%|█▏        | 45/367 [00:08<00:59,  5.43it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  13%|█▎        | 46/367 [00:08<00:58,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  13%|█▎        | 47/367 [00:08<00:55,  5.77it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  13%|█▎        | 48/367 [00:08<00:56,  5.64it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  13%|█▎        | 49/367 [00:09<00:55,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  14%|█▎        | 50/367 [00:09<00:57,  5.48it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  14%|█▍        | 51/367 [00:09<00:54,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  14%|█▍        | 52/367 [00:09<00:55,  5.64it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  14%|█▍        | 53/367 [00:09<00:53,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  15%|█▍        | 54/367 [00:10<00:55,  5.68it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  15%|█▍        | 55/367 [00:10<00:54,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  15%|█▌        | 56/367 [00:10<00:56,  5.50it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  16%|█▌        | 57/367 [00:10<00:52,  5.90it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  16%|█▌        | 58/367 [00:10<00:55,  5.54it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  16%|█▌        | 59/367 [00:10<00:55,  5.52it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  16%|█▋        | 60/367 [00:11<00:51,  5.99it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  17%|█▋        | 61/367 [00:11<00:56,  5.40it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  17%|█▋        | 62/367 [00:11<00:56,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  17%|█▋        | 63/367 [00:11<00:56,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  17%|█▋        | 64/367 [00:11<00:56,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2055 || acc: 93.75% || lr 7.899e-06:  18%|█▊        | 65/367 [00:12<00:55,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  18%|█▊        | 65/367 [00:12<00:55,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  18%|█▊        | 66/367 [00:12<00:54,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  18%|█▊        | 67/367 [00:12<00:56,  5.29it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  19%|█▊        | 68/367 [00:12<00:59,  5.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  19%|█▉        | 69/367 [00:12<00:59,  5.04it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  19%|█▉        | 70/367 [00:13<01:00,  4.91it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  19%|█▉        | 71/367 [00:13<00:57,  5.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  20%|█▉        | 72/367 [00:13<00:58,  5.03it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  20%|█▉        | 73/367 [00:13<00:56,  5.17it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  20%|██        | 74/367 [00:13<00:52,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  20%|██        | 75/367 [00:13<00:50,  5.74it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  21%|██        | 76/367 [00:14<00:48,  6.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  21%|██        | 77/367 [00:14<00:46,  6.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  21%|██▏       | 78/367 [00:14<00:47,  6.06it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  22%|██▏       | 79/367 [00:14<00:49,  5.81it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  22%|██▏       | 80/367 [00:14<00:50,  5.66it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  22%|██▏       | 81/367 [00:14<00:48,  5.87it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  22%|██▏       | 82/367 [00:15<00:48,  5.87it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  23%|██▎       | 83/367 [00:15<00:52,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  23%|██▎       | 84/367 [00:15<00:50,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3121 || acc: 86.25% || lr 7.898e-06:  23%|██▎       | 85/367 [00:15<00:50,  5.63it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  23%|██▎       | 85/367 [00:15<00:50,  5.63it/s] \u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  23%|██▎       | 86/367 [00:15<00:53,  5.27it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  24%|██▎       | 87/367 [00:16<00:54,  5.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  24%|██▍       | 88/367 [00:16<00:53,  5.17it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  24%|██▍       | 89/367 [00:16<00:55,  5.03it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  25%|██▍       | 90/367 [00:16<00:54,  5.06it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  25%|██▍       | 91/367 [00:16<00:55,  5.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  25%|██▌       | 92/367 [00:17<00:53,  5.13it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  25%|██▌       | 93/367 [00:17<00:53,  5.12it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  26%|██▌       | 94/367 [00:17<00:49,  5.52it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  26%|██▌       | 95/367 [00:17<00:50,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  26%|██▌       | 96/367 [00:17<00:49,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  26%|██▋       | 97/367 [00:17<00:50,  5.38it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  27%|██▋       | 98/367 [00:18<00:49,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  27%|██▋       | 99/367 [00:18<00:51,  5.20it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  27%|██▋       | 100/367 [00:18<00:47,  5.61it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  28%|██▊       | 101/367 [00:18<00:45,  5.90it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  28%|██▊       | 102/367 [00:18<00:44,  5.94it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  28%|██▊       | 103/367 [00:18<00:45,  5.75it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  28%|██▊       | 104/367 [00:19<00:47,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.241 || acc: 91.25% || lr 7.896e-06:  29%|██▊       | 105/367 [00:19<00:47,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  29%|██▊       | 105/367 [00:19<00:47,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  29%|██▉       | 106/367 [00:19<00:45,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  29%|██▉       | 107/367 [00:19<00:42,  6.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  29%|██▉       | 108/367 [00:19<00:39,  6.51it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  30%|██▉       | 109/367 [00:19<00:41,  6.16it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  30%|██▉       | 110/367 [00:20<00:41,  6.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  30%|███       | 111/367 [00:20<00:41,  6.11it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  31%|███       | 112/367 [00:20<00:47,  5.42it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  31%|███       | 113/367 [00:20<00:45,  5.58it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  31%|███       | 114/367 [00:20<00:44,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  31%|███▏      | 115/367 [00:21<00:41,  6.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  32%|███▏      | 116/367 [00:21<00:41,  6.09it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  32%|███▏      | 117/367 [00:21<00:39,  6.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  32%|███▏      | 118/367 [00:21<00:37,  6.55it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  32%|███▏      | 119/367 [00:21<00:39,  6.32it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  33%|███▎      | 120/367 [00:21<00:43,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  33%|███▎      | 121/367 [00:21<00:40,  6.01it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  33%|███▎      | 122/367 [00:22<00:39,  6.17it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  34%|███▎      | 123/367 [00:22<00:40,  5.96it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  34%|███▍      | 124/367 [00:22<00:41,  5.91it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1921 || acc: 92.50% || lr 7.895e-06:  34%|███▍      | 125/367 [00:22<00:39,  6.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  34%|███▍      | 125/367 [00:22<00:39,  6.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  34%|███▍      | 126/367 [00:22<00:40,  5.95it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  35%|███▍      | 127/367 [00:23<00:41,  5.72it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  35%|███▍      | 128/367 [00:23<00:41,  5.70it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  35%|███▌      | 129/367 [00:23<00:41,  5.73it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  35%|███▌      | 130/367 [00:23<00:45,  5.23it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  36%|███▌      | 131/367 [00:23<00:42,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  36%|███▌      | 132/367 [00:23<00:40,  5.86it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  36%|███▌      | 133/367 [00:24<00:39,  5.85it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  37%|███▋      | 134/367 [00:24<00:40,  5.81it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  37%|███▋      | 135/367 [00:24<00:40,  5.74it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  37%|███▋      | 136/367 [00:24<00:41,  5.58it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  37%|███▋      | 137/367 [00:24<00:40,  5.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  38%|███▊      | 138/367 [00:24<00:42,  5.42it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  38%|███▊      | 139/367 [00:25<00:41,  5.49it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  38%|███▊      | 140/367 [00:25<00:43,  5.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  38%|███▊      | 141/367 [00:25<00:42,  5.29it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  39%|███▊      | 142/367 [00:25<00:41,  5.48it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  39%|███▉      | 143/367 [00:25<00:38,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  39%|███▉      | 144/367 [00:26<00:41,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2215 || acc: 93.12% || lr 7.893e-06:  40%|███▉      | 145/367 [00:26<00:42,  5.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  40%|███▉      | 145/367 [00:26<00:42,  5.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  40%|███▉      | 146/367 [00:26<00:41,  5.28it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  40%|████      | 147/367 [00:26<00:37,  5.85it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  40%|████      | 148/367 [00:26<00:40,  5.46it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  41%|████      | 149/367 [00:27<00:39,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  41%|████      | 150/367 [00:27<00:37,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  41%|████      | 151/367 [00:27<00:39,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  41%|████▏     | 152/367 [00:27<00:38,  5.58it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  42%|████▏     | 153/367 [00:27<00:36,  5.88it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  42%|████▏     | 154/367 [00:27<00:34,  6.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  42%|████▏     | 155/367 [00:28<00:38,  5.50it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  43%|████▎     | 156/367 [00:28<00:40,  5.25it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  43%|████▎     | 157/367 [00:28<00:39,  5.38it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  43%|████▎     | 158/367 [00:28<00:36,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  43%|████▎     | 159/367 [00:28<00:36,  5.70it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.73it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  44%|████▍     | 161/367 [00:29<00:35,  5.79it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  44%|████▍     | 162/367 [00:29<00:35,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  44%|████▍     | 163/367 [00:29<00:36,  5.61it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  45%|████▍     | 164/367 [00:29<00:35,  5.67it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2387 || acc: 90.62% || lr 7.892e-06:  45%|████▍     | 165/367 [00:29<00:37,  5.43it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  45%|████▍     | 165/367 [00:29<00:37,  5.43it/s] \u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  45%|████▌     | 166/367 [00:30<00:37,  5.42it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  46%|████▌     | 167/367 [00:30<00:36,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  46%|████▌     | 168/367 [00:30<00:36,  5.52it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  46%|████▌     | 169/367 [00:30<00:35,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  46%|████▋     | 170/367 [00:30<00:37,  5.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  47%|████▋     | 171/367 [00:30<00:37,  5.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  47%|████▋     | 172/367 [00:31<00:36,  5.40it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  47%|████▋     | 173/367 [00:31<00:36,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  47%|████▋     | 174/367 [00:31<00:37,  5.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  48%|████▊     | 175/367 [00:31<00:36,  5.24it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  48%|████▊     | 176/367 [00:31<00:35,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  48%|████▊     | 177/367 [00:32<00:35,  5.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  49%|████▊     | 178/367 [00:32<00:34,  5.53it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  49%|████▉     | 179/367 [00:32<00:33,  5.66it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  49%|████▉     | 180/367 [00:32<00:32,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  49%|████▉     | 181/367 [00:32<00:30,  6.04it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  50%|████▉     | 182/367 [00:32<00:32,  5.73it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  50%|████▉     | 183/367 [00:33<00:34,  5.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  50%|█████     | 184/367 [00:33<00:35,  5.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2373 || acc: 92.50% || lr 7.89e-06:  50%|█████     | 185/367 [00:33<00:34,  5.31it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  50%|█████     | 185/367 [00:33<00:34,  5.31it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  51%|█████     | 186/367 [00:33<00:32,  5.58it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  51%|█████     | 187/367 [00:33<00:30,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  51%|█████     | 188/367 [00:33<00:29,  6.06it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  51%|█████▏    | 189/367 [00:34<00:31,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  52%|█████▏    | 190/367 [00:34<00:30,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  52%|█████▏    | 191/367 [00:34<00:30,  5.84it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  52%|█████▏    | 192/367 [00:34<00:30,  5.69it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  53%|█████▎    | 193/367 [00:34<00:31,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  53%|█████▎    | 194/367 [00:35<00:33,  5.13it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  53%|█████▎    | 195/367 [00:35<00:32,  5.29it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  53%|█████▎    | 196/367 [00:35<00:31,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  54%|█████▎    | 197/367 [00:35<00:28,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  54%|█████▍    | 198/367 [00:35<00:27,  6.23it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  54%|█████▍    | 199/367 [00:35<00:26,  6.38it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  54%|█████▍    | 200/367 [00:36<00:27,  5.96it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  55%|█████▍    | 201/367 [00:36<00:28,  5.77it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  55%|█████▌    | 202/367 [00:36<00:28,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  55%|█████▌    | 203/367 [00:36<00:29,  5.64it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  56%|█████▌    | 204/367 [00:36<00:27,  5.85it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1494 || acc: 95.00% || lr 7.889e-06:  56%|█████▌    | 205/367 [00:37<00:30,  5.34it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  56%|█████▌    | 205/367 [00:37<00:30,  5.34it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  56%|█████▌    | 206/367 [00:37<00:28,  5.60it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  56%|█████▋    | 207/367 [00:37<00:29,  5.47it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  57%|█████▋    | 208/367 [00:37<00:31,  5.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  57%|█████▋    | 209/367 [00:37<00:29,  5.28it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  57%|█████▋    | 210/367 [00:37<00:28,  5.46it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  57%|█████▋    | 211/367 [00:38<00:27,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  58%|█████▊    | 212/367 [00:38<00:27,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  58%|█████▊    | 213/367 [00:38<00:26,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  58%|█████▊    | 214/367 [00:38<00:25,  5.91it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  59%|█████▊    | 215/367 [00:38<00:26,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  59%|█████▉    | 216/367 [00:38<00:25,  6.02it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  59%|█████▉    | 217/367 [00:39<00:26,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  59%|█████▉    | 218/367 [00:39<00:26,  5.67it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  60%|█████▉    | 219/367 [00:39<00:25,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  60%|█████▉    | 220/367 [00:39<00:25,  5.86it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  60%|██████    | 221/367 [00:39<00:25,  5.66it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  60%|██████    | 222/367 [00:39<00:23,  6.09it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  61%|██████    | 223/367 [00:40<00:23,  6.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  61%|██████    | 224/367 [00:40<00:22,  6.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2468 || acc: 91.25% || lr 7.887e-06:  61%|██████▏   | 225/367 [00:40<00:24,  5.86it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  61%|██████▏   | 225/367 [00:40<00:24,  5.86it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  62%|██████▏   | 226/367 [00:40<00:24,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  62%|██████▏   | 227/367 [00:40<00:23,  6.04it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  62%|██████▏   | 228/367 [00:40<00:23,  5.91it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  62%|██████▏   | 229/367 [00:41<00:25,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  63%|██████▎   | 230/367 [00:41<00:26,  5.10it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  63%|██████▎   | 231/367 [00:41<00:23,  5.67it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  63%|██████▎   | 232/367 [00:41<00:22,  5.93it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  63%|██████▎   | 233/367 [00:41<00:21,  6.13it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  64%|██████▍   | 234/367 [00:42<00:24,  5.32it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  64%|██████▍   | 235/367 [00:42<00:24,  5.37it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  64%|██████▍   | 236/367 [00:42<00:23,  5.53it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  65%|██████▍   | 237/367 [00:42<00:23,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  65%|██████▍   | 238/367 [00:42<00:22,  5.84it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  65%|██████▌   | 239/367 [00:43<00:23,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  65%|██████▌   | 240/367 [00:43<00:23,  5.49it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  66%|██████▌   | 241/367 [00:43<00:22,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  66%|██████▌   | 242/367 [00:43<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  66%|██████▌   | 243/367 [00:43<00:22,  5.50it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  66%|██████▋   | 244/367 [00:43<00:22,  5.51it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1524 || acc: 94.38% || lr 7.886e-06:  67%|██████▋   | 245/367 [00:44<00:21,  5.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  67%|██████▋   | 245/367 [00:44<00:21,  5.62it/s] \u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  67%|██████▋   | 246/367 [00:44<00:22,  5.45it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  67%|██████▋   | 247/367 [00:44<00:21,  5.49it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  68%|██████▊   | 248/367 [00:44<00:22,  5.23it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  68%|██████▊   | 249/367 [00:44<00:22,  5.23it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  68%|██████▊   | 250/367 [00:45<00:22,  5.10it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  68%|██████▊   | 251/367 [00:45<00:22,  5.26it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  69%|██████▊   | 252/367 [00:45<00:21,  5.46it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  69%|██████▉   | 253/367 [00:45<00:20,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  69%|██████▉   | 254/367 [00:45<00:19,  5.93it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  69%|██████▉   | 255/367 [00:45<00:18,  5.99it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  70%|██████▉   | 256/367 [00:46<00:17,  6.24it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  70%|███████   | 257/367 [00:46<00:16,  6.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  70%|███████   | 258/367 [00:46<00:17,  6.22it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  71%|███████   | 259/367 [00:46<00:20,  5.20it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  71%|███████   | 260/367 [00:46<00:19,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  71%|███████   | 261/367 [00:46<00:19,  5.52it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  71%|███████▏  | 262/367 [00:47<00:19,  5.46it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  72%|███████▏  | 263/367 [00:47<00:20,  5.07it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  72%|███████▏  | 264/367 [00:47<00:18,  5.57it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.243 || acc: 90.62% || lr 7.885e-06:  72%|███████▏  | 265/367 [00:47<00:19,  5.27it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  72%|███████▏  | 265/367 [00:47<00:19,  5.27it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  72%|███████▏  | 266/367 [00:47<00:18,  5.55it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  73%|███████▎  | 267/367 [00:48<00:17,  5.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  73%|███████▎  | 268/367 [00:48<00:17,  5.51it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  73%|███████▎  | 269/367 [00:48<00:16,  5.93it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  74%|███████▎  | 270/367 [00:48<00:16,  5.99it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  74%|███████▍  | 271/367 [00:48<00:16,  5.76it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  74%|███████▍  | 273/367 [00:49<00:16,  5.63it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  75%|███████▍  | 274/367 [00:49<00:15,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  75%|███████▍  | 275/367 [00:49<00:15,  5.77it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  75%|███████▌  | 276/367 [00:49<00:15,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.61it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  76%|███████▌  | 278/367 [00:50<00:17,  5.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  76%|███████▌  | 279/367 [00:50<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  76%|███████▋  | 280/367 [00:50<00:16,  5.31it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  77%|███████▋  | 281/367 [00:50<00:16,  5.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  77%|███████▋  | 282/367 [00:50<00:14,  5.82it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  77%|███████▋  | 283/367 [00:50<00:14,  5.64it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  77%|███████▋  | 284/367 [00:51<00:15,  5.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.294 || acc: 88.12% || lr 7.883e-06:  78%|███████▊  | 285/367 [00:51<00:15,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  78%|███████▊  | 285/367 [00:51<00:15,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  78%|███████▊  | 286/367 [00:51<00:14,  5.40it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  78%|███████▊  | 287/367 [00:51<00:13,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  78%|███████▊  | 288/367 [00:51<00:13,  5.91it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  79%|███████▊  | 289/367 [00:51<00:14,  5.47it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  79%|███████▉  | 290/367 [00:52<00:14,  5.25it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  79%|███████▉  | 291/367 [00:52<00:14,  5.09it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  80%|███████▉  | 292/367 [00:52<00:13,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  80%|███████▉  | 293/367 [00:52<00:12,  5.84it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  80%|████████  | 294/367 [00:52<00:12,  5.83it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  80%|████████  | 295/367 [00:52<00:11,  6.21it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  81%|████████  | 296/367 [00:53<00:11,  6.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  81%|████████  | 297/367 [00:53<00:11,  5.84it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  81%|████████  | 298/367 [00:53<00:12,  5.60it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  81%|████████▏ | 299/367 [00:53<00:12,  5.64it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  82%|████████▏ | 300/367 [00:53<00:12,  5.35it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  82%|████████▏ | 301/367 [00:54<00:12,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  82%|████████▏ | 302/367 [00:54<00:12,  5.39it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  83%|████████▎ | 303/367 [00:54<00:11,  5.58it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  83%|████████▎ | 304/367 [00:54<00:12,  5.21it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1939 || acc: 93.12% || lr 7.882e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.36it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.36it/s] \u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  83%|████████▎ | 306/367 [00:55<00:10,  5.74it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  84%|████████▎ | 307/367 [00:55<00:10,  5.60it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  84%|████████▍ | 308/367 [00:55<00:10,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  84%|████████▍ | 309/367 [00:55<00:11,  5.24it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  85%|████████▍ | 311/367 [00:55<00:10,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  85%|████████▌ | 312/367 [00:56<00:10,  5.40it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  85%|████████▌ | 313/367 [00:56<00:10,  5.30it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  86%|████████▌ | 314/367 [00:56<00:09,  5.30it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.38it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  86%|████████▌ | 316/367 [00:56<00:08,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  86%|████████▋ | 317/367 [00:56<00:08,  6.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  87%|████████▋ | 318/367 [00:57<00:08,  5.71it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  87%|████████▋ | 319/367 [00:57<00:08,  5.73it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  87%|████████▋ | 320/367 [00:57<00:08,  5.82it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  87%|████████▋ | 321/367 [00:57<00:07,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  88%|████████▊ | 322/367 [00:57<00:07,  5.80it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  88%|████████▊ | 323/367 [00:58<00:07,  5.86it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  88%|████████▊ | 324/367 [00:58<00:06,  6.25it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.1923 || acc: 93.12% || lr 7.88e-06:  89%|████████▊ | 325/367 [00:58<00:07,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  89%|████████▊ | 325/367 [00:58<00:07,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  89%|████████▉ | 326/367 [00:58<00:06,  6.19it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  89%|████████▉ | 327/367 [00:58<00:06,  5.76it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  89%|████████▉ | 328/367 [00:58<00:06,  5.70it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  90%|████████▉ | 329/367 [00:59<00:06,  5.99it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  90%|████████▉ | 330/367 [00:59<00:06,  5.59it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  90%|█████████ | 331/367 [00:59<00:07,  5.14it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.24it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.60it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  91%|█████████ | 334/367 [00:59<00:05,  5.56it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  91%|█████████▏| 335/367 [01:00<00:05,  5.44it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  92%|█████████▏| 336/367 [01:00<00:05,  5.76it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.62it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  92%|█████████▏| 338/367 [01:00<00:04,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  92%|█████████▏| 339/367 [01:00<00:04,  5.72it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  93%|█████████▎| 340/367 [01:01<00:04,  5.68it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  93%|█████████▎| 341/367 [01:01<00:04,  5.95it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  93%|█████████▎| 342/367 [01:01<00:04,  6.00it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  93%|█████████▎| 343/367 [01:01<00:03,  6.20it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  94%|█████████▎| 344/367 [01:01<00:03,  5.75it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2422 || acc: 91.25% || lr 7.879e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.34it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.34it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  94%|█████████▍| 346/367 [01:02<00:03,  5.34it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  95%|█████████▍| 347/367 [01:02<00:03,  5.42it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.52it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.53it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.53it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.54it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  96%|█████████▌| 352/367 [01:03<00:02,  5.42it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  96%|█████████▌| 353/367 [01:03<00:02,  5.78it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.81it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  97%|█████████▋| 355/367 [01:03<00:01,  6.04it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  97%|█████████▋| 356/367 [01:03<00:01,  6.15it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  97%|█████████▋| 357/367 [01:03<00:01,  6.32it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  98%|█████████▊| 358/367 [01:04<00:01,  6.41it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  98%|█████████▊| 359/367 [01:04<00:01,  6.20it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  98%|█████████▊| 360/367 [01:04<00:01,  6.08it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  98%|█████████▊| 361/367 [01:04<00:00,  6.17it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  99%|█████████▊| 362/367 [01:04<00:00,  6.01it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  99%|█████████▉| 363/367 [01:04<00:00,  6.05it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  99%|█████████▉| 364/367 [01:05<00:00,  5.89it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.2482 || acc: 91.25% || lr 7.877e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.95it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3229 || acc: 82.50% || lr 7.876e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.95it/s]\u001b[A\n",
      "Epoch: [5/30] || loss: 0.3229 || acc: 82.50% || lr 7.876e-06: 100%|██████████| 367/367 [01:05<00:00,  5.60it/s]\n",
      "\n",
      "[Validation] Epoch 6:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 6:   3%|▎         | 3/92 [00:00<00:03, 24.11it/s]\u001b[A\n",
      "[Validation] Epoch 6:   7%|▋         | 6/92 [00:00<00:04, 19.23it/s]\u001b[A\n",
      "[Validation] Epoch 6:   9%|▊         | 8/92 [00:00<00:04, 17.88it/s]\u001b[A\n",
      "[Validation] Epoch 6:  11%|█         | 10/92 [00:00<00:04, 18.23it/s]\u001b[A\n",
      "[Validation] Epoch 6:  13%|█▎        | 12/92 [00:00<00:04, 17.74it/s]\u001b[A\n",
      "[Validation] Epoch 6:  15%|█▌        | 14/92 [00:00<00:04, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 6:  17%|█▋        | 16/92 [00:00<00:04, 18.27it/s]\u001b[A\n",
      "[Validation] Epoch 6:  21%|██        | 19/92 [00:01<00:03, 18.91it/s]\u001b[A\n",
      "[Validation] Epoch 6:  23%|██▎       | 21/92 [00:01<00:03, 18.67it/s]\u001b[A\n",
      "[Validation] Epoch 6:  25%|██▌       | 23/92 [00:01<00:03, 18.76it/s]\u001b[A\n",
      "[Validation] Epoch 6:  27%|██▋       | 25/92 [00:01<00:03, 18.55it/s]\u001b[A\n",
      "[Validation] Epoch 6:  29%|██▉       | 27/92 [00:01<00:03, 17.29it/s]\u001b[A\n",
      "[Validation] Epoch 6:  32%|███▏      | 29/92 [00:01<00:03, 17.77it/s]\u001b[A\n",
      "[Validation] Epoch 6:  34%|███▎      | 31/92 [00:01<00:03, 17.51it/s]\u001b[A\n",
      "[Validation] Epoch 6:  37%|███▋      | 34/92 [00:01<00:03, 18.83it/s]\u001b[A\n",
      "[Validation] Epoch 6:  40%|████      | 37/92 [00:02<00:02, 18.90it/s]\u001b[A\n",
      "[Validation] Epoch 6:  42%|████▏     | 39/92 [00:02<00:02, 18.15it/s]\u001b[A\n",
      "[Validation] Epoch 6:  45%|████▍     | 41/92 [00:02<00:02, 18.35it/s]\u001b[A\n",
      "[Validation] Epoch 6:  47%|████▋     | 43/92 [00:02<00:02, 17.97it/s]\u001b[A\n",
      "[Validation] Epoch 6:  49%|████▉     | 45/92 [00:02<00:02, 17.49it/s]\u001b[A\n",
      "[Validation] Epoch 6:  51%|█████     | 47/92 [00:02<00:02, 17.96it/s]\u001b[A\n",
      "[Validation] Epoch 6:  54%|█████▍    | 50/92 [00:02<00:02, 19.18it/s]\u001b[A\n",
      "[Validation] Epoch 6:  58%|█████▊    | 53/92 [00:02<00:01, 19.80it/s]\u001b[A\n",
      "[Validation] Epoch 6:  60%|█████▉    | 55/92 [00:02<00:01, 19.08it/s]\u001b[A\n",
      "[Validation] Epoch 6:  63%|██████▎   | 58/92 [00:03<00:01, 19.28it/s]\u001b[A\n",
      "[Validation] Epoch 6:  65%|██████▌   | 60/92 [00:03<00:01, 19.03it/s]\u001b[A\n",
      "[Validation] Epoch 6:  67%|██████▋   | 62/92 [00:03<00:01, 18.59it/s]\u001b[A\n",
      "[Validation] Epoch 6:  70%|██████▉   | 64/92 [00:03<00:01, 17.88it/s]\u001b[A\n",
      "[Validation] Epoch 6:  73%|███████▎  | 67/92 [00:03<00:01, 18.52it/s]\u001b[A\n",
      "[Validation] Epoch 6:  75%|███████▌  | 69/92 [00:03<00:01, 18.30it/s]\u001b[A\n",
      "[Validation] Epoch 6:  77%|███████▋  | 71/92 [00:03<00:01, 18.10it/s]\u001b[A\n",
      "[Validation] Epoch 6:  80%|████████  | 74/92 [00:04<00:00, 18.59it/s]\u001b[A\n",
      "[Validation] Epoch 6:  84%|████████▎ | 77/92 [00:04<00:00, 19.38it/s]\u001b[A\n",
      "[Validation] Epoch 6:  86%|████████▌ | 79/92 [00:04<00:00, 19.36it/s]\u001b[A\n",
      "[Validation] Epoch 6:  89%|████████▉ | 82/92 [00:04<00:00, 19.95it/s]\u001b[A\n",
      "[Validation] Epoch 6:  91%|█████████▏| 84/92 [00:04<00:00, 19.49it/s]\u001b[A\n",
      "[Validation] Epoch 6:  95%|█████████▍| 87/92 [00:04<00:00, 19.91it/s]\u001b[A\n",
      "[Validation] Epoch 6:  97%|█████████▋| 89/92 [00:04<00:00, 19.69it/s]\u001b[A\n",
      "[Validation] Epoch 6:  99%|█████████▉| 91/92 [00:04<00:00, 19.40it/s]\u001b[A\n",
      "Validation: [5/30] || loss: 0.122 || acc: 95.79%: 100%|██████████| 92/92 [00:04<00:00, 18.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.9578804347826086\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 6/30 [07:15<28:59, 72.48s/it]\n",
      "[Training] Epoch 7:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 7:   0%|          | 1/367 [00:00<01:03,  5.75it/s]\u001b[A\n",
      "[Training] Epoch 7:   1%|          | 2/367 [00:00<01:05,  5.58it/s]\u001b[A\n",
      "[Training] Epoch 7:   1%|          | 3/367 [00:00<01:00,  6.02it/s]\u001b[A\n",
      "[Training] Epoch 7:   1%|          | 4/367 [00:00<01:05,  5.57it/s]\u001b[A\n",
      "[Training] Epoch 7:   1%|▏         | 5/367 [00:00<01:00,  5.94it/s]\u001b[A\n",
      "[Training] Epoch 7:   2%|▏         | 6/367 [00:01<00:59,  6.02it/s]\u001b[A\n",
      "[Training] Epoch 7:   2%|▏         | 7/367 [00:01<01:04,  5.55it/s]\u001b[A\n",
      "[Training] Epoch 7:   2%|▏         | 8/367 [00:01<00:59,  5.99it/s]\u001b[A\n",
      "[Training] Epoch 7:   2%|▏         | 9/367 [00:01<00:56,  6.34it/s]\u001b[A\n",
      "[Training] Epoch 7:   3%|▎         | 10/367 [00:01<00:58,  6.10it/s]\u001b[A\n",
      "[Training] Epoch 7:   3%|▎         | 11/367 [00:01<00:59,  6.03it/s]\u001b[A\n",
      "[Training] Epoch 7:   3%|▎         | 12/367 [00:01<00:55,  6.34it/s]\u001b[A\n",
      "[Training] Epoch 7:   4%|▎         | 13/367 [00:02<00:59,  5.99it/s]\u001b[A\n",
      "[Training] Epoch 7:   4%|▍         | 14/367 [00:02<01:01,  5.76it/s]\u001b[A\n",
      "[Training] Epoch 7:   4%|▍         | 15/367 [00:02<01:00,  5.80it/s]\u001b[A\n",
      "[Training] Epoch 7:   4%|▍         | 16/367 [00:02<01:02,  5.66it/s]\u001b[A\n",
      "[Training] Epoch 7:   5%|▍         | 17/367 [00:02<01:00,  5.78it/s]\u001b[A\n",
      "[Training] Epoch 7:   5%|▍         | 18/367 [00:03<01:01,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   5%|▍         | 18/367 [00:03<01:01,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   5%|▌         | 19/367 [00:03<01:00,  5.76it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   5%|▌         | 20/367 [00:03<00:57,  6.00it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   6%|▌         | 21/367 [00:03<01:02,  5.53it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   6%|▌         | 22/367 [00:03<01:02,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   6%|▋         | 23/367 [00:03<01:01,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   7%|▋         | 24/367 [00:04<01:02,  5.46it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   7%|▋         | 25/367 [00:04<00:58,  5.88it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   7%|▋         | 26/367 [00:04<00:53,  6.34it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   7%|▋         | 27/367 [00:04<00:58,  5.82it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   8%|▊         | 28/367 [00:04<00:56,  6.03it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   8%|▊         | 29/367 [00:04<00:54,  6.17it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   8%|▊         | 30/367 [00:05<00:55,  6.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   8%|▊         | 31/367 [00:05<00:54,  6.15it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   9%|▊         | 32/367 [00:05<00:54,  6.14it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   9%|▉         | 33/367 [00:05<00:55,  5.98it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:   9%|▉         | 34/367 [00:05<00:53,  6.21it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:  10%|▉         | 35/367 [00:05<00:58,  5.63it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:  10%|▉         | 36/367 [00:06<00:54,  6.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:  10%|█         | 37/367 [00:06<00:53,  6.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1448 || acc: 85.00% || lr 7.874e-06:  10%|█         | 38/367 [00:06<00:57,  5.75it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  10%|█         | 38/367 [00:06<00:57,  5.75it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  11%|█         | 39/367 [00:06<00:59,  5.52it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  11%|█         | 40/367 [00:06<01:00,  5.43it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  11%|█         | 41/367 [00:07<01:03,  5.10it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  11%|█▏        | 42/367 [00:07<01:06,  4.90it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  12%|█▏        | 43/367 [00:07<01:02,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  12%|█▏        | 44/367 [00:07<01:05,  4.96it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  12%|█▏        | 45/367 [00:07<01:04,  5.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  13%|█▎        | 46/367 [00:08<01:08,  4.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  13%|█▎        | 47/367 [00:08<01:05,  4.90it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  13%|█▎        | 48/367 [00:08<01:02,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  13%|█▎        | 49/367 [00:08<00:59,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  14%|█▎        | 50/367 [00:08<01:03,  5.01it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  14%|█▍        | 51/367 [00:09<01:01,  5.11it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  14%|█▍        | 52/367 [00:09<01:00,  5.20it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  14%|█▍        | 53/367 [00:09<01:01,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  15%|█▍        | 54/367 [00:09<01:02,  5.03it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  15%|█▍        | 55/367 [00:09<01:01,  5.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  15%|█▌        | 56/367 [00:10<01:01,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  16%|█▌        | 57/367 [00:10<01:00,  5.09it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1933 || acc: 93.75% || lr 7.873e-06:  16%|█▌        | 58/367 [00:10<01:00,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  16%|█▌        | 58/367 [00:10<01:00,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  16%|█▌        | 59/367 [00:10<00:58,  5.27it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  16%|█▋        | 60/367 [00:10<01:00,  5.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  17%|█▋        | 61/367 [00:11<00:59,  5.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  17%|█▋        | 62/367 [00:11<01:00,  5.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  17%|█▋        | 63/367 [00:11<00:54,  5.63it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  17%|█▋        | 64/367 [00:11<00:54,  5.54it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  18%|█▊        | 65/367 [00:11<00:54,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  18%|█▊        | 66/367 [00:11<00:53,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  18%|█▊        | 67/367 [00:12<00:57,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  19%|█▊        | 68/367 [00:12<00:55,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  19%|█▉        | 69/367 [00:12<00:55,  5.35it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  19%|█▉        | 70/367 [00:12<00:51,  5.77it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  19%|█▉        | 71/367 [00:12<00:51,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  20%|█▉        | 72/367 [00:13<00:56,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  20%|█▉        | 73/367 [00:13<00:52,  5.59it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  20%|██        | 74/367 [00:13<00:51,  5.67it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  20%|██        | 75/367 [00:13<00:52,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  21%|██        | 76/367 [00:13<00:50,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  21%|██        | 77/367 [00:13<00:46,  6.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.62% || lr 7.871e-06:  21%|██▏       | 78/367 [00:13<00:46,  6.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  21%|██▏       | 78/367 [00:13<00:46,  6.22it/s] \u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  22%|██▏       | 79/367 [00:14<00:48,  5.90it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  22%|██▏       | 80/367 [00:14<00:48,  5.87it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  22%|██▏       | 81/367 [00:14<00:48,  5.85it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  22%|██▏       | 82/367 [00:14<00:48,  5.84it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  23%|██▎       | 83/367 [00:14<00:46,  6.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  23%|██▎       | 84/367 [00:15<00:46,  6.07it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  23%|██▎       | 85/367 [00:15<00:46,  6.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  23%|██▎       | 86/367 [00:15<00:50,  5.52it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  24%|██▎       | 87/367 [00:15<00:54,  5.17it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  24%|██▍       | 88/367 [00:15<00:55,  5.03it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  24%|██▍       | 89/367 [00:15<00:53,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  25%|██▍       | 90/367 [00:16<00:49,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  25%|██▍       | 91/367 [00:16<00:47,  5.79it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  25%|██▌       | 92/367 [00:16<00:48,  5.68it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  25%|██▌       | 93/367 [00:16<00:51,  5.32it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  26%|██▌       | 94/367 [00:16<00:49,  5.47it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  26%|██▌       | 95/367 [00:17<00:47,  5.77it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  26%|██▌       | 96/367 [00:17<00:46,  5.80it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  26%|██▋       | 97/367 [00:17<00:46,  5.86it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1349 || acc: 95.00% || lr 7.87e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.91it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.91it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  27%|██▋       | 99/367 [00:17<00:47,  5.62it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  27%|██▋       | 100/367 [00:17<00:47,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  28%|██▊       | 101/367 [00:18<00:49,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  28%|██▊       | 102/367 [00:18<00:45,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  28%|██▊       | 103/367 [00:18<00:46,  5.72it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  28%|██▊       | 104/367 [00:18<00:43,  6.07it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  29%|██▊       | 105/367 [00:18<00:41,  6.25it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  29%|██▉       | 106/367 [00:18<00:42,  6.19it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  29%|██▉       | 107/367 [00:19<00:44,  5.87it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  29%|██▉       | 108/367 [00:19<00:42,  6.10it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  30%|██▉       | 109/367 [00:19<00:43,  5.93it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  30%|██▉       | 110/367 [00:19<00:43,  5.93it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  30%|███       | 111/367 [00:19<00:43,  5.88it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  31%|███       | 112/367 [00:19<00:42,  5.93it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  31%|███       | 113/367 [00:20<00:44,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  31%|███       | 114/367 [00:20<00:43,  5.76it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  31%|███▏      | 115/367 [00:20<00:44,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  32%|███▏      | 116/367 [00:20<00:46,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  32%|███▏      | 117/367 [00:20<00:48,  5.19it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1265 || acc: 95.00% || lr 7.868e-06:  32%|███▏      | 118/367 [00:21<00:49,  5.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  32%|███▏      | 118/367 [00:21<00:49,  5.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  32%|███▏      | 119/367 [00:21<00:47,  5.19it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  33%|███▎      | 120/367 [00:21<00:43,  5.68it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  33%|███▎      | 121/367 [00:21<00:45,  5.43it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  33%|███▎      | 122/367 [00:21<00:42,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  34%|███▎      | 123/367 [00:21<00:39,  6.17it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  34%|███▍      | 124/367 [00:22<00:37,  6.52it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  34%|███▍      | 125/367 [00:22<00:39,  6.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  34%|███▍      | 126/367 [00:22<00:41,  5.82it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  35%|███▍      | 127/367 [00:22<00:39,  6.03it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  35%|███▍      | 128/367 [00:22<00:41,  5.75it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  35%|███▌      | 129/367 [00:22<00:42,  5.58it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  35%|███▌      | 130/367 [00:23<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  36%|███▌      | 131/367 [00:23<00:41,  5.68it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  36%|███▌      | 132/367 [00:23<00:42,  5.57it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  36%|███▌      | 133/367 [00:23<00:41,  5.67it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  37%|███▋      | 134/367 [00:23<00:39,  5.94it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  37%|███▋      | 135/367 [00:23<00:39,  5.94it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  37%|███▋      | 136/367 [00:24<00:43,  5.35it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  37%|███▋      | 137/367 [00:24<00:43,  5.32it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.09408 || acc: 96.88% || lr 7.867e-06:  38%|███▊      | 138/367 [00:24<00:40,  5.66it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  38%|███▊      | 138/367 [00:24<00:40,  5.66it/s]  \u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  38%|███▊      | 139/367 [00:24<00:38,  5.94it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  38%|███▊      | 140/367 [00:24<00:37,  6.10it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  38%|███▊      | 141/367 [00:25<00:37,  6.03it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  39%|███▊      | 142/367 [00:25<00:36,  6.24it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  39%|███▉      | 143/367 [00:25<00:37,  5.90it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  39%|███▉      | 144/367 [00:25<00:39,  5.72it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  40%|███▉      | 145/367 [00:25<00:39,  5.66it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  40%|███▉      | 146/367 [00:25<00:39,  5.53it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  40%|████      | 147/367 [00:26<00:42,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  40%|████      | 148/367 [00:26<00:40,  5.46it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  41%|████      | 149/367 [00:26<00:39,  5.54it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  41%|████      | 150/367 [00:26<00:39,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  41%|████      | 151/367 [00:26<00:35,  6.12it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  41%|████▏     | 152/367 [00:26<00:34,  6.29it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  42%|████▏     | 153/367 [00:27<00:33,  6.40it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  42%|████▏     | 154/367 [00:27<00:36,  5.82it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  42%|████▏     | 155/367 [00:27<00:34,  6.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  43%|████▎     | 156/367 [00:27<00:37,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  43%|████▎     | 157/367 [00:27<00:40,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.126 || acc: 96.25% || lr 7.866e-06:  43%|████▎     | 158/367 [00:27<00:37,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  43%|████▎     | 158/367 [00:28<00:37,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  43%|████▎     | 159/367 [00:28<00:36,  5.77it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.73it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  44%|████▍     | 161/367 [00:28<00:35,  5.84it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  44%|████▍     | 162/367 [00:28<00:35,  5.70it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  44%|████▍     | 163/367 [00:28<00:32,  6.25it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  45%|████▍     | 164/367 [00:29<00:34,  5.89it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  45%|████▍     | 165/367 [00:29<00:32,  6.20it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  45%|████▌     | 166/367 [00:29<00:38,  5.26it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  46%|████▌     | 167/367 [00:29<00:39,  5.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  46%|████▌     | 168/367 [00:29<00:39,  5.08it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  46%|████▌     | 169/367 [00:29<00:37,  5.35it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  46%|████▋     | 170/367 [00:30<00:39,  5.00it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  47%|████▋     | 171/367 [00:30<00:37,  5.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  47%|████▋     | 172/367 [00:30<00:36,  5.28it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  47%|████▋     | 173/367 [00:30<00:37,  5.16it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  47%|████▋     | 174/367 [00:30<00:37,  5.20it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  48%|████▊     | 175/367 [00:31<00:36,  5.33it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  48%|████▊     | 176/367 [00:31<00:34,  5.48it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  48%|████▊     | 177/367 [00:31<00:32,  5.86it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1281 || acc: 95.62% || lr 7.864e-06:  49%|████▊     | 178/367 [00:31<00:32,  5.76it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  49%|████▊     | 178/367 [00:31<00:32,  5.76it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  49%|████▉     | 179/367 [00:31<00:34,  5.51it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  49%|████▉     | 180/367 [00:31<00:31,  5.86it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  49%|████▉     | 181/367 [00:32<00:32,  5.65it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  50%|████▉     | 182/367 [00:32<00:33,  5.50it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  50%|████▉     | 183/367 [00:32<00:31,  5.80it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  50%|█████     | 184/367 [00:32<00:31,  5.85it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  50%|█████     | 185/367 [00:32<00:32,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  51%|█████     | 186/367 [00:33<00:30,  5.91it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  51%|█████     | 187/367 [00:33<00:32,  5.50it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  51%|█████     | 188/367 [00:33<00:32,  5.43it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  51%|█████▏    | 189/367 [00:33<00:34,  5.16it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  52%|█████▏    | 190/367 [00:33<00:31,  5.58it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  52%|█████▏    | 191/367 [00:33<00:32,  5.49it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  52%|█████▏    | 192/367 [00:34<00:32,  5.43it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  53%|█████▎    | 193/367 [00:34<00:30,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  53%|█████▎    | 194/367 [00:34<00:29,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  53%|█████▎    | 195/367 [00:34<00:30,  5.72it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  53%|█████▎    | 196/367 [00:34<00:31,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  54%|█████▎    | 197/367 [00:35<00:32,  5.17it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1374 || acc: 95.00% || lr 7.863e-06:  54%|█████▍    | 198/367 [00:35<00:31,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  54%|█████▍    | 198/367 [00:35<00:31,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  54%|█████▍    | 199/367 [00:35<00:30,  5.53it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  54%|█████▍    | 200/367 [00:35<00:29,  5.63it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  55%|█████▍    | 201/367 [00:35<00:30,  5.53it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  55%|█████▌    | 202/367 [00:35<00:27,  5.96it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  55%|█████▌    | 203/367 [00:36<00:27,  5.92it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  56%|█████▌    | 204/367 [00:36<00:27,  5.88it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  56%|█████▌    | 205/367 [00:36<00:28,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  56%|█████▌    | 206/367 [00:36<00:29,  5.54it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  56%|█████▋    | 207/367 [00:36<00:29,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  57%|█████▋    | 208/367 [00:37<00:28,  5.49it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  57%|█████▋    | 209/367 [00:37<00:29,  5.29it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  57%|█████▋    | 210/367 [00:37<00:29,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  57%|█████▋    | 211/367 [00:37<00:28,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  58%|█████▊    | 212/367 [00:37<00:29,  5.24it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  58%|█████▊    | 213/367 [00:37<00:28,  5.39it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  58%|█████▊    | 214/367 [00:38<00:27,  5.57it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  59%|█████▊    | 215/367 [00:38<00:29,  5.21it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  59%|█████▉    | 216/367 [00:38<00:29,  5.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  59%|█████▉    | 217/367 [00:38<00:28,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2037 || acc: 93.75% || lr 7.861e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.38it/s] \u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  60%|█████▉    | 219/367 [00:39<00:28,  5.15it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  60%|█████▉    | 220/367 [00:39<00:26,  5.52it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  60%|██████    | 221/367 [00:39<00:24,  5.97it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  60%|██████    | 222/367 [00:39<00:25,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  61%|██████    | 223/367 [00:39<00:24,  5.77it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  61%|██████    | 224/367 [00:39<00:23,  6.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  61%|██████▏   | 225/367 [00:40<00:23,  5.98it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  62%|██████▏   | 226/367 [00:40<00:24,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  62%|██████▏   | 227/367 [00:40<00:22,  6.25it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  62%|██████▏   | 228/367 [00:40<00:24,  5.77it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  62%|██████▏   | 229/367 [00:40<00:22,  6.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  63%|██████▎   | 230/367 [00:40<00:22,  6.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  63%|██████▎   | 231/367 [00:41<00:21,  6.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  63%|██████▎   | 232/367 [00:41<00:21,  6.33it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  63%|██████▎   | 233/367 [00:41<00:20,  6.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  64%|██████▍   | 234/367 [00:41<00:21,  6.09it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  64%|██████▍   | 235/367 [00:41<00:20,  6.31it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  64%|██████▍   | 236/367 [00:41<00:21,  6.16it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  65%|██████▍   | 237/367 [00:42<00:21,  5.99it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1989 || acc: 92.50% || lr 7.86e-06:  65%|██████▍   | 238/367 [00:42<00:20,  6.16it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  65%|██████▍   | 238/367 [00:42<00:20,  6.16it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  65%|██████▌   | 239/367 [00:42<00:21,  5.89it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  65%|██████▌   | 240/367 [00:42<00:22,  5.73it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  66%|██████▌   | 241/367 [00:42<00:20,  6.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  66%|██████▌   | 242/367 [00:42<00:20,  6.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  66%|██████▌   | 243/367 [00:43<00:20,  5.99it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  66%|██████▋   | 244/367 [00:43<00:22,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  67%|██████▋   | 245/367 [00:43<00:21,  5.79it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  67%|██████▋   | 246/367 [00:43<00:20,  5.86it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  67%|██████▋   | 247/367 [00:43<00:20,  5.91it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  68%|██████▊   | 248/367 [00:43<00:19,  6.12it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  68%|██████▊   | 249/367 [00:44<00:18,  6.24it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  68%|██████▊   | 250/367 [00:44<00:19,  5.95it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  68%|██████▊   | 251/367 [00:44<00:20,  5.79it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  69%|██████▊   | 252/367 [00:44<00:19,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  69%|██████▉   | 253/367 [00:44<00:20,  5.44it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  69%|██████▉   | 254/367 [00:45<00:21,  5.37it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  69%|██████▉   | 255/367 [00:45<00:20,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  70%|██████▉   | 256/367 [00:45<00:19,  5.75it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  70%|███████   | 257/367 [00:45<00:19,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1319 || acc: 95.62% || lr 7.858e-06:  70%|███████   | 258/367 [00:45<00:19,  5.50it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  70%|███████   | 258/367 [00:45<00:19,  5.50it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  71%|███████   | 259/367 [00:45<00:19,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  71%|███████   | 260/367 [00:46<00:19,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  71%|███████   | 261/367 [00:46<00:18,  5.73it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  71%|███████▏  | 262/367 [00:46<00:19,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  72%|███████▏  | 263/367 [00:46<00:19,  5.47it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  72%|███████▏  | 265/367 [00:46<00:18,  5.61it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.74it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  73%|███████▎  | 267/367 [00:47<00:18,  5.40it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  73%|███████▎  | 269/367 [00:47<00:17,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  74%|███████▎  | 270/367 [00:47<00:18,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  74%|███████▍  | 271/367 [00:48<00:19,  4.92it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  74%|███████▍  | 272/367 [00:48<00:17,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  74%|███████▍  | 273/367 [00:48<00:17,  5.52it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  75%|███████▍  | 274/367 [00:48<00:16,  5.78it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  75%|███████▍  | 275/367 [00:48<00:17,  5.34it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  75%|███████▌  | 276/367 [00:49<00:17,  5.20it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.30it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2338 || acc: 90.00% || lr 7.857e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  76%|███████▌  | 279/367 [00:49<00:16,  5.33it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  76%|███████▋  | 280/367 [00:49<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  77%|███████▋  | 281/367 [00:49<00:15,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  77%|███████▋  | 282/367 [00:50<00:14,  5.89it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.54it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  77%|███████▋  | 284/367 [00:50<00:14,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  78%|███████▊  | 285/367 [00:50<00:14,  5.70it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  78%|███████▊  | 286/367 [00:50<00:13,  5.92it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  78%|███████▊  | 287/367 [00:50<00:13,  5.90it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  78%|███████▊  | 288/367 [00:51<00:14,  5.42it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  79%|███████▊  | 289/367 [00:51<00:14,  5.46it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  79%|███████▉  | 290/367 [00:51<00:14,  5.37it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  79%|███████▉  | 291/367 [00:51<00:14,  5.33it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  80%|███████▉  | 292/367 [00:51<00:14,  5.09it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  80%|███████▉  | 293/367 [00:52<00:14,  5.00it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  80%|████████  | 294/367 [00:52<00:13,  5.39it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  80%|████████  | 295/367 [00:52<00:13,  5.33it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  81%|████████  | 296/367 [00:52<00:12,  5.62it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  81%|████████  | 297/367 [00:52<00:12,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.3063 || acc: 90.00% || lr 7.855e-06:  81%|████████  | 298/367 [00:52<00:12,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  81%|████████  | 298/367 [00:53<00:12,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  81%|████████▏ | 299/367 [00:53<00:11,  5.75it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  82%|████████▏ | 300/367 [00:53<00:11,  6.01it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  82%|████████▏ | 301/367 [00:53<00:11,  5.67it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  82%|████████▏ | 302/367 [00:53<00:10,  5.93it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  83%|████████▎ | 303/367 [00:53<00:10,  5.97it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  83%|████████▎ | 304/367 [00:54<00:11,  5.56it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  83%|████████▎ | 305/367 [00:54<00:10,  5.96it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.92it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  84%|████████▎ | 307/367 [00:54<00:09,  6.12it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  84%|████████▍ | 308/367 [00:54<00:10,  5.62it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  84%|████████▍ | 309/367 [00:54<00:10,  5.38it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.34it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  85%|████████▍ | 311/367 [00:55<00:10,  5.32it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  85%|████████▌ | 312/367 [00:55<00:10,  5.28it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.63it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  86%|████████▌ | 314/367 [00:55<00:10,  5.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  86%|████████▌ | 315/367 [00:56<00:10,  5.07it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.30it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  86%|████████▋ | 317/367 [00:56<00:09,  5.17it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1843 || acc: 93.75% || lr 7.854e-06:  87%|████████▋ | 318/367 [00:56<00:09,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  87%|████████▋ | 318/367 [00:56<00:09,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  87%|████████▋ | 319/367 [00:56<00:09,  5.25it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  87%|████████▋ | 320/367 [00:56<00:08,  5.66it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  87%|████████▋ | 321/367 [00:57<00:08,  5.67it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  88%|████████▊ | 322/367 [00:57<00:07,  5.71it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  88%|████████▊ | 323/367 [00:57<00:07,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  88%|████████▊ | 324/367 [00:57<00:07,  5.95it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  89%|████████▊ | 325/367 [00:57<00:07,  5.69it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.37it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.47it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  89%|████████▉ | 328/367 [00:58<00:07,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  90%|████████▉ | 329/367 [00:58<00:07,  5.20it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  90%|████████▉ | 330/367 [00:58<00:07,  5.19it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.30it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.41it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.45it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.49it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.47it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.43it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2149 || acc: 93.12% || lr 7.852e-06:  92%|█████████▏| 338/367 [01:00<00:04,  5.81it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  92%|█████████▏| 338/367 [01:00<00:04,  5.81it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  92%|█████████▏| 339/367 [01:00<00:04,  5.70it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.57it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  93%|█████████▎| 342/367 [01:00<00:04,  5.64it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.91it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.30it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.50it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.74it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.76it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.85it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  95%|█████████▌| 350/367 [01:02<00:02,  6.25it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  96%|█████████▌| 351/367 [01:02<00:02,  6.04it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.74it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.58it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.55it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.23it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.62it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.60it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.2007 || acc: 92.50% || lr 7.851e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.59it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.59it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.18it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.06it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.22it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.02it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.05it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  99%|█████████▉| 364/367 [01:05<00:00,  4.96it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.47it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06: 100%|█████████▉| 366/367 [01:05<00:00,  6.05it/s]\u001b[A\n",
      "Epoch: [6/30] || loss: 0.1755 || acc: 91.25% || lr 7.849e-06: 100%|██████████| 367/367 [01:05<00:00,  5.61it/s]\n",
      "\n",
      "[Validation] Epoch 7:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 7:   3%|▎         | 3/92 [00:00<00:03, 23.27it/s]\u001b[A\n",
      "[Validation] Epoch 7:   7%|▋         | 6/92 [00:00<00:04, 19.73it/s]\u001b[A\n",
      "[Validation] Epoch 7:  10%|▉         | 9/92 [00:00<00:04, 18.13it/s]\u001b[A\n",
      "[Validation] Epoch 7:  12%|█▏        | 11/92 [00:00<00:04, 17.71it/s]\u001b[A\n",
      "[Validation] Epoch 7:  14%|█▍        | 13/92 [00:00<00:04, 16.35it/s]\u001b[A\n",
      "[Validation] Epoch 7:  16%|█▋        | 15/92 [00:00<00:04, 17.14it/s]\u001b[A\n",
      "[Validation] Epoch 7:  20%|█▉        | 18/92 [00:00<00:04, 18.37it/s]\u001b[A\n",
      "[Validation] Epoch 7:  22%|██▏       | 20/92 [00:01<00:03, 18.14it/s]\u001b[A\n",
      "[Validation] Epoch 7:  24%|██▍       | 22/92 [00:01<00:03, 18.03it/s]\u001b[A\n",
      "[Validation] Epoch 7:  26%|██▌       | 24/92 [00:01<00:03, 18.38it/s]\u001b[A\n",
      "[Validation] Epoch 7:  28%|██▊       | 26/92 [00:01<00:03, 17.80it/s]\u001b[A\n",
      "[Validation] Epoch 7:  32%|███▏      | 29/92 [00:01<00:03, 18.62it/s]\u001b[A\n",
      "[Validation] Epoch 7:  35%|███▍      | 32/92 [00:01<00:03, 19.49it/s]\u001b[A\n",
      "[Validation] Epoch 7:  37%|███▋      | 34/92 [00:01<00:03, 18.98it/s]\u001b[A\n",
      "[Validation] Epoch 7:  40%|████      | 37/92 [00:01<00:02, 19.42it/s]\u001b[A\n",
      "[Validation] Epoch 7:  42%|████▏     | 39/92 [00:02<00:02, 18.89it/s]\u001b[A\n",
      "[Validation] Epoch 7:  46%|████▌     | 42/92 [00:02<00:02, 19.58it/s]\u001b[A\n",
      "[Validation] Epoch 7:  48%|████▊     | 44/92 [00:02<00:02, 18.79it/s]\u001b[A\n",
      "[Validation] Epoch 7:  51%|█████     | 47/92 [00:02<00:02, 18.74it/s]\u001b[A\n",
      "[Validation] Epoch 7:  53%|█████▎    | 49/92 [00:02<00:02, 18.13it/s]\u001b[A\n",
      "[Validation] Epoch 7:  57%|█████▋    | 52/92 [00:02<00:02, 19.05it/s]\u001b[A\n",
      "[Validation] Epoch 7:  60%|█████▉    | 55/92 [00:02<00:01, 19.86it/s]\u001b[A\n",
      "[Validation] Epoch 7:  62%|██████▏   | 57/92 [00:03<00:01, 19.41it/s]\u001b[A\n",
      "[Validation] Epoch 7:  65%|██████▌   | 60/92 [00:03<00:01, 19.53it/s]\u001b[A\n",
      "[Validation] Epoch 7:  67%|██████▋   | 62/92 [00:03<00:01, 19.61it/s]\u001b[A\n",
      "[Validation] Epoch 7:  70%|██████▉   | 64/92 [00:03<00:01, 19.17it/s]\u001b[A\n",
      "[Validation] Epoch 7:  72%|███████▏  | 66/92 [00:03<00:01, 18.53it/s]\u001b[A\n",
      "[Validation] Epoch 7:  74%|███████▍  | 68/92 [00:03<00:01, 18.44it/s]\u001b[A\n",
      "[Validation] Epoch 7:  76%|███████▌  | 70/92 [00:03<00:01, 18.38it/s]\u001b[A\n",
      "[Validation] Epoch 7:  78%|███████▊  | 72/92 [00:03<00:01, 18.28it/s]\u001b[A\n",
      "[Validation] Epoch 7:  80%|████████  | 74/92 [00:03<00:01, 17.65it/s]\u001b[A\n",
      "[Validation] Epoch 7:  83%|████████▎ | 76/92 [00:04<00:00, 17.84it/s]\u001b[A\n",
      "[Validation] Epoch 7:  85%|████████▍ | 78/92 [00:04<00:00, 16.63it/s]\u001b[A\n",
      "[Validation] Epoch 7:  87%|████████▋ | 80/92 [00:04<00:00, 17.09it/s]\u001b[A\n",
      "[Validation] Epoch 7:  89%|████████▉ | 82/92 [00:04<00:00, 17.61it/s]\u001b[A\n",
      "[Validation] Epoch 7:  91%|█████████▏| 84/92 [00:04<00:00, 17.72it/s]\u001b[A\n",
      "[Validation] Epoch 7:  93%|█████████▎| 86/92 [00:04<00:00, 17.73it/s]\u001b[A\n",
      "[Validation] Epoch 7:  96%|█████████▌| 88/92 [00:04<00:00, 18.17it/s]\u001b[A\n",
      "[Validation] Epoch 7:  98%|█████████▊| 90/92 [00:04<00:00, 17.31it/s]\u001b[A\n",
      "Validation: [6/30] || loss: 0.08745 || acc: 96.88%: 100%|██████████| 92/92 [00:05<00:00, 18.38it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.96875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 23%|██▎       | 7/30 [08:27<27:45, 72.40s/it]\n",
      "[Training] Epoch 8:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 8:   0%|          | 1/367 [00:00<01:06,  5.50it/s]\u001b[A\n",
      "[Training] Epoch 8:   1%|          | 2/367 [00:00<01:02,  5.84it/s]\u001b[A\n",
      "[Training] Epoch 8:   1%|          | 3/367 [00:00<01:02,  5.78it/s]\u001b[A\n",
      "[Training] Epoch 8:   1%|          | 4/367 [00:00<00:58,  6.25it/s]\u001b[A\n",
      "[Training] Epoch 8:   1%|▏         | 5/367 [00:00<00:57,  6.33it/s]\u001b[A\n",
      "[Training] Epoch 8:   2%|▏         | 6/367 [00:01<01:03,  5.67it/s]\u001b[A\n",
      "[Training] Epoch 8:   2%|▏         | 7/367 [00:01<01:03,  5.64it/s]\u001b[A\n",
      "[Training] Epoch 8:   2%|▏         | 8/367 [00:01<01:08,  5.27it/s]\u001b[A\n",
      "[Training] Epoch 8:   2%|▏         | 9/367 [00:01<01:06,  5.42it/s]\u001b[A\n",
      "[Training] Epoch 8:   3%|▎         | 10/367 [00:01<01:09,  5.13it/s]\u001b[A\n",
      "[Training] Epoch 8:   3%|▎         | 11/367 [00:01<01:07,  5.30it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   3%|▎         | 11/367 [00:01<01:07,  5.30it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   3%|▎         | 12/367 [00:02<01:05,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   4%|▎         | 13/367 [00:02<01:00,  5.84it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   4%|▍         | 14/367 [00:02<01:00,  5.82it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   4%|▍         | 15/367 [00:02<01:02,  5.60it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   4%|▍         | 16/367 [00:02<01:08,  5.15it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   5%|▍         | 17/367 [00:03<01:06,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   5%|▍         | 18/367 [00:03<01:01,  5.71it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   5%|▌         | 19/367 [00:03<01:05,  5.34it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   5%|▌         | 20/367 [00:03<01:05,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   6%|▌         | 21/367 [00:03<01:05,  5.28it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   6%|▌         | 22/367 [00:04<01:05,  5.30it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   6%|▋         | 23/367 [00:04<00:59,  5.78it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   7%|▋         | 24/367 [00:04<01:00,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   7%|▋         | 25/367 [00:04<01:05,  5.24it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   7%|▋         | 26/367 [00:04<01:09,  4.92it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   7%|▋         | 27/367 [00:04<01:05,  5.21it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   8%|▊         | 28/367 [00:05<00:59,  5.66it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   8%|▊         | 29/367 [00:05<00:58,  5.79it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   8%|▊         | 30/367 [00:05<00:55,  6.04it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06394 || acc: 53.75% || lr 7.848e-06:   8%|▊         | 31/367 [00:05<00:57,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:   8%|▊         | 31/367 [00:05<00:57,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:   9%|▊         | 32/367 [00:05<00:58,  5.70it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:   9%|▉         | 33/367 [00:05<00:58,  5.76it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:   9%|▉         | 34/367 [00:06<01:02,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  10%|▉         | 35/367 [00:06<01:00,  5.52it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  10%|▉         | 36/367 [00:06<00:59,  5.56it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  10%|█         | 37/367 [00:06<01:00,  5.48it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  10%|█         | 38/367 [00:06<00:56,  5.85it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  11%|█         | 39/367 [00:07<00:57,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  11%|█         | 40/367 [00:07<01:02,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  11%|█         | 41/367 [00:07<00:58,  5.59it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  11%|█▏        | 42/367 [00:07<00:59,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  12%|█▏        | 43/367 [00:07<00:58,  5.49it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  12%|█▏        | 44/367 [00:07<00:58,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  12%|█▏        | 45/367 [00:08<01:02,  5.19it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  13%|█▎        | 46/367 [00:08<01:01,  5.19it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  13%|█▎        | 47/367 [00:08<01:04,  4.94it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  13%|█▎        | 48/367 [00:08<01:04,  4.96it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  13%|█▎        | 49/367 [00:08<01:04,  4.95it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  14%|█▎        | 50/367 [00:09<01:02,  5.08it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09115 || acc: 96.88% || lr 7.847e-06:  14%|█▍        | 51/367 [00:09<00:58,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  14%|█▍        | 51/367 [00:09<00:58,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  14%|█▍        | 52/367 [00:09<01:03,  4.92it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  14%|█▍        | 53/367 [00:09<01:01,  5.11it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  15%|█▍        | 54/367 [00:09<00:56,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  15%|█▍        | 55/367 [00:10<00:53,  5.85it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  15%|█▌        | 56/367 [00:10<00:54,  5.73it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  16%|█▌        | 57/367 [00:10<00:55,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  16%|█▌        | 58/367 [00:10<00:55,  5.54it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  16%|█▌        | 59/367 [00:10<00:54,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  16%|█▋        | 60/367 [00:10<00:53,  5.75it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  17%|█▋        | 61/367 [00:11<00:54,  5.65it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  17%|█▋        | 62/367 [00:11<00:53,  5.69it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  17%|█▋        | 63/367 [00:11<00:51,  5.91it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  17%|█▋        | 64/367 [00:11<00:53,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  18%|█▊        | 65/367 [00:11<00:54,  5.58it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  18%|█▊        | 66/367 [00:12<00:55,  5.41it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  18%|█▊        | 67/367 [00:12<00:55,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  19%|█▊        | 68/367 [00:12<00:53,  5.62it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  19%|█▉        | 69/367 [00:12<00:54,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  19%|█▉        | 70/367 [00:12<00:55,  5.38it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.09264 || acc: 98.12% || lr 7.845e-06:  19%|█▉        | 71/367 [00:12<00:54,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  19%|█▉        | 71/367 [00:12<00:54,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  20%|█▉        | 72/367 [00:13<00:54,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  20%|█▉        | 73/367 [00:13<00:53,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  20%|██        | 74/367 [00:13<00:50,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  20%|██        | 75/367 [00:13<00:52,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  21%|██        | 76/367 [00:13<00:51,  5.65it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  21%|██        | 77/367 [00:14<00:52,  5.52it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  21%|██▏       | 78/367 [00:14<00:52,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  22%|██▏       | 79/367 [00:14<00:51,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  22%|██▏       | 80/367 [00:14<00:52,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  22%|██▏       | 81/367 [00:14<00:51,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  22%|██▏       | 82/367 [00:14<00:51,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  23%|██▎       | 83/367 [00:15<00:49,  5.70it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  23%|██▎       | 84/367 [00:15<00:53,  5.34it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  23%|██▎       | 85/367 [00:15<00:51,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  23%|██▎       | 86/367 [00:15<00:50,  5.55it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  24%|██▎       | 87/367 [00:15<00:47,  5.95it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  24%|██▍       | 88/367 [00:15<00:48,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  24%|██▍       | 89/367 [00:16<00:48,  5.71it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  25%|██▍       | 90/367 [00:16<00:46,  5.98it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.05101 || acc: 98.12% || lr 7.844e-06:  25%|██▍       | 91/367 [00:16<00:45,  6.12it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  25%|██▍       | 91/367 [00:16<00:45,  6.12it/s]  \u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  25%|██▌       | 92/367 [00:16<00:46,  5.91it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  25%|██▌       | 93/367 [00:16<00:46,  5.85it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  26%|██▌       | 94/367 [00:16<00:47,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  26%|██▌       | 95/367 [00:17<00:47,  5.79it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  26%|██▌       | 96/367 [00:17<00:48,  5.56it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  26%|██▋       | 97/367 [00:17<00:48,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.87it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  27%|██▋       | 99/367 [00:17<00:44,  6.02it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  27%|██▋       | 100/367 [00:18<00:43,  6.14it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  28%|██▊       | 101/367 [00:18<00:44,  6.03it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  28%|██▊       | 102/367 [00:18<00:46,  5.74it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  28%|██▊       | 103/367 [00:18<00:46,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  28%|██▊       | 104/367 [00:18<00:50,  5.19it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  29%|██▊       | 105/367 [00:18<00:51,  5.11it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  29%|██▉       | 106/367 [00:19<00:51,  5.12it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  29%|██▉       | 107/367 [00:19<00:46,  5.58it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  29%|██▉       | 108/367 [00:19<00:45,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  30%|██▉       | 109/367 [00:19<00:46,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  30%|██▉       | 110/367 [00:19<00:43,  5.94it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.156 || acc: 95.00% || lr 7.842e-06:  30%|███       | 111/367 [00:19<00:43,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  30%|███       | 111/367 [00:20<00:43,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  31%|███       | 112/367 [00:20<00:47,  5.39it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  31%|███       | 113/367 [00:20<00:46,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  31%|███       | 114/367 [00:20<00:46,  5.42it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  31%|███▏      | 115/367 [00:20<00:44,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  32%|███▏      | 116/367 [00:20<00:45,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  32%|███▏      | 117/367 [00:21<00:43,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  32%|███▏      | 118/367 [00:21<00:41,  6.06it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  32%|███▏      | 119/367 [00:21<00:42,  5.79it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  33%|███▎      | 120/367 [00:21<00:40,  6.08it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  33%|███▎      | 121/367 [00:21<00:41,  6.00it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  34%|███▎      | 123/367 [00:21<00:34,  7.11it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  34%|███▍      | 124/367 [00:22<00:36,  6.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  34%|███▍      | 125/367 [00:22<00:37,  6.42it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  34%|███▍      | 126/367 [00:22<00:38,  6.28it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  35%|███▍      | 127/367 [00:22<00:39,  6.04it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  35%|███▍      | 128/367 [00:22<00:39,  6.01it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  35%|███▌      | 129/367 [00:23<00:42,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  35%|███▌      | 130/367 [00:23<00:42,  5.62it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1225 || acc: 95.00% || lr 7.841e-06:  36%|███▌      | 131/367 [00:23<00:38,  6.06it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  36%|███▌      | 131/367 [00:23<00:38,  6.06it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  36%|███▌      | 132/367 [00:23<00:42,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  36%|███▌      | 133/367 [00:23<00:43,  5.40it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  37%|███▋      | 134/367 [00:23<00:41,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  37%|███▋      | 135/367 [00:24<00:40,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  37%|███▋      | 136/367 [00:24<00:41,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  37%|███▋      | 137/367 [00:24<00:42,  5.42it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  38%|███▊      | 138/367 [00:24<00:40,  5.66it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  38%|███▊      | 139/367 [00:24<00:38,  5.92it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  38%|███▊      | 140/367 [00:24<00:36,  6.24it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  38%|███▊      | 141/367 [00:25<00:36,  6.17it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  39%|███▊      | 142/367 [00:25<00:38,  5.87it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  39%|███▉      | 143/367 [00:25<00:39,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  39%|███▉      | 144/367 [00:25<00:41,  5.34it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  40%|███▉      | 145/367 [00:25<00:40,  5.47it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  40%|███▉      | 146/367 [00:26<00:38,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  40%|████      | 147/367 [00:26<00:37,  5.86it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  40%|████      | 148/367 [00:26<00:38,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  41%|████      | 149/367 [00:26<00:38,  5.65it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  41%|████      | 150/367 [00:26<00:37,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1187 || acc: 95.00% || lr 7.839e-06:  41%|████      | 151/367 [00:26<00:35,  6.15it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  41%|████      | 151/367 [00:26<00:35,  6.15it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  41%|████▏     | 152/367 [00:27<00:38,  5.59it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  42%|████▏     | 153/367 [00:27<00:36,  5.93it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  42%|████▏     | 154/367 [00:27<00:34,  6.11it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  42%|████▏     | 155/367 [00:27<00:35,  5.94it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  43%|████▎     | 156/367 [00:27<00:35,  5.96it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  43%|████▎     | 157/367 [00:27<00:37,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  43%|████▎     | 158/367 [00:28<00:36,  5.78it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  43%|████▎     | 159/367 [00:28<00:33,  6.17it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  44%|████▍     | 161/367 [00:28<00:34,  6.05it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  44%|████▍     | 162/367 [00:28<00:37,  5.52it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  44%|████▍     | 163/367 [00:28<00:34,  5.97it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  45%|████▍     | 164/367 [00:29<00:35,  5.76it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  45%|████▍     | 165/367 [00:29<00:37,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  45%|████▌     | 166/367 [00:29<00:42,  4.75it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  46%|████▌     | 167/367 [00:29<00:40,  4.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  46%|████▌     | 168/367 [00:29<00:37,  5.34it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  46%|████▌     | 169/367 [00:30<00:38,  5.15it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  46%|████▋     | 170/367 [00:30<00:38,  5.07it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.03442 || acc: 99.38% || lr 7.838e-06:  47%|████▋     | 171/367 [00:30<00:37,  5.17it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  47%|████▋     | 171/367 [00:30<00:37,  5.17it/s]  \u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  47%|████▋     | 172/367 [00:30<00:36,  5.32it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  47%|████▋     | 173/367 [00:30<00:35,  5.48it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  47%|████▋     | 174/367 [00:31<00:38,  5.08it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  48%|████▊     | 175/367 [00:31<00:36,  5.26it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  48%|████▊     | 176/367 [00:31<00:35,  5.33it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  48%|████▊     | 177/367 [00:31<00:33,  5.69it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  49%|████▊     | 178/367 [00:31<00:33,  5.65it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  49%|████▉     | 179/367 [00:31<00:31,  5.92it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  49%|████▉     | 180/367 [00:32<00:30,  6.17it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  49%|████▉     | 181/367 [00:32<00:30,  6.01it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  50%|████▉     | 182/367 [00:32<00:29,  6.18it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  50%|████▉     | 183/367 [00:32<00:30,  6.05it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  50%|█████     | 184/367 [00:32<00:33,  5.54it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  50%|█████     | 185/367 [00:32<00:30,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  51%|█████     | 186/367 [00:33<00:31,  5.78it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  51%|█████     | 187/367 [00:33<00:31,  5.64it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  51%|█████     | 188/367 [00:33<00:31,  5.70it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  51%|█████▏    | 189/367 [00:33<00:31,  5.74it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  52%|█████▏    | 190/367 [00:33<00:30,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.129 || acc: 95.62% || lr 7.836e-06:  52%|█████▏    | 191/367 [00:33<00:30,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  52%|█████▏    | 191/367 [00:34<00:30,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  52%|█████▏    | 192/367 [00:34<00:30,  5.76it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  53%|█████▎    | 193/367 [00:34<00:31,  5.60it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  53%|█████▎    | 194/367 [00:34<00:29,  5.93it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  53%|█████▎    | 195/367 [00:34<00:28,  6.13it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  53%|█████▎    | 196/367 [00:34<00:27,  6.12it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  54%|█████▎    | 197/367 [00:34<00:26,  6.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  54%|█████▍    | 198/367 [00:35<00:27,  6.14it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  54%|█████▍    | 199/367 [00:35<00:26,  6.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  54%|█████▍    | 200/367 [00:35<00:26,  6.21it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  55%|█████▍    | 201/367 [00:35<00:29,  5.65it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  55%|█████▌    | 202/367 [00:35<00:29,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  55%|█████▌    | 203/367 [00:36<00:29,  5.60it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  56%|█████▌    | 204/367 [00:36<00:29,  5.59it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  56%|█████▌    | 205/367 [00:36<00:27,  5.81it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  56%|█████▌    | 206/367 [00:36<00:28,  5.60it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  56%|█████▋    | 207/367 [00:36<00:29,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  57%|█████▋    | 208/367 [00:36<00:30,  5.23it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  57%|█████▋    | 209/367 [00:37<00:31,  5.01it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  57%|█████▋    | 210/367 [00:37<00:30,  5.16it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.06915 || acc: 96.88% || lr 7.835e-06:  57%|█████▋    | 211/367 [00:37<00:28,  5.55it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  57%|█████▋    | 211/367 [00:37<00:28,  5.55it/s] \u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  58%|█████▊    | 212/367 [00:37<00:29,  5.28it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  58%|█████▊    | 213/367 [00:37<00:29,  5.24it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  58%|█████▊    | 214/367 [00:38<00:27,  5.60it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  59%|█████▊    | 215/367 [00:38<00:26,  5.73it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  59%|█████▉    | 216/367 [00:38<00:28,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  59%|█████▉    | 217/367 [00:38<00:27,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.39it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  60%|█████▉    | 219/367 [00:38<00:26,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  60%|█████▉    | 220/367 [00:39<00:27,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  60%|██████    | 221/367 [00:39<00:27,  5.39it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  60%|██████    | 222/367 [00:39<00:26,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  61%|██████    | 223/367 [00:39<00:24,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  61%|██████    | 224/367 [00:39<00:24,  5.75it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  61%|██████▏   | 225/367 [00:40<00:24,  5.79it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  62%|██████▏   | 226/367 [00:40<00:24,  5.73it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  62%|██████▏   | 227/367 [00:40<00:25,  5.41it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  62%|██████▏   | 228/367 [00:40<00:24,  5.75it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  62%|██████▏   | 229/367 [00:40<00:24,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  63%|██████▎   | 230/367 [00:40<00:25,  5.31it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1141 || acc: 97.50% || lr 7.833e-06:  63%|██████▎   | 231/367 [00:41<00:23,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  63%|██████▎   | 231/367 [00:41<00:23,  5.68it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  63%|██████▎   | 232/367 [00:41<00:24,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  63%|██████▎   | 233/367 [00:41<00:25,  5.18it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  64%|██████▍   | 234/367 [00:41<00:23,  5.55it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  64%|██████▍   | 235/367 [00:41<00:22,  5.93it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  64%|██████▍   | 236/367 [00:41<00:20,  6.54it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  65%|██████▍   | 237/367 [00:42<00:20,  6.28it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  65%|██████▍   | 238/367 [00:42<00:22,  5.64it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  65%|██████▌   | 239/367 [00:42<00:23,  5.54it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  65%|██████▌   | 240/367 [00:42<00:23,  5.49it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  66%|██████▌   | 241/367 [00:42<00:22,  5.59it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  66%|██████▌   | 242/367 [00:43<00:21,  5.88it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  66%|██████▌   | 243/367 [00:43<00:20,  5.92it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  66%|██████▋   | 244/367 [00:43<00:20,  5.87it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  67%|██████▋   | 245/367 [00:43<00:21,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  67%|██████▋   | 246/367 [00:43<00:19,  6.20it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  67%|██████▋   | 247/367 [00:43<00:20,  5.74it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  68%|██████▊   | 248/367 [00:44<00:20,  5.73it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  68%|██████▊   | 249/367 [00:44<00:22,  5.22it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  68%|██████▊   | 250/367 [00:44<00:22,  5.24it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1152 || acc: 94.38% || lr 7.832e-06:  68%|██████▊   | 251/367 [00:44<00:20,  5.69it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  68%|██████▊   | 251/367 [00:44<00:20,  5.69it/s] \u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  69%|██████▊   | 252/367 [00:44<00:21,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  69%|██████▉   | 253/367 [00:45<00:21,  5.37it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  69%|██████▉   | 254/367 [00:45<00:19,  5.69it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  69%|██████▉   | 255/367 [00:45<00:19,  5.81it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  70%|██████▉   | 256/367 [00:45<00:19,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  70%|███████   | 257/367 [00:45<00:19,  5.56it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  70%|███████   | 258/367 [00:45<00:19,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  71%|███████   | 259/367 [00:46<00:20,  5.29it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  71%|███████   | 260/367 [00:46<00:19,  5.41it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  71%|███████   | 261/367 [00:46<00:19,  5.48it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  71%|███████▏  | 262/367 [00:46<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  72%|███████▏  | 263/367 [00:46<00:18,  5.62it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  72%|███████▏  | 264/367 [00:47<00:19,  5.18it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  72%|███████▏  | 265/367 [00:47<00:18,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  72%|███████▏  | 266/367 [00:47<00:16,  5.94it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.66it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  73%|███████▎  | 269/367 [00:47<00:16,  6.03it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  74%|███████▎  | 270/367 [00:47<00:15,  6.12it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1498 || acc: 95.62% || lr 7.83e-06:  74%|███████▍  | 271/367 [00:48<00:16,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  74%|███████▍  | 271/367 [00:48<00:16,  5.77it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.91it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  74%|███████▍  | 273/367 [00:48<00:15,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  75%|███████▍  | 274/367 [00:48<00:17,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  75%|███████▍  | 275/367 [00:48<00:17,  5.39it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  75%|███████▌  | 276/367 [00:49<00:17,  5.32it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.38it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.41it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  76%|███████▌  | 279/367 [00:49<00:16,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  76%|███████▋  | 280/367 [00:49<00:15,  5.55it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  77%|███████▋  | 281/367 [00:49<00:15,  5.62it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  77%|███████▋  | 282/367 [00:50<00:14,  5.82it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  77%|███████▋  | 283/367 [00:50<00:14,  5.82it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  77%|███████▋  | 284/367 [00:50<00:15,  5.38it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  78%|███████▊  | 285/367 [00:50<00:15,  5.46it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  78%|███████▊  | 286/367 [00:50<00:15,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  78%|███████▊  | 287/367 [00:51<00:14,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  78%|███████▊  | 288/367 [00:51<00:14,  5.49it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.78it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  79%|███████▉  | 290/367 [00:51<00:12,  6.04it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1209 || acc: 95.62% || lr 7.829e-06:  79%|███████▉  | 291/367 [00:51<00:13,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  79%|███████▉  | 291/367 [00:51<00:13,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  80%|███████▉  | 292/367 [00:51<00:13,  5.43it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  80%|███████▉  | 293/367 [00:52<00:12,  5.73it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  80%|████████  | 294/367 [00:52<00:13,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  80%|████████  | 295/367 [00:52<00:13,  5.51it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  81%|████████  | 296/367 [00:52<00:13,  5.40it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  81%|████████  | 297/367 [00:52<00:12,  5.52it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  81%|████████  | 298/367 [00:53<00:12,  5.56it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  81%|████████▏ | 299/367 [00:53<00:11,  6.02it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  82%|████████▏ | 300/367 [00:53<00:11,  5.85it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  82%|████████▏ | 301/367 [00:53<00:11,  5.87it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  82%|████████▏ | 302/367 [00:53<00:10,  6.18it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  83%|████████▎ | 303/367 [00:53<00:10,  6.29it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  83%|████████▎ | 304/367 [00:54<00:10,  6.08it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  83%|████████▎ | 305/367 [00:54<00:09,  6.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  83%|████████▎ | 306/367 [00:54<00:11,  5.50it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  84%|████████▎ | 307/367 [00:54<00:11,  5.31it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  84%|████████▍ | 308/367 [00:54<00:10,  5.86it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  84%|████████▍ | 309/367 [00:54<00:09,  5.82it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  84%|████████▍ | 310/367 [00:55<00:09,  5.80it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08995 || acc: 96.88% || lr 7.828e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.74it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.74it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.55it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  85%|████████▌ | 313/367 [00:55<00:10,  5.25it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  86%|████████▌ | 314/367 [00:55<00:10,  5.14it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  86%|████████▌ | 315/367 [00:55<00:09,  5.75it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  86%|████████▌ | 316/367 [00:56<00:08,  5.78it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  86%|████████▋ | 317/367 [00:56<00:08,  5.69it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.58it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  87%|████████▋ | 319/367 [00:56<00:09,  5.21it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  87%|████████▋ | 320/367 [00:56<00:08,  5.25it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  87%|████████▋ | 321/367 [00:57<00:08,  5.33it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.48it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  88%|████████▊ | 323/367 [00:57<00:08,  5.14it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  88%|████████▊ | 324/367 [00:57<00:08,  5.17it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  89%|████████▊ | 325/367 [00:57<00:07,  5.39it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  89%|████████▉ | 326/367 [00:57<00:06,  5.93it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  89%|████████▉ | 327/367 [00:58<00:06,  5.81it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  89%|████████▉ | 328/367 [00:58<00:06,  5.84it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  90%|████████▉ | 329/367 [00:58<00:07,  5.26it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.08171 || acc: 98.75% || lr 7.826e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.53it/s]  \u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.56it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.52it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.28it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.45it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.94it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  92%|█████████▏| 337/367 [00:59<00:05,  5.88it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  92%|█████████▏| 338/367 [01:00<00:04,  6.23it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  92%|█████████▏| 339/367 [01:00<00:04,  6.16it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.57it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.63it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  93%|█████████▎| 342/367 [01:00<00:04,  5.88it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  93%|█████████▎| 343/367 [01:00<00:04,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.44it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  94%|█████████▍| 345/367 [01:01<00:04,  4.98it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  94%|█████████▍| 346/367 [01:01<00:04,  4.84it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.09it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.33it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.30it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.108 || acc: 96.88% || lr 7.825e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.42it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.42it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.72it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.29it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.13it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  97%|█████████▋| 356/367 [01:03<00:02,  5.33it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.27it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.61it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.33it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.89it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.81it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.67it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.53it/s]\u001b[A\n",
      "Epoch: [7/30] || loss: 0.1941 || acc: 93.75% || lr 7.823e-06: 100%|██████████| 367/367 [01:05<00:00,  5.61it/s]\n",
      "\n",
      "[Validation] Epoch 8:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 8:   3%|▎         | 3/92 [00:00<00:03, 23.04it/s]\u001b[A\n",
      "[Validation] Epoch 8:   7%|▋         | 6/92 [00:00<00:04, 19.81it/s]\u001b[A\n",
      "[Validation] Epoch 8:  10%|▉         | 9/92 [00:00<00:04, 19.07it/s]\u001b[A\n",
      "[Validation] Epoch 8:  12%|█▏        | 11/92 [00:00<00:04, 17.24it/s]\u001b[A\n",
      "[Validation] Epoch 8:  14%|█▍        | 13/92 [00:00<00:04, 17.19it/s]\u001b[A\n",
      "[Validation] Epoch 8:  16%|█▋        | 15/92 [00:00<00:04, 16.89it/s]\u001b[A\n",
      "[Validation] Epoch 8:  18%|█▊        | 17/92 [00:00<00:04, 17.09it/s]\u001b[A\n",
      "[Validation] Epoch 8:  21%|██        | 19/92 [00:01<00:04, 17.35it/s]\u001b[A\n",
      "[Validation] Epoch 8:  23%|██▎       | 21/92 [00:01<00:04, 17.60it/s]\u001b[A\n",
      "[Validation] Epoch 8:  25%|██▌       | 23/92 [00:01<00:03, 18.01it/s]\u001b[A\n",
      "[Validation] Epoch 8:  27%|██▋       | 25/92 [00:01<00:03, 17.96it/s]\u001b[A\n",
      "[Validation] Epoch 8:  29%|██▉       | 27/92 [00:01<00:03, 18.26it/s]\u001b[A\n",
      "[Validation] Epoch 8:  32%|███▏      | 29/92 [00:01<00:03, 18.74it/s]\u001b[A\n",
      "[Validation] Epoch 8:  35%|███▍      | 32/92 [00:01<00:02, 20.39it/s]\u001b[A\n",
      "[Validation] Epoch 8:  38%|███▊      | 35/92 [00:01<00:02, 19.87it/s]\u001b[A\n",
      "[Validation] Epoch 8:  40%|████      | 37/92 [00:02<00:02, 18.37it/s]\u001b[A\n",
      "[Validation] Epoch 8:  42%|████▏     | 39/92 [00:02<00:02, 18.17it/s]\u001b[A\n",
      "[Validation] Epoch 8:  45%|████▍     | 41/92 [00:02<00:02, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 8:  47%|████▋     | 43/92 [00:02<00:02, 17.10it/s]\u001b[A\n",
      "[Validation] Epoch 8:  49%|████▉     | 45/92 [00:02<00:02, 17.67it/s]\u001b[A\n",
      "[Validation] Epoch 8:  52%|█████▏    | 48/92 [00:02<00:02, 18.24it/s]\u001b[A\n",
      "[Validation] Epoch 8:  55%|█████▌    | 51/92 [00:02<00:02, 19.81it/s]\u001b[A\n",
      "[Validation] Epoch 8:  58%|█████▊    | 53/92 [00:02<00:02, 19.24it/s]\u001b[A\n",
      "[Validation] Epoch 8:  60%|█████▉    | 55/92 [00:02<00:01, 19.30it/s]\u001b[A\n",
      "[Validation] Epoch 8:  62%|██████▏   | 57/92 [00:03<00:01, 19.23it/s]\u001b[A\n",
      "[Validation] Epoch 8:  64%|██████▍   | 59/92 [00:03<00:01, 18.55it/s]\u001b[A\n",
      "[Validation] Epoch 8:  67%|██████▋   | 62/92 [00:03<00:01, 19.13it/s]\u001b[A\n",
      "[Validation] Epoch 8:  70%|██████▉   | 64/92 [00:03<00:01, 18.78it/s]\u001b[A\n",
      "[Validation] Epoch 8:  72%|███████▏  | 66/92 [00:03<00:01, 16.80it/s]\u001b[A\n",
      "[Validation] Epoch 8:  74%|███████▍  | 68/92 [00:03<00:01, 16.61it/s]\u001b[A\n",
      "[Validation] Epoch 8:  77%|███████▋  | 71/92 [00:03<00:01, 17.06it/s]\u001b[A\n",
      "[Validation] Epoch 8:  79%|███████▉  | 73/92 [00:04<00:01, 17.24it/s]\u001b[A\n",
      "[Validation] Epoch 8:  82%|████████▏ | 75/92 [00:04<00:00, 17.48it/s]\u001b[A\n",
      "[Validation] Epoch 8:  84%|████████▎ | 77/92 [00:04<00:00, 18.03it/s]\u001b[A\n",
      "[Validation] Epoch 8:  86%|████████▌ | 79/92 [00:04<00:00, 18.35it/s]\u001b[A\n",
      "[Validation] Epoch 8:  88%|████████▊ | 81/92 [00:04<00:00, 17.55it/s]\u001b[A\n",
      "[Validation] Epoch 8:  91%|█████████▏| 84/92 [00:04<00:00, 18.27it/s]\u001b[A\n",
      "[Validation] Epoch 8:  93%|█████████▎| 86/92 [00:04<00:00, 18.11it/s]\u001b[A\n",
      "[Validation] Epoch 8:  96%|█████████▌| 88/92 [00:04<00:00, 17.02it/s]\u001b[A\n",
      "[Validation] Epoch 8:  98%|█████████▊| 90/92 [00:04<00:00, 17.29it/s]\u001b[A\n",
      "[Validation] Epoch 8: 100%|██████████| 92/92 [00:05<00:00, 17.58it/s]\u001b[A\n",
      "Validation: [7/30] || loss: 0.0885 || acc: 97.83%: 100%|██████████| 92/92 [00:05<00:00, 18.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.9782608695652174\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 27%|██▋       | 8/30 [09:40<26:40, 72.75s/it]\n",
      "[Training] Epoch 9:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 9:   0%|          | 1/367 [00:00<00:56,  6.51it/s]\u001b[A\n",
      "[Training] Epoch 9:   1%|          | 2/367 [00:00<01:04,  5.68it/s]\u001b[A\n",
      "[Training] Epoch 9:   1%|          | 3/367 [00:00<01:00,  6.07it/s]\u001b[A\n",
      "[Training] Epoch 9:   1%|          | 4/367 [00:00<01:01,  5.95it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   1%|          | 4/367 [00:00<01:01,  5.95it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   1%|▏         | 5/367 [00:00<00:59,  6.11it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   2%|▏         | 6/367 [00:00<00:57,  6.25it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   2%|▏         | 7/367 [00:01<01:01,  5.83it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   2%|▏         | 8/367 [00:01<01:04,  5.57it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   2%|▏         | 9/367 [00:01<01:03,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   3%|▎         | 10/367 [00:01<01:05,  5.49it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   3%|▎         | 11/367 [00:01<01:03,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   3%|▎         | 12/367 [00:02<01:04,  5.48it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   4%|▎         | 13/367 [00:02<01:04,  5.50it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   4%|▍         | 14/367 [00:02<00:58,  6.03it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   4%|▍         | 15/367 [00:02<01:01,  5.68it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   4%|▍         | 16/367 [00:02<00:57,  6.08it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   5%|▍         | 17/367 [00:02<01:02,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   5%|▍         | 18/367 [00:03<01:03,  5.46it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   5%|▌         | 19/367 [00:03<00:58,  5.90it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   5%|▌         | 20/367 [00:03<00:58,  5.96it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   6%|▌         | 21/367 [00:03<00:56,  6.13it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   6%|▌         | 22/367 [00:03<00:55,  6.26it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   6%|▋         | 23/367 [00:03<01:00,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.008422 || acc: 20.00% || lr 7.822e-06:   7%|▋         | 24/367 [00:04<00:59,  5.75it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   7%|▋         | 24/367 [00:04<00:59,  5.75it/s]   \u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   7%|▋         | 25/367 [00:04<01:02,  5.47it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   7%|▋         | 26/367 [00:04<00:58,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   7%|▋         | 27/367 [00:04<00:57,  5.91it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   8%|▊         | 28/367 [00:04<01:03,  5.34it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   8%|▊         | 29/367 [00:05<01:02,  5.43it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   8%|▊         | 30/367 [00:05<01:04,  5.24it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   8%|▊         | 31/367 [00:05<01:00,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   9%|▊         | 32/367 [00:05<00:56,  5.88it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   9%|▉         | 33/367 [00:05<00:54,  6.09it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:   9%|▉         | 34/367 [00:05<00:57,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  10%|▉         | 35/367 [00:06<00:53,  6.22it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  10%|▉         | 36/367 [00:06<00:55,  5.99it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  10%|█         | 37/367 [00:06<00:57,  5.78it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  10%|█         | 38/367 [00:06<00:52,  6.27it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  11%|█         | 39/367 [00:06<00:55,  5.90it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  11%|█         | 40/367 [00:06<00:57,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  11%|█         | 41/367 [00:07<00:58,  5.54it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  11%|█▏        | 42/367 [00:07<01:04,  5.01it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  12%|█▏        | 43/367 [00:07<01:04,  5.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1132 || acc: 97.50% || lr 7.82e-06:  12%|█▏        | 44/367 [00:07<01:06,  4.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  12%|█▏        | 44/367 [00:07<01:06,  4.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  12%|█▏        | 45/367 [00:07<01:06,  4.81it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  13%|█▎        | 46/367 [00:08<01:01,  5.23it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  13%|█▎        | 47/367 [00:08<00:57,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  13%|█▎        | 48/367 [00:08<00:58,  5.47it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  13%|█▎        | 49/367 [00:08<00:55,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  14%|█▎        | 50/367 [00:08<00:59,  5.32it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  14%|█▍        | 51/367 [00:09<00:57,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  14%|█▍        | 52/367 [00:09<00:55,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  14%|█▍        | 53/367 [00:09<00:56,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  15%|█▍        | 54/367 [00:09<00:56,  5.50it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  15%|█▍        | 55/367 [00:09<00:53,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  15%|█▌        | 56/367 [00:09<00:54,  5.73it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  16%|█▌        | 57/367 [00:10<00:52,  5.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  16%|█▌        | 58/367 [00:10<00:53,  5.82it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  16%|█▌        | 59/367 [00:10<00:51,  5.98it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  16%|█▋        | 60/367 [00:10<00:52,  5.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  17%|█▋        | 61/367 [00:10<00:50,  6.07it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  17%|█▋        | 62/367 [00:10<00:50,  6.06it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  17%|█▋        | 63/367 [00:11<00:48,  6.31it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03704 || acc: 98.75% || lr 7.819e-06:  17%|█▋        | 64/367 [00:11<00:49,  6.15it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  17%|█▋        | 64/367 [00:11<00:49,  6.15it/s] \u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  18%|█▊        | 65/367 [00:11<00:50,  5.95it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  18%|█▊        | 66/367 [00:11<00:52,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  18%|█▊        | 67/367 [00:11<00:51,  5.88it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  19%|█▊        | 68/367 [00:11<00:54,  5.53it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  19%|█▉        | 69/367 [00:12<00:51,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  19%|█▉        | 70/367 [00:12<00:49,  6.05it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  19%|█▉        | 71/367 [00:12<00:50,  5.88it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  20%|█▉        | 72/367 [00:12<00:51,  5.75it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  20%|█▉        | 73/367 [00:12<00:48,  6.03it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  20%|██        | 74/367 [00:12<00:46,  6.26it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  20%|██        | 75/367 [00:13<00:49,  5.95it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  21%|██        | 76/367 [00:13<00:49,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  21%|██        | 77/367 [00:13<00:45,  6.36it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  21%|██▏       | 78/367 [00:13<00:48,  5.95it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  22%|██▏       | 79/367 [00:13<00:49,  5.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  22%|██▏       | 80/367 [00:13<00:48,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  22%|██▏       | 81/367 [00:14<00:48,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  22%|██▏       | 82/367 [00:14<00:50,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  23%|██▎       | 83/367 [00:14<00:50,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.0606 || acc: 97.50% || lr 7.817e-06:  23%|██▎       | 84/367 [00:14<00:50,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  23%|██▎       | 84/367 [00:14<00:50,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  23%|██▎       | 85/367 [00:14<00:54,  5.20it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  23%|██▎       | 86/367 [00:15<00:51,  5.43it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  24%|██▎       | 87/367 [00:15<00:50,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  24%|██▍       | 88/367 [00:15<00:50,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  24%|██▍       | 89/367 [00:15<00:49,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  25%|██▍       | 90/367 [00:15<00:47,  5.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  25%|██▍       | 91/367 [00:15<00:48,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  25%|██▌       | 92/367 [00:16<00:48,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.68it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  26%|██▌       | 94/367 [00:16<00:47,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  26%|██▌       | 95/367 [00:16<00:45,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  26%|██▌       | 96/367 [00:16<00:45,  6.01it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  26%|██▋       | 97/367 [00:16<00:46,  5.82it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  27%|██▋       | 98/367 [00:17<00:46,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  27%|██▋       | 99/367 [00:17<00:47,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  27%|██▋       | 100/367 [00:17<00:47,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  28%|██▊       | 101/367 [00:17<00:44,  5.93it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  28%|██▊       | 102/367 [00:17<00:48,  5.44it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  28%|██▊       | 103/367 [00:17<00:44,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09469 || acc: 96.25% || lr 7.816e-06:  28%|██▊       | 104/367 [00:18<00:45,  5.83it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  28%|██▊       | 104/367 [00:18<00:45,  5.83it/s] \u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  29%|██▊       | 105/367 [00:18<00:45,  5.78it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  29%|██▉       | 106/367 [00:18<00:44,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  29%|██▉       | 107/367 [00:18<00:45,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  29%|██▉       | 108/367 [00:18<00:42,  6.02it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  30%|██▉       | 109/367 [00:18<00:43,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  30%|██▉       | 110/367 [00:19<00:43,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  30%|███       | 111/367 [00:19<00:46,  5.47it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  31%|███       | 112/367 [00:19<00:46,  5.50it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  31%|███       | 113/367 [00:19<00:46,  5.41it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  31%|███       | 114/367 [00:19<00:44,  5.72it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  31%|███▏      | 115/367 [00:20<00:45,  5.51it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  32%|███▏      | 116/367 [00:20<00:46,  5.34it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  32%|███▏      | 117/367 [00:20<00:43,  5.76it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  32%|███▏      | 118/367 [00:20<00:42,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  32%|███▏      | 119/367 [00:20<00:44,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  33%|███▎      | 120/367 [00:20<00:43,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  33%|███▎      | 121/367 [00:21<00:43,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  33%|███▎      | 122/367 [00:21<00:43,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  34%|███▎      | 123/367 [00:21<00:42,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1074 || acc: 96.25% || lr 7.814e-06:  34%|███▍      | 124/367 [00:21<00:42,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  34%|███▍      | 124/367 [00:21<00:42,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  34%|███▍      | 125/367 [00:21<00:41,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  34%|███▍      | 126/367 [00:22<00:43,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  35%|███▍      | 127/367 [00:22<00:42,  5.67it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  35%|███▍      | 128/367 [00:22<00:41,  5.72it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  35%|███▌      | 129/367 [00:22<00:43,  5.41it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  35%|███▌      | 130/367 [00:22<00:42,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  36%|███▌      | 131/367 [00:22<00:42,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  36%|███▌      | 132/367 [00:23<00:40,  5.83it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  36%|███▌      | 133/367 [00:23<00:37,  6.22it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  37%|███▋      | 134/367 [00:23<00:39,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  37%|███▋      | 135/367 [00:23<00:39,  5.93it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  37%|███▋      | 136/367 [00:23<00:40,  5.75it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  37%|███▋      | 137/367 [00:23<00:42,  5.42it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  38%|███▊      | 138/367 [00:24<00:41,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  38%|███▊      | 139/367 [00:24<00:40,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  38%|███▊      | 140/367 [00:24<00:38,  5.96it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  38%|███▊      | 141/367 [00:24<00:38,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  39%|███▊      | 142/367 [00:24<00:40,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  39%|███▉      | 143/367 [00:25<00:40,  5.49it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06448 || acc: 97.50% || lr 7.813e-06:  39%|███▉      | 144/367 [00:25<00:37,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  39%|███▉      | 144/367 [00:25<00:37,  5.94it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  40%|███▉      | 145/367 [00:25<00:36,  6.05it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  40%|███▉      | 146/367 [00:25<00:36,  5.99it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  40%|████      | 147/367 [00:25<00:37,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  40%|████      | 148/367 [00:25<00:36,  5.93it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  41%|████      | 149/367 [00:25<00:34,  6.26it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  41%|████      | 150/367 [00:26<00:36,  5.96it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  41%|████      | 151/367 [00:26<00:34,  6.34it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  41%|████▏     | 152/367 [00:26<00:35,  5.98it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  42%|████▏     | 153/367 [00:26<00:36,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  42%|████▏     | 154/367 [00:26<00:39,  5.34it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  42%|████▏     | 155/367 [00:27<00:39,  5.43it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  43%|████▎     | 156/367 [00:27<00:39,  5.35it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  43%|████▎     | 157/367 [00:27<00:40,  5.16it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  43%|████▎     | 158/367 [00:27<00:37,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  43%|████▎     | 159/367 [00:27<00:41,  5.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  44%|████▎     | 160/367 [00:28<00:39,  5.24it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  44%|████▍     | 161/367 [00:28<00:40,  5.07it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  44%|████▍     | 162/367 [00:28<00:37,  5.45it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  44%|████▍     | 163/367 [00:28<00:37,  5.49it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.09406 || acc: 95.62% || lr 7.811e-06:  45%|████▍     | 164/367 [00:28<00:36,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  45%|████▍     | 164/367 [00:28<00:36,  5.58it/s] \u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  45%|████▍     | 165/367 [00:28<00:36,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  45%|████▌     | 166/367 [00:29<00:34,  5.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  46%|████▌     | 167/367 [00:29<00:32,  6.22it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  46%|████▌     | 168/367 [00:29<00:30,  6.42it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  46%|████▌     | 169/367 [00:29<00:34,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  46%|████▋     | 170/367 [00:29<00:32,  6.06it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  47%|████▋     | 171/367 [00:29<00:35,  5.53it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  47%|████▋     | 172/367 [00:30<00:34,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  47%|████▋     | 173/367 [00:30<00:31,  6.07it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  47%|████▋     | 174/367 [00:30<00:33,  5.84it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  48%|████▊     | 175/367 [00:30<00:32,  5.92it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  48%|████▊     | 176/367 [00:30<00:32,  5.91it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  48%|████▊     | 177/367 [00:30<00:33,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  49%|████▊     | 178/367 [00:31<00:34,  5.53it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  49%|████▉     | 179/367 [00:31<00:33,  5.56it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  49%|████▉     | 180/367 [00:31<00:33,  5.64it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  49%|████▉     | 181/367 [00:31<00:32,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  50%|████▉     | 182/367 [00:31<00:31,  5.83it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  50%|████▉     | 183/367 [00:31<00:31,  5.81it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.03651 || acc: 99.38% || lr 7.81e-06:  50%|█████     | 184/367 [00:32<00:31,  5.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  50%|█████     | 184/367 [00:32<00:31,  5.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  50%|█████     | 185/367 [00:32<00:31,  5.78it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  51%|█████     | 186/367 [00:32<00:29,  6.14it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  51%|█████     | 187/367 [00:32<00:29,  6.11it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  51%|█████     | 188/367 [00:32<00:30,  5.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  51%|█████▏    | 189/367 [00:32<00:29,  6.00it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  52%|█████▏    | 190/367 [00:33<00:29,  6.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  52%|█████▏    | 191/367 [00:33<00:29,  5.98it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  52%|█████▏    | 192/367 [00:33<00:31,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  53%|█████▎    | 193/367 [00:33<00:31,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  53%|█████▎    | 194/367 [00:33<00:30,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  53%|█████▎    | 195/367 [00:34<00:33,  5.10it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  53%|█████▎    | 196/367 [00:34<00:32,  5.27it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  54%|█████▎    | 197/367 [00:34<00:32,  5.22it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  54%|█████▍    | 198/367 [00:34<00:30,  5.57it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  54%|█████▍    | 199/367 [00:34<00:29,  5.72it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  54%|█████▍    | 200/367 [00:34<00:29,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  55%|█████▍    | 201/367 [00:35<00:28,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  55%|█████▌    | 202/367 [00:35<00:30,  5.46it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  55%|█████▌    | 203/367 [00:35<00:31,  5.21it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06942 || acc: 97.50% || lr 7.808e-06:  56%|█████▌    | 204/367 [00:35<00:29,  5.60it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  56%|█████▌    | 204/367 [00:35<00:29,  5.60it/s]  \u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  56%|█████▌    | 205/367 [00:35<00:28,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  56%|█████▌    | 206/367 [00:36<00:29,  5.42it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  56%|█████▋    | 207/367 [00:36<00:28,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  57%|█████▋    | 208/367 [00:36<00:28,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  57%|█████▋    | 209/367 [00:36<00:29,  5.36it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  57%|█████▋    | 210/367 [00:36<00:31,  5.01it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  57%|█████▋    | 211/367 [00:37<00:30,  5.16it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  58%|█████▊    | 212/367 [00:37<00:29,  5.34it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  58%|█████▊    | 213/367 [00:37<00:28,  5.46it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  58%|█████▊    | 214/367 [00:37<00:30,  5.07it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  59%|█████▊    | 215/367 [00:37<00:29,  5.11it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  59%|█████▉    | 216/367 [00:38<00:28,  5.25it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  59%|█████▉    | 217/367 [00:38<00:27,  5.42it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.36it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  60%|█████▉    | 219/367 [00:38<00:26,  5.50it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  60%|█████▉    | 220/367 [00:38<00:28,  5.09it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  60%|██████    | 221/367 [00:38<00:27,  5.26it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  60%|██████    | 222/367 [00:39<00:26,  5.44it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  61%|██████    | 223/367 [00:39<00:25,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.115 || acc: 96.88% || lr 7.807e-06:  61%|██████    | 224/367 [00:39<00:24,  5.76it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  61%|██████    | 224/367 [00:39<00:24,  5.76it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  61%|██████▏   | 225/367 [00:39<00:24,  5.71it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  62%|██████▏   | 226/367 [00:39<00:24,  5.83it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  62%|██████▏   | 227/367 [00:39<00:24,  5.64it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  62%|██████▏   | 228/367 [00:40<00:24,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  62%|██████▏   | 229/367 [00:40<00:22,  6.17it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  63%|██████▎   | 230/367 [00:40<00:24,  5.61it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  63%|██████▎   | 231/367 [00:40<00:28,  4.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  63%|██████▎   | 232/367 [00:40<00:28,  4.75it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  63%|██████▎   | 233/367 [00:41<00:25,  5.19it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  64%|██████▍   | 234/367 [00:41<00:24,  5.41it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  64%|██████▍   | 235/367 [00:41<00:23,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  64%|██████▍   | 236/367 [00:41<00:23,  5.68it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  65%|██████▍   | 237/367 [00:41<00:22,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  65%|██████▍   | 238/367 [00:41<00:22,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  65%|██████▌   | 239/367 [00:42<00:22,  5.73it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  65%|██████▌   | 240/367 [00:42<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  66%|██████▌   | 241/367 [00:42<00:20,  6.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  66%|██████▌   | 242/367 [00:42<00:21,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  66%|██████▌   | 243/367 [00:42<00:22,  5.53it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07606 || acc: 98.12% || lr 7.806e-06:  66%|██████▋   | 244/367 [00:43<00:22,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  66%|██████▋   | 244/367 [00:43<00:22,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  67%|██████▋   | 245/367 [00:43<00:22,  5.37it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  67%|██████▋   | 246/367 [00:43<00:22,  5.37it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  67%|██████▋   | 247/367 [00:43<00:22,  5.42it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  68%|██████▊   | 248/367 [00:43<00:22,  5.32it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  68%|██████▊   | 249/367 [00:43<00:21,  5.54it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.56it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  68%|██████▊   | 251/367 [00:44<00:21,  5.45it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  69%|██████▊   | 252/367 [00:44<00:22,  5.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  69%|██████▉   | 253/367 [00:44<00:21,  5.25it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  69%|██████▉   | 254/367 [00:44<00:23,  4.86it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  69%|██████▉   | 255/367 [00:45<00:21,  5.28it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  70%|██████▉   | 256/367 [00:45<00:21,  5.23it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  70%|███████   | 257/367 [00:45<00:19,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  70%|███████   | 258/367 [00:45<00:18,  5.81it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  71%|███████   | 259/367 [00:45<00:18,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  71%|███████   | 260/367 [00:45<00:18,  5.82it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  71%|███████   | 261/367 [00:46<00:18,  5.66it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  71%|███████▏  | 262/367 [00:46<00:19,  5.36it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  72%|███████▏  | 263/367 [00:46<00:20,  5.12it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.08366 || acc: 97.50% || lr 7.804e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  72%|███████▏  | 264/367 [00:46<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  72%|███████▏  | 265/367 [00:46<00:17,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  72%|███████▏  | 266/367 [00:47<00:16,  6.08it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.67it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  73%|███████▎  | 268/367 [00:47<00:16,  5.90it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  73%|███████▎  | 269/367 [00:47<00:15,  6.33it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  74%|███████▎  | 270/367 [00:47<00:15,  6.16it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  74%|███████▍  | 271/367 [00:47<00:15,  6.01it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  74%|███████▍  | 273/367 [00:48<00:16,  5.73it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  75%|███████▍  | 274/367 [00:48<00:17,  5.29it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  75%|███████▍  | 275/367 [00:48<00:16,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  75%|███████▌  | 276/367 [00:48<00:15,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  75%|███████▌  | 277/367 [00:48<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.35it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  76%|███████▌  | 279/367 [00:49<00:16,  5.40it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  76%|███████▋  | 280/367 [00:49<00:16,  5.43it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  77%|███████▋  | 281/367 [00:49<00:14,  5.74it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  77%|███████▋  | 282/367 [00:49<00:14,  5.75it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.31it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06494 || acc: 98.12% || lr 7.803e-06:  77%|███████▋  | 284/367 [00:50<00:14,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  77%|███████▋  | 284/367 [00:50<00:14,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  78%|███████▊  | 285/367 [00:50<00:14,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  78%|███████▊  | 286/367 [00:50<00:14,  5.49it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  78%|███████▊  | 287/367 [00:50<00:13,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  78%|███████▊  | 288/367 [00:50<00:15,  5.25it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  79%|███████▊  | 289/367 [00:51<00:15,  5.02it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  79%|███████▉  | 290/367 [00:51<00:14,  5.40it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  79%|███████▉  | 291/367 [00:51<00:13,  5.51it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  80%|███████▉  | 292/367 [00:51<00:13,  5.48it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  80%|███████▉  | 293/367 [00:51<00:13,  5.54it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  80%|████████  | 294/367 [00:52<00:13,  5.58it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  80%|████████  | 295/367 [00:52<00:13,  5.32it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  81%|████████  | 296/367 [00:52<00:13,  5.30it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  81%|████████  | 297/367 [00:52<00:12,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  81%|████████  | 298/367 [00:52<00:12,  5.51it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  81%|████████▏ | 299/367 [00:53<00:12,  5.27it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  82%|████████▏ | 300/367 [00:53<00:12,  5.27it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.27it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  82%|████████▏ | 302/367 [00:53<00:12,  5.10it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  83%|████████▎ | 303/367 [00:53<00:13,  4.89it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.05938 || acc: 98.12% || lr 7.801e-06:  83%|████████▎ | 304/367 [00:54<00:12,  4.99it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  83%|████████▎ | 304/367 [00:54<00:12,  4.99it/s]   \u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  83%|████████▎ | 305/367 [00:54<00:13,  4.73it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  83%|████████▎ | 306/367 [00:54<00:13,  4.61it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  84%|████████▎ | 307/367 [00:54<00:12,  4.92it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  84%|████████▍ | 308/367 [00:54<00:11,  5.15it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  84%|████████▍ | 309/367 [00:55<00:10,  5.37it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.66it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.89it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  85%|████████▌ | 312/367 [00:55<00:10,  5.45it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.82it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  86%|████████▌ | 314/367 [00:55<00:08,  6.03it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  86%|████████▌ | 316/367 [00:56<00:08,  5.98it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  86%|████████▋ | 317/367 [00:56<00:08,  6.02it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.65it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  87%|████████▋ | 319/367 [00:56<00:08,  5.92it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  87%|████████▋ | 320/367 [00:56<00:08,  5.68it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  87%|████████▋ | 321/367 [00:57<00:08,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  88%|████████▊ | 322/367 [00:57<00:07,  5.67it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  88%|████████▊ | 323/367 [00:57<00:07,  5.78it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1224 || acc: 96.88% || lr 7.8e-06:  88%|████████▊ | 324/367 [00:57<00:07,  5.80it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  88%|████████▊ | 324/367 [00:57<00:07,  5.80it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  89%|████████▊ | 325/367 [00:57<00:06,  6.18it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  89%|████████▉ | 326/367 [00:57<00:06,  6.01it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  89%|████████▉ | 327/367 [00:58<00:06,  6.00it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  89%|████████▉ | 328/367 [00:58<00:06,  5.76it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  90%|████████▉ | 329/367 [00:58<00:06,  6.00it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.87it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  90%|█████████ | 332/367 [00:58<00:05,  6.04it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  91%|█████████ | 333/367 [00:59<00:05,  6.45it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  91%|█████████ | 334/367 [00:59<00:05,  5.77it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.69it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  92%|█████████▏| 337/367 [00:59<00:05,  5.35it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  92%|█████████▏| 338/367 [00:59<00:05,  5.47it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  92%|█████████▏| 339/367 [01:00<00:05,  5.51it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.62it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  93%|█████████▎| 341/367 [01:00<00:04,  5.30it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  93%|█████████▎| 342/367 [01:00<00:04,  5.51it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  93%|█████████▎| 343/367 [01:00<00:04,  5.85it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.1141 || acc: 96.88% || lr 7.798e-06:  94%|█████████▎| 344/367 [01:01<00:03,  6.18it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  94%|█████████▎| 344/367 [01:01<00:03,  6.18it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  94%|█████████▍| 345/367 [01:01<00:03,  5.79it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.49it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  95%|█████████▍| 348/367 [01:01<00:03,  5.50it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  95%|█████████▌| 349/367 [01:01<00:03,  5.59it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  95%|█████████▌| 350/367 [01:02<00:02,  5.98it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  96%|█████████▌| 351/367 [01:02<00:02,  6.23it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.53it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.54it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  96%|█████████▋| 354/367 [01:02<00:02,  5.43it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.46it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.57it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.63it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  98%|█████████▊| 359/367 [01:03<00:01,  5.52it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  98%|█████████▊| 360/367 [01:03<00:01,  5.41it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  98%|█████████▊| 361/367 [01:04<00:01,  5.91it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  99%|█████████▊| 362/367 [01:04<00:00,  6.09it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.99it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.06352 || acc: 97.50% || lr 7.797e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07365 || acc: 97.50% || lr 7.795e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.55it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07365 || acc: 97.50% || lr 7.795e-06:  99%|█████████▉| 365/367 [01:04<00:00,  5.19it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07365 || acc: 97.50% || lr 7.795e-06: 100%|█████████▉| 366/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [8/30] || loss: 0.07365 || acc: 97.50% || lr 7.795e-06: 100%|██████████| 367/367 [01:05<00:00,  5.64it/s]\n",
      "\n",
      "[Validation] Epoch 9:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 9:   3%|▎         | 3/92 [00:00<00:04, 22.13it/s]\u001b[A\n",
      "[Validation] Epoch 9:   7%|▋         | 6/92 [00:00<00:04, 20.58it/s]\u001b[A\n",
      "[Validation] Epoch 9:  10%|▉         | 9/92 [00:00<00:04, 18.27it/s]\u001b[A\n",
      "[Validation] Epoch 9:  12%|█▏        | 11/92 [00:00<00:04, 18.17it/s]\u001b[A\n",
      "[Validation] Epoch 9:  14%|█▍        | 13/92 [00:00<00:04, 18.01it/s]\u001b[A\n",
      "[Validation] Epoch 9:  17%|█▋        | 16/92 [00:00<00:03, 19.24it/s]\u001b[A\n",
      "[Validation] Epoch 9:  20%|█▉        | 18/92 [00:00<00:04, 18.17it/s]\u001b[A\n",
      "[Validation] Epoch 9:  22%|██▏       | 20/92 [00:01<00:04, 17.91it/s]\u001b[A\n",
      "[Validation] Epoch 9:  25%|██▌       | 23/92 [00:01<00:03, 19.06it/s]\u001b[A\n",
      "[Validation] Epoch 9:  27%|██▋       | 25/92 [00:01<00:03, 19.19it/s]\u001b[A\n",
      "[Validation] Epoch 9:  30%|███       | 28/92 [00:01<00:03, 19.48it/s]\u001b[A\n",
      "[Validation] Epoch 9:  33%|███▎      | 30/92 [00:01<00:03, 18.10it/s]\u001b[A\n",
      "[Validation] Epoch 9:  35%|███▍      | 32/92 [00:01<00:03, 17.80it/s]\u001b[A\n",
      "[Validation] Epoch 9:  38%|███▊      | 35/92 [00:01<00:03, 18.18it/s]\u001b[A\n",
      "[Validation] Epoch 9:  40%|████      | 37/92 [00:02<00:03, 17.23it/s]\u001b[A\n",
      "[Validation] Epoch 9:  42%|████▏     | 39/92 [00:02<00:03, 17.30it/s]\u001b[A\n",
      "[Validation] Epoch 9:  46%|████▌     | 42/92 [00:02<00:02, 18.06it/s]\u001b[A\n",
      "[Validation] Epoch 9:  48%|████▊     | 44/92 [00:02<00:02, 18.30it/s]\u001b[A\n",
      "[Validation] Epoch 9:  50%|█████     | 46/92 [00:02<00:02, 17.92it/s]\u001b[A\n",
      "[Validation] Epoch 9:  52%|█████▏    | 48/92 [00:02<00:02, 17.34it/s]\u001b[A\n",
      "[Validation] Epoch 9:  54%|█████▍    | 50/92 [00:02<00:02, 17.86it/s]\u001b[A\n",
      "[Validation] Epoch 9:  57%|█████▋    | 52/92 [00:02<00:02, 17.32it/s]\u001b[A\n",
      "[Validation] Epoch 9:  59%|█████▊    | 54/92 [00:02<00:02, 17.70it/s]\u001b[A\n",
      "[Validation] Epoch 9:  61%|██████    | 56/92 [00:03<00:02, 17.68it/s]\u001b[A\n",
      "[Validation] Epoch 9:  64%|██████▍   | 59/92 [00:03<00:01, 18.30it/s]\u001b[A\n",
      "[Validation] Epoch 9:  66%|██████▋   | 61/92 [00:03<00:01, 18.59it/s]\u001b[A\n",
      "[Validation] Epoch 9:  70%|██████▉   | 64/92 [00:03<00:01, 19.34it/s]\u001b[A\n",
      "[Validation] Epoch 9:  72%|███████▏  | 66/92 [00:03<00:01, 19.04it/s]\u001b[A\n",
      "[Validation] Epoch 9:  74%|███████▍  | 68/92 [00:03<00:01, 17.85it/s]\u001b[A\n",
      "[Validation] Epoch 9:  76%|███████▌  | 70/92 [00:03<00:01, 17.94it/s]\u001b[A\n",
      "[Validation] Epoch 9:  78%|███████▊  | 72/92 [00:03<00:01, 17.42it/s]\u001b[A\n",
      "[Validation] Epoch 9:  80%|████████  | 74/92 [00:04<00:01, 17.55it/s]\u001b[A\n",
      "[Validation] Epoch 9:  83%|████████▎ | 76/92 [00:04<00:00, 17.28it/s]\u001b[A\n",
      "[Validation] Epoch 9:  85%|████████▍ | 78/92 [00:04<00:00, 16.98it/s]\u001b[A\n",
      "[Validation] Epoch 9:  87%|████████▋ | 80/92 [00:04<00:00, 17.37it/s]\u001b[A\n",
      "[Validation] Epoch 9:  90%|█████████ | 83/92 [00:04<00:00, 17.59it/s]\u001b[A\n",
      "[Validation] Epoch 9:  92%|█████████▏| 85/92 [00:04<00:00, 17.91it/s]\u001b[A\n",
      "[Validation] Epoch 9:  96%|█████████▌| 88/92 [00:04<00:00, 19.57it/s]\u001b[A\n",
      "[Validation] Epoch 9:  98%|█████████▊| 90/92 [00:04<00:00, 18.81it/s]\u001b[A\n",
      "[Validation] Epoch 9: 100%|██████████| 92/92 [00:05<00:00, 18.63it/s]\u001b[A\n",
      "Validation: [8/30] || loss: 0.02415 || acc: 99.05%: 100%|██████████| 92/92 [00:05<00:00, 18.12it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.9904891304347826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 9/30 [10:52<25:22, 72.50s/it]\n",
      "[Training] Epoch 10:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 10:   0%|          | 1/367 [00:00<00:50,  7.24it/s]\u001b[A\n",
      "[Training] Epoch 10:   1%|          | 2/367 [00:00<00:52,  6.90it/s]\u001b[A\n",
      "[Training] Epoch 10:   1%|          | 3/367 [00:00<01:04,  5.61it/s]\u001b[A\n",
      "[Training] Epoch 10:   1%|          | 4/367 [00:00<01:00,  6.02it/s]\u001b[A\n",
      "[Training] Epoch 10:   1%|▏         | 5/367 [00:00<01:07,  5.39it/s]\u001b[A\n",
      "[Training] Epoch 10:   2%|▏         | 6/367 [00:01<01:04,  5.57it/s]\u001b[A\n",
      "[Training] Epoch 10:   2%|▏         | 7/367 [00:01<01:05,  5.48it/s]\u001b[A\n",
      "[Training] Epoch 10:   2%|▏         | 8/367 [00:01<01:03,  5.61it/s]\u001b[A\n",
      "[Training] Epoch 10:   2%|▏         | 9/367 [00:01<01:01,  5.86it/s]\u001b[A\n",
      "[Training] Epoch 10:   3%|▎         | 10/367 [00:01<01:01,  5.85it/s]\u001b[A\n",
      "[Training] Epoch 10:   3%|▎         | 11/367 [00:01<01:00,  5.84it/s]\u001b[A\n",
      "[Training] Epoch 10:   3%|▎         | 12/367 [00:02<00:58,  6.03it/s]\u001b[A\n",
      "[Training] Epoch 10:   4%|▎         | 13/367 [00:02<01:02,  5.66it/s]\u001b[A\n",
      "[Training] Epoch 10:   4%|▍         | 14/367 [00:02<01:02,  5.67it/s]\u001b[A\n",
      "[Training] Epoch 10:   4%|▍         | 15/367 [00:02<01:04,  5.42it/s]\u001b[A\n",
      "[Training] Epoch 10:   4%|▍         | 16/367 [00:02<01:03,  5.55it/s]\u001b[A\n",
      "[Training] Epoch 10:   5%|▍         | 17/367 [00:02<01:03,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   5%|▍         | 17/367 [00:02<01:03,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   5%|▍         | 18/367 [00:03<01:09,  5.00it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   5%|▌         | 19/367 [00:03<01:07,  5.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   5%|▌         | 20/367 [00:03<01:02,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   6%|▌         | 21/367 [00:03<01:01,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   6%|▌         | 22/367 [00:03<01:02,  5.56it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   6%|▋         | 23/367 [00:04<01:02,  5.54it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   7%|▋         | 24/367 [00:04<00:57,  5.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   7%|▋         | 25/367 [00:04<00:57,  5.91it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   7%|▋         | 26/367 [00:04<00:57,  5.89it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   7%|▋         | 27/367 [00:04<00:57,  5.92it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   8%|▊         | 28/367 [00:04<00:57,  5.90it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   8%|▊         | 29/367 [00:05<00:53,  6.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   8%|▊         | 30/367 [00:05<00:54,  6.14it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   8%|▊         | 31/367 [00:05<00:55,  6.04it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   9%|▊         | 32/367 [00:05<00:56,  5.91it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   9%|▉         | 33/367 [00:05<01:00,  5.54it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:   9%|▉         | 34/367 [00:05<00:57,  5.83it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:  10%|▉         | 35/367 [00:06<00:56,  5.82it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:  10%|▉         | 36/367 [00:06<00:56,  5.87it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.0778 || acc: 81.88% || lr 7.794e-06:  10%|█         | 37/367 [00:06<00:54,  6.06it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  10%|█         | 37/367 [00:06<00:54,  6.06it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  10%|█         | 38/367 [00:06<00:58,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  11%|█         | 39/367 [00:06<00:58,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  11%|█         | 40/367 [00:06<00:58,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  11%|█         | 41/367 [00:07<00:55,  5.92it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  11%|█▏        | 42/367 [00:07<00:55,  5.86it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  12%|█▏        | 43/367 [00:07<00:56,  5.73it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  12%|█▏        | 44/367 [00:07<00:58,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  12%|█▏        | 45/367 [00:07<00:54,  5.96it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  13%|█▎        | 46/367 [00:07<00:51,  6.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  13%|█▎        | 47/367 [00:08<00:50,  6.30it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  13%|█▎        | 48/367 [00:08<00:49,  6.39it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  13%|█▎        | 49/367 [00:08<00:53,  5.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  14%|█▎        | 50/367 [00:08<00:51,  6.13it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  14%|█▍        | 51/367 [00:08<00:54,  5.77it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  14%|█▍        | 52/367 [00:09<00:56,  5.53it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  14%|█▍        | 53/367 [00:09<00:57,  5.49it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  15%|█▍        | 54/367 [00:09<01:02,  4.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  15%|█▍        | 55/367 [00:09<01:08,  4.57it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  15%|█▌        | 56/367 [00:09<01:01,  5.03it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04227 || acc: 98.75% || lr 7.792e-06:  16%|█▌        | 57/367 [00:10<01:00,  5.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  16%|█▌        | 57/367 [00:10<01:00,  5.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  16%|█▌        | 58/367 [00:10<00:57,  5.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  16%|█▌        | 59/367 [00:10<01:01,  4.99it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  16%|█▋        | 60/367 [00:10<00:57,  5.38it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  17%|█▋        | 61/367 [00:10<00:56,  5.41it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  17%|█▋        | 62/367 [00:10<00:56,  5.38it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  17%|█▋        | 63/367 [00:11<00:52,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  17%|█▋        | 64/367 [00:11<00:53,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  18%|█▊        | 65/367 [00:11<00:53,  5.60it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  18%|█▊        | 66/367 [00:11<00:50,  6.00it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  18%|█▊        | 67/367 [00:11<00:51,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  19%|█▊        | 68/367 [00:12<00:53,  5.56it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  19%|█▉        | 69/367 [00:12<00:57,  5.20it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  19%|█▉        | 70/367 [00:12<00:57,  5.13it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  19%|█▉        | 71/367 [00:12<01:01,  4.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  20%|█▉        | 72/367 [00:12<01:01,  4.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  20%|█▉        | 73/367 [00:13<00:59,  4.90it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  20%|██        | 74/367 [00:13<00:56,  5.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  20%|██        | 75/367 [00:13<00:51,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  21%|██        | 76/367 [00:13<00:52,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05105 || acc: 98.12% || lr 7.791e-06:  21%|██        | 77/367 [00:13<00:49,  5.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  21%|██        | 77/367 [00:13<00:49,  5.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  21%|██▏       | 78/367 [00:13<00:48,  5.93it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  22%|██▏       | 79/367 [00:14<00:49,  5.82it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  22%|██▏       | 80/367 [00:14<00:53,  5.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  22%|██▏       | 81/367 [00:14<00:51,  5.56it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  22%|██▏       | 82/367 [00:14<00:45,  6.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  23%|██▎       | 83/367 [00:14<00:45,  6.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  23%|██▎       | 84/367 [00:14<00:49,  5.73it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  23%|██▎       | 85/367 [00:15<00:47,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  23%|██▎       | 86/367 [00:15<00:47,  5.90it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  24%|██▎       | 87/367 [00:15<00:44,  6.26it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  24%|██▍       | 88/367 [00:15<00:45,  6.08it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  24%|██▍       | 89/367 [00:15<00:44,  6.27it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  25%|██▍       | 90/367 [00:15<00:47,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  25%|██▍       | 91/367 [00:16<00:47,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  25%|██▌       | 92/367 [00:16<00:48,  5.71it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  26%|██▌       | 94/367 [00:16<00:46,  5.86it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  26%|██▌       | 95/367 [00:16<00:46,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  26%|██▌       | 96/367 [00:16<00:49,  5.50it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03792 || acc: 98.75% || lr 7.789e-06:  26%|██▋       | 97/367 [00:17<00:47,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  26%|██▋       | 97/367 [00:17<00:47,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  27%|██▋       | 99/367 [00:17<00:44,  5.96it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  27%|██▋       | 100/367 [00:17<00:44,  5.99it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  28%|██▊       | 101/367 [00:17<00:42,  6.30it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  28%|██▊       | 102/367 [00:17<00:41,  6.39it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  28%|██▊       | 103/367 [00:18<00:43,  6.11it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  28%|██▊       | 104/367 [00:18<00:46,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  29%|██▊       | 105/367 [00:18<00:50,  5.20it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  29%|██▉       | 106/367 [00:18<00:48,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  29%|██▉       | 107/367 [00:18<00:47,  5.46it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  29%|██▉       | 108/367 [00:19<00:46,  5.55it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  30%|██▉       | 109/367 [00:19<00:43,  5.89it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  30%|██▉       | 110/367 [00:19<00:44,  5.72it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  30%|███       | 111/367 [00:19<00:45,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  31%|███       | 112/367 [00:19<00:44,  5.71it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  31%|███       | 113/367 [00:19<00:44,  5.75it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  31%|███       | 114/367 [00:20<00:41,  6.04it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  31%|███▏      | 115/367 [00:20<00:42,  5.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  32%|███▏      | 116/367 [00:20<00:42,  5.90it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06679 || acc: 98.75% || lr 7.788e-06:  32%|███▏      | 117/367 [00:20<00:43,  5.81it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  32%|███▏      | 117/367 [00:20<00:43,  5.81it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  32%|███▏      | 118/367 [00:20<00:42,  5.82it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  32%|███▏      | 119/367 [00:20<00:42,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  33%|███▎      | 120/367 [00:21<00:42,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  33%|███▎      | 121/367 [00:21<00:43,  5.64it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  33%|███▎      | 122/367 [00:21<00:42,  5.74it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  34%|███▎      | 123/367 [00:21<00:44,  5.45it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  34%|███▍      | 124/367 [00:21<00:44,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  34%|███▍      | 125/367 [00:21<00:41,  5.83it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  34%|███▍      | 126/367 [00:22<00:41,  5.77it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  35%|███▍      | 127/367 [00:22<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  35%|███▍      | 128/367 [00:22<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  35%|███▌      | 129/367 [00:22<00:40,  5.87it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  35%|███▌      | 130/367 [00:22<00:42,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  36%|███▌      | 131/367 [00:23<00:42,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  36%|███▌      | 132/367 [00:23<00:46,  5.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  36%|███▌      | 133/367 [00:23<00:43,  5.32it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  37%|███▋      | 134/367 [00:23<00:45,  5.07it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  37%|███▋      | 135/367 [00:23<00:41,  5.57it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  37%|███▋      | 136/367 [00:24<00:43,  5.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03411 || acc: 98.12% || lr 7.787e-06:  37%|███▋      | 137/367 [00:24<00:44,  5.19it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  37%|███▋      | 137/367 [00:24<00:44,  5.19it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  38%|███▊      | 138/367 [00:24<00:44,  5.12it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  38%|███▊      | 139/367 [00:24<00:41,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  38%|███▊      | 140/367 [00:24<00:38,  5.95it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  38%|███▊      | 141/367 [00:24<00:36,  6.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  39%|███▊      | 142/367 [00:25<00:38,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  39%|███▉      | 143/367 [00:25<00:37,  5.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  39%|███▉      | 144/367 [00:25<00:35,  6.27it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  40%|███▉      | 145/367 [00:25<00:35,  6.20it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  40%|███▉      | 146/367 [00:25<00:36,  6.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  40%|████      | 147/367 [00:25<00:36,  6.00it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  40%|████      | 148/367 [00:26<00:38,  5.76it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  41%|████      | 149/367 [00:26<00:35,  6.12it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  41%|████      | 150/367 [00:26<00:35,  6.04it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  41%|████      | 151/367 [00:26<00:34,  6.20it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  41%|████▏     | 152/367 [00:26<00:34,  6.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  42%|████▏     | 153/367 [00:26<00:36,  5.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  42%|████▏     | 154/367 [00:27<00:35,  5.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  42%|████▏     | 155/367 [00:27<00:34,  6.14it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  43%|████▎     | 156/367 [00:27<00:36,  5.85it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04517 || acc: 98.12% || lr 7.785e-06:  43%|████▎     | 157/367 [00:27<00:33,  6.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  43%|████▎     | 157/367 [00:27<00:33,  6.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  43%|████▎     | 158/367 [00:27<00:37,  5.60it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  43%|████▎     | 159/367 [00:27<00:36,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  44%|████▎     | 160/367 [00:28<00:38,  5.31it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  44%|████▍     | 161/367 [00:28<00:37,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  44%|████▍     | 162/367 [00:28<00:37,  5.40it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  44%|████▍     | 163/367 [00:28<00:37,  5.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  45%|████▍     | 164/367 [00:28<00:35,  5.73it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  45%|████▍     | 165/367 [00:29<00:35,  5.76it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  45%|████▌     | 166/367 [00:29<00:35,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  46%|████▌     | 167/367 [00:29<00:35,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  46%|████▌     | 168/367 [00:29<00:35,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  46%|████▌     | 169/367 [00:29<00:35,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  46%|████▋     | 170/367 [00:29<00:36,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  47%|████▋     | 171/367 [00:30<00:35,  5.46it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  47%|████▋     | 172/367 [00:30<00:37,  5.25it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  47%|████▋     | 173/367 [00:30<00:36,  5.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  47%|████▋     | 174/367 [00:30<00:33,  5.77it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  48%|████▊     | 175/367 [00:30<00:30,  6.27it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  48%|████▊     | 176/367 [00:30<00:31,  6.10it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.04115 || acc: 98.12% || lr 7.784e-06:  48%|████▊     | 177/367 [00:31<00:34,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  48%|████▊     | 177/367 [00:31<00:34,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  49%|████▊     | 178/367 [00:31<00:33,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  49%|████▉     | 179/367 [00:31<00:33,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  49%|████▉     | 180/367 [00:31<00:31,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  49%|████▉     | 181/367 [00:31<00:32,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  50%|████▉     | 182/367 [00:32<00:32,  5.69it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  50%|████▉     | 183/367 [00:32<00:33,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  50%|█████     | 184/367 [00:32<00:33,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  50%|█████     | 185/367 [00:32<00:33,  5.41it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  51%|█████     | 186/367 [00:32<00:32,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  51%|█████     | 187/367 [00:32<00:30,  5.90it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  51%|█████     | 188/367 [00:33<00:30,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  51%|█████▏    | 189/367 [00:33<00:30,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  52%|█████▏    | 190/367 [00:33<00:30,  5.85it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  52%|█████▏    | 191/367 [00:33<00:30,  5.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  52%|█████▏    | 192/367 [00:33<00:31,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  53%|█████▎    | 193/367 [00:33<00:29,  5.82it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  53%|█████▎    | 194/367 [00:34<00:29,  5.87it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  53%|█████▎    | 195/367 [00:34<00:27,  6.33it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  53%|█████▎    | 196/367 [00:34<00:27,  6.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.06324 || acc: 98.12% || lr 7.782e-06:  54%|█████▎    | 197/367 [00:34<00:26,  6.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  54%|█████▎    | 197/367 [00:34<00:26,  6.37it/s] \u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  54%|█████▍    | 198/367 [00:34<00:30,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  54%|█████▍    | 199/367 [00:34<00:29,  5.70it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  54%|█████▍    | 200/367 [00:35<00:28,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  55%|█████▍    | 201/367 [00:35<00:29,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  55%|█████▌    | 202/367 [00:35<00:29,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  55%|█████▌    | 203/367 [00:35<00:29,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  56%|█████▌    | 204/367 [00:35<00:28,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  56%|█████▌    | 205/367 [00:36<00:28,  5.75it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  56%|█████▌    | 206/367 [00:36<00:27,  5.84it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  56%|█████▋    | 207/367 [00:36<00:28,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  57%|█████▋    | 208/367 [00:36<00:28,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  57%|█████▋    | 209/367 [00:36<00:28,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  57%|█████▋    | 210/367 [00:36<00:26,  5.92it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  57%|█████▋    | 211/367 [00:37<00:27,  5.72it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  58%|█████▊    | 212/367 [00:37<00:27,  5.70it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  58%|█████▊    | 213/367 [00:37<00:27,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  58%|█████▊    | 214/367 [00:37<00:26,  5.70it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  59%|█████▊    | 215/367 [00:37<00:27,  5.54it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  59%|█████▉    | 216/367 [00:37<00:26,  5.60it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.1065 || acc: 97.50% || lr 7.781e-06:  59%|█████▉    | 217/367 [00:38<00:26,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  59%|█████▉    | 217/367 [00:38<00:26,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  59%|█████▉    | 218/367 [00:38<00:26,  5.64it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  60%|█████▉    | 219/367 [00:38<00:26,  5.61it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  60%|█████▉    | 220/367 [00:38<00:26,  5.55it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  60%|██████    | 221/367 [00:38<00:24,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  60%|██████    | 222/367 [00:39<00:26,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  61%|██████    | 223/367 [00:39<00:26,  5.52it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  61%|██████    | 224/367 [00:39<00:26,  5.45it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  61%|██████▏   | 225/367 [00:39<00:25,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  62%|██████▏   | 226/367 [00:39<00:24,  5.83it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  62%|██████▏   | 227/367 [00:39<00:23,  6.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  62%|██████▏   | 228/367 [00:40<00:21,  6.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  62%|██████▏   | 229/367 [00:40<00:21,  6.39it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  63%|██████▎   | 230/367 [00:40<00:22,  6.12it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  63%|██████▎   | 231/367 [00:40<00:22,  5.94it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  63%|██████▎   | 232/367 [00:40<00:22,  5.95it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  63%|██████▎   | 233/367 [00:40<00:24,  5.42it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  64%|██████▍   | 234/367 [00:41<00:23,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  64%|██████▍   | 235/367 [00:41<00:24,  5.33it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  64%|██████▍   | 236/367 [00:41<00:25,  5.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08566 || acc: 95.62% || lr 7.779e-06:  65%|██████▍   | 237/367 [00:41<00:24,  5.21it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  65%|██████▍   | 237/367 [00:41<00:24,  5.21it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  65%|██████▍   | 238/367 [00:41<00:25,  5.10it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  65%|██████▌   | 239/367 [00:42<00:24,  5.29it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  65%|██████▌   | 240/367 [00:42<00:23,  5.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  66%|██████▌   | 241/367 [00:42<00:22,  5.65it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  66%|██████▌   | 242/367 [00:42<00:20,  6.01it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  66%|██████▌   | 243/367 [00:42<00:20,  6.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  66%|██████▋   | 244/367 [00:42<00:21,  5.76it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  67%|██████▋   | 245/367 [00:43<00:22,  5.31it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  67%|██████▋   | 246/367 [00:43<00:23,  5.06it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  67%|██████▋   | 247/367 [00:43<00:23,  5.04it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  68%|██████▊   | 248/367 [00:43<00:21,  5.44it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  68%|██████▊   | 249/367 [00:43<00:21,  5.42it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  68%|██████▊   | 251/367 [00:44<00:21,  5.47it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  69%|██████▊   | 252/367 [00:44<00:20,  5.64it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  69%|██████▉   | 253/367 [00:44<00:21,  5.40it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  69%|██████▉   | 254/367 [00:44<00:21,  5.29it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  69%|██████▉   | 255/367 [00:45<00:21,  5.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  70%|██████▉   | 256/367 [00:45<00:21,  5.25it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.02025 || acc: 100.00% || lr 7.778e-06:  70%|███████   | 257/367 [00:45<00:20,  5.29it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  70%|███████   | 257/367 [00:45<00:20,  5.29it/s] \u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  70%|███████   | 258/367 [00:45<00:21,  5.00it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  71%|███████   | 259/367 [00:45<00:22,  4.87it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  71%|███████   | 260/367 [00:46<00:22,  4.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  71%|███████   | 261/367 [00:46<00:19,  5.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  71%|███████▏  | 262/367 [00:46<00:19,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  72%|███████▏  | 263/367 [00:46<00:19,  5.46it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  72%|███████▏  | 264/367 [00:46<00:19,  5.30it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  72%|███████▏  | 265/367 [00:46<00:18,  5.66it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.70it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  73%|███████▎  | 268/367 [00:47<00:17,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  73%|███████▎  | 269/367 [00:47<00:18,  5.34it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  74%|███████▎  | 270/367 [00:47<00:17,  5.49it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  74%|███████▍  | 271/367 [00:47<00:17,  5.55it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  74%|███████▍  | 272/367 [00:48<00:17,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  74%|███████▍  | 273/367 [00:48<00:16,  5.57it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  75%|███████▍  | 274/367 [00:48<00:16,  5.73it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  75%|███████▍  | 275/367 [00:48<00:15,  5.91it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  75%|███████▌  | 276/367 [00:48<00:14,  6.16it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05828 || acc: 98.75% || lr 7.776e-06:  75%|███████▌  | 277/367 [00:48<00:14,  6.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  75%|███████▌  | 277/367 [00:48<00:14,  6.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  76%|███████▌  | 278/367 [00:49<00:14,  6.04it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  76%|███████▌  | 279/367 [00:49<00:14,  6.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  76%|███████▋  | 280/367 [00:49<00:15,  5.71it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  77%|███████▋  | 281/367 [00:49<00:16,  5.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  77%|███████▋  | 282/367 [00:49<00:16,  5.15it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  77%|███████▋  | 283/367 [00:50<00:16,  4.94it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  77%|███████▋  | 284/367 [00:50<00:17,  4.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  78%|███████▊  | 285/367 [00:50<00:16,  5.01it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  78%|███████▊  | 286/367 [00:50<00:15,  5.14it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  78%|███████▊  | 287/367 [00:50<00:14,  5.60it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  78%|███████▊  | 288/367 [00:51<00:13,  5.71it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.59it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  79%|███████▉  | 290/367 [00:51<00:13,  5.89it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  79%|███████▉  | 291/367 [00:51<00:14,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  80%|███████▉  | 292/367 [00:51<00:13,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  80%|███████▉  | 293/367 [00:51<00:14,  5.23it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  80%|████████  | 294/367 [00:52<00:13,  5.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  80%|████████  | 295/367 [00:52<00:13,  5.33it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  81%|████████  | 296/367 [00:52<00:13,  5.33it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.05586 || acc: 97.50% || lr 7.775e-06:  81%|████████  | 297/367 [00:52<00:14,  4.74it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  81%|████████  | 297/367 [00:52<00:14,  4.74it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  81%|████████  | 298/367 [00:53<00:14,  4.80it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  81%|████████▏ | 299/367 [00:53<00:12,  5.26it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  82%|████████▏ | 300/367 [00:53<00:13,  4.95it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.35it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  82%|████████▏ | 302/367 [00:53<00:11,  5.54it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  83%|████████▎ | 303/367 [00:53<00:12,  5.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  83%|████████▎ | 304/367 [00:54<00:11,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  83%|████████▎ | 306/367 [00:54<00:11,  5.33it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  84%|████████▎ | 307/367 [00:54<00:10,  5.49it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  84%|████████▍ | 308/367 [00:54<00:10,  5.56it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  84%|████████▍ | 309/367 [00:55<00:11,  5.21it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  85%|████████▌ | 312/367 [00:55<00:10,  5.41it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  85%|████████▌ | 313/367 [00:55<00:10,  5.12it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  86%|████████▌ | 314/367 [00:55<00:10,  4.96it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.24it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.39it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08805 || acc: 98.12% || lr 7.773e-06:  86%|████████▋ | 317/367 [00:56<00:08,  5.72it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  86%|████████▋ | 317/367 [00:56<00:08,  5.72it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  87%|████████▋ | 318/367 [00:56<00:08,  5.97it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  87%|████████▋ | 319/367 [00:56<00:07,  6.18it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  87%|████████▋ | 320/367 [00:57<00:08,  5.32it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  87%|████████▋ | 321/367 [00:57<00:09,  4.98it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.17it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  88%|████████▊ | 323/367 [00:57<00:08,  5.38it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  88%|████████▊ | 324/367 [00:57<00:07,  5.72it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  89%|████████▊ | 325/367 [00:57<00:07,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.58it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.53it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  89%|████████▉ | 328/367 [00:58<00:06,  5.68it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  90%|████████▉ | 329/367 [00:58<00:06,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  90%|████████▉ | 330/367 [00:58<00:06,  6.17it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.65it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  90%|█████████ | 332/367 [00:59<00:05,  6.07it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  91%|█████████ | 333/367 [00:59<00:06,  5.60it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  91%|█████████ | 334/367 [00:59<00:05,  5.88it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  91%|█████████▏| 335/367 [00:59<00:05,  5.92it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  92%|█████████▏| 336/367 [00:59<00:05,  5.40it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08403 || acc: 96.25% || lr 7.772e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.46it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.46it/s] \u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  92%|█████████▏| 338/367 [01:00<00:05,  5.51it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  92%|█████████▏| 339/367 [01:00<00:04,  5.82it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  93%|█████████▎| 340/367 [01:00<00:04,  5.86it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  93%|█████████▎| 341/367 [01:00<00:04,  6.09it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  93%|█████████▎| 342/367 [01:00<00:04,  6.02it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.39it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  94%|█████████▍| 345/367 [01:01<00:03,  5.50it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  94%|█████████▍| 346/367 [01:01<00:03,  5.49it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.48it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.05it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.28it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  96%|█████████▌| 351/367 [01:02<00:02,  5.43it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.56it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.62it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.63it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  97%|█████████▋| 355/367 [01:03<00:01,  6.29it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  97%|█████████▋| 356/367 [01:03<00:01,  6.20it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.08124 || acc: 97.50% || lr 7.77e-06:  97%|█████████▋| 357/367 [01:03<00:01,  6.13it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  97%|█████████▋| 357/367 [01:03<00:01,  6.13it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.79it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  98%|█████████▊| 359/367 [01:03<00:01,  5.78it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.85it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  98%|█████████▊| 361/367 [01:04<00:00,  6.19it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  99%|█████████▊| 362/367 [01:04<00:00,  6.01it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.37it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.68it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06:  99%|█████████▉| 365/367 [01:04<00:00,  5.67it/s]\u001b[A\n",
      "Epoch: [9/30] || loss: 0.03515 || acc: 98.75% || lr 7.769e-06: 100%|██████████| 367/367 [01:05<00:00,  5.63it/s]\n",
      "\n",
      "[Validation] Epoch 10:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 10:   3%|▎         | 3/92 [00:00<00:03, 23.57it/s]\u001b[A\n",
      "[Validation] Epoch 10:   7%|▋         | 6/92 [00:00<00:04, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 10:   9%|▊         | 8/92 [00:00<00:04, 17.94it/s]\u001b[A\n",
      "[Validation] Epoch 10:  11%|█         | 10/92 [00:00<00:04, 16.95it/s]\u001b[A\n",
      "[Validation] Epoch 10:  13%|█▎        | 12/92 [00:00<00:04, 17.52it/s]\u001b[A\n",
      "[Validation] Epoch 10:  15%|█▌        | 14/92 [00:00<00:04, 17.84it/s]\u001b[A\n",
      "[Validation] Epoch 10:  17%|█▋        | 16/92 [00:00<00:04, 18.34it/s]\u001b[A\n",
      "[Validation] Epoch 10:  21%|██        | 19/92 [00:01<00:03, 18.45it/s]\u001b[A\n",
      "[Validation] Epoch 10:  24%|██▍       | 22/92 [00:01<00:03, 18.87it/s]\u001b[A\n",
      "[Validation] Epoch 10:  27%|██▋       | 25/92 [00:01<00:03, 18.76it/s]\u001b[A\n",
      "[Validation] Epoch 10:  29%|██▉       | 27/92 [00:01<00:03, 18.30it/s]\u001b[A\n",
      "[Validation] Epoch 10:  32%|███▏      | 29/92 [00:01<00:03, 17.92it/s]\u001b[A\n",
      "[Validation] Epoch 10:  34%|███▎      | 31/92 [00:01<00:03, 17.44it/s]\u001b[A\n",
      "[Validation] Epoch 10:  36%|███▌      | 33/92 [00:01<00:03, 17.49it/s]\u001b[A\n",
      "[Validation] Epoch 10:  38%|███▊      | 35/92 [00:01<00:03, 18.06it/s]\u001b[A\n",
      "[Validation] Epoch 10:  40%|████      | 37/92 [00:02<00:02, 18.39it/s]\u001b[A\n",
      "[Validation] Epoch 10:  42%|████▏     | 39/92 [00:02<00:02, 18.09it/s]\u001b[A\n",
      "[Validation] Epoch 10:  45%|████▍     | 41/92 [00:02<00:02, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 10:  47%|████▋     | 43/92 [00:02<00:02, 17.75it/s]\u001b[A\n",
      "[Validation] Epoch 10:  50%|█████     | 46/92 [00:02<00:02, 19.36it/s]\u001b[A\n",
      "[Validation] Epoch 10:  52%|█████▏    | 48/92 [00:02<00:02, 18.72it/s]\u001b[A\n",
      "[Validation] Epoch 10:  54%|█████▍    | 50/92 [00:02<00:02, 18.38it/s]\u001b[A\n",
      "[Validation] Epoch 10:  57%|█████▋    | 52/92 [00:02<00:02, 18.68it/s]\u001b[A\n",
      "[Validation] Epoch 10:  59%|█████▊    | 54/92 [00:02<00:02, 18.60it/s]\u001b[A\n",
      "[Validation] Epoch 10:  62%|██████▏   | 57/92 [00:03<00:01, 19.46it/s]\u001b[A\n",
      "[Validation] Epoch 10:  64%|██████▍   | 59/92 [00:03<00:01, 18.54it/s]\u001b[A\n",
      "[Validation] Epoch 10:  66%|██████▋   | 61/92 [00:03<00:01, 17.86it/s]\u001b[A\n",
      "[Validation] Epoch 10:  68%|██████▊   | 63/92 [00:03<00:01, 17.72it/s]\u001b[A\n",
      "[Validation] Epoch 10:  71%|███████   | 65/92 [00:03<00:01, 16.72it/s]\u001b[A\n",
      "[Validation] Epoch 10:  73%|███████▎  | 67/92 [00:03<00:01, 17.09it/s]\u001b[A\n",
      "[Validation] Epoch 10:  75%|███████▌  | 69/92 [00:03<00:01, 16.52it/s]\u001b[A\n",
      "[Validation] Epoch 10:  78%|███████▊  | 72/92 [00:03<00:01, 17.29it/s]\u001b[A\n",
      "[Validation] Epoch 10:  80%|████████  | 74/92 [00:04<00:01, 17.04it/s]\u001b[A\n",
      "[Validation] Epoch 10:  83%|████████▎ | 76/92 [00:04<00:00, 16.96it/s]\u001b[A\n",
      "[Validation] Epoch 10:  85%|████████▍ | 78/92 [00:04<00:00, 17.31it/s]\u001b[A\n",
      "[Validation] Epoch 10:  87%|████████▋ | 80/92 [00:04<00:00, 17.55it/s]\u001b[A\n",
      "[Validation] Epoch 10:  89%|████████▉ | 82/92 [00:04<00:00, 18.15it/s]\u001b[A\n",
      "[Validation] Epoch 10:  91%|█████████▏| 84/92 [00:04<00:00, 18.22it/s]\u001b[A\n",
      "[Validation] Epoch 10:  93%|█████████▎| 86/92 [00:04<00:00, 17.61it/s]\u001b[A\n",
      "[Validation] Epoch 10:  96%|█████████▌| 88/92 [00:04<00:00, 17.92it/s]\u001b[A\n",
      "[Validation] Epoch 10:  99%|█████████▉| 91/92 [00:05<00:00, 18.47it/s]\u001b[A\n",
      "Validation: [9/30] || loss: 0.02005 || acc: 99.05%: 100%|██████████| 92/92 [00:05<00:00, 17.91it/s]\n",
      " 33%|███▎      | 10/30 [12:03<23:57, 71.85s/it]\n",
      "[Training] Epoch 11:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 11:   0%|          | 1/367 [00:00<00:55,  6.59it/s]\u001b[A\n",
      "[Training] Epoch 11:   1%|          | 2/367 [00:00<00:58,  6.29it/s]\u001b[A\n",
      "[Training] Epoch 11:   1%|          | 3/367 [00:00<01:07,  5.41it/s]\u001b[A\n",
      "[Training] Epoch 11:   1%|          | 4/367 [00:00<01:05,  5.51it/s]\u001b[A\n",
      "[Training] Epoch 11:   1%|▏         | 5/367 [00:00<01:03,  5.70it/s]\u001b[A\n",
      "[Training] Epoch 11:   2%|▏         | 6/367 [00:01<01:10,  5.15it/s]\u001b[A\n",
      "[Training] Epoch 11:   2%|▏         | 7/367 [00:01<01:08,  5.26it/s]\u001b[A\n",
      "[Training] Epoch 11:   2%|▏         | 8/367 [00:01<01:08,  5.24it/s]\u001b[A\n",
      "[Training] Epoch 11:   2%|▏         | 9/367 [00:01<01:03,  5.63it/s]\u001b[A\n",
      "[Training] Epoch 11:   3%|▎         | 10/367 [00:01<01:02,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   3%|▎         | 10/367 [00:01<01:02,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   3%|▎         | 11/367 [00:01<01:02,  5.71it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   3%|▎         | 12/367 [00:02<01:02,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   4%|▎         | 13/367 [00:02<01:01,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   4%|▍         | 14/367 [00:02<01:02,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   4%|▍         | 15/367 [00:02<01:00,  5.78it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   4%|▍         | 16/367 [00:02<01:05,  5.38it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   5%|▍         | 17/367 [00:03<01:01,  5.70it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   5%|▍         | 18/367 [00:03<01:04,  5.41it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   5%|▌         | 19/367 [00:03<01:07,  5.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   5%|▌         | 20/367 [00:03<01:07,  5.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   6%|▌         | 21/367 [00:03<01:04,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   6%|▌         | 22/367 [00:04<01:07,  5.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   6%|▋         | 23/367 [00:04<01:05,  5.25it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   7%|▋         | 24/367 [00:04<01:08,  5.03it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   7%|▋         | 25/367 [00:04<01:05,  5.26it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   7%|▋         | 26/367 [00:04<01:08,  4.95it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   7%|▋         | 27/367 [00:05<01:10,  4.80it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   8%|▊         | 28/367 [00:05<01:07,  5.00it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   8%|▊         | 29/367 [00:05<01:05,  5.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0381 || acc: 48.12% || lr 7.768e-06:   8%|▊         | 30/367 [00:05<01:03,  5.34it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:   8%|▊         | 30/367 [00:05<01:03,  5.34it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:   8%|▊         | 31/367 [00:05<01:03,  5.25it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:   9%|▊         | 32/367 [00:05<01:06,  5.06it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:   9%|▉         | 33/367 [00:06<01:02,  5.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:   9%|▉         | 34/367 [00:06<01:04,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  10%|▉         | 35/367 [00:06<01:00,  5.50it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  10%|▉         | 36/367 [00:06<00:58,  5.68it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  10%|█         | 37/367 [00:06<00:58,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  10%|█         | 38/367 [00:07<01:01,  5.32it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  11%|█         | 39/367 [00:07<00:58,  5.59it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  11%|█         | 40/367 [00:07<01:01,  5.34it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  11%|█         | 41/367 [00:07<00:58,  5.62it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  11%|█▏        | 42/367 [00:07<00:58,  5.58it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  12%|█▏        | 43/367 [00:07<00:56,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  12%|█▏        | 44/367 [00:08<00:53,  6.05it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  12%|█▏        | 45/367 [00:08<00:59,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  13%|█▎        | 46/367 [00:08<00:58,  5.47it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  13%|█▎        | 47/367 [00:08<00:55,  5.76it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  13%|█▎        | 48/367 [00:08<00:52,  6.04it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  13%|█▎        | 49/367 [00:08<00:50,  6.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.766e-06:  14%|█▎        | 50/367 [00:09<00:52,  6.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  14%|█▎        | 50/367 [00:09<00:52,  6.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  14%|█▍        | 51/367 [00:09<00:47,  6.61it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  14%|█▍        | 52/367 [00:09<00:52,  5.99it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  14%|█▍        | 53/367 [00:09<00:55,  5.67it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  15%|█▍        | 54/367 [00:09<00:55,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  15%|█▍        | 55/367 [00:09<00:55,  5.66it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  15%|█▌        | 56/367 [00:10<00:50,  6.12it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  16%|█▌        | 57/367 [00:10<00:52,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  16%|█▌        | 58/367 [00:10<00:54,  5.71it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  16%|█▌        | 59/367 [00:10<00:53,  5.76it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  16%|█▋        | 60/367 [00:10<00:52,  5.82it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  17%|█▋        | 61/367 [00:11<00:52,  5.88it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  17%|█▋        | 62/367 [00:11<00:49,  6.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  17%|█▋        | 63/367 [00:11<00:49,  6.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  17%|█▋        | 64/367 [00:11<00:48,  6.20it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  18%|█▊        | 65/367 [00:11<00:50,  6.02it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  18%|█▊        | 66/367 [00:11<00:56,  5.36it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  18%|█▊        | 67/367 [00:12<00:55,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  19%|█▊        | 68/367 [00:12<00:57,  5.22it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  19%|█▉        | 69/367 [00:12<00:56,  5.25it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01607 || acc: 100.00% || lr 7.765e-06:  19%|█▉        | 70/367 [00:12<00:54,  5.41it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  19%|█▉        | 70/367 [00:12<00:54,  5.41it/s] \u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  19%|█▉        | 71/367 [00:12<00:52,  5.68it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  20%|█▉        | 72/367 [00:12<00:52,  5.59it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  20%|█▉        | 73/367 [00:13<00:52,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  20%|██        | 74/367 [00:13<00:53,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  20%|██        | 75/367 [00:13<00:54,  5.36it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  21%|██        | 76/367 [00:13<00:50,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  21%|██        | 77/367 [00:13<00:50,  5.70it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  21%|██▏       | 78/367 [00:14<00:50,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  22%|██▏       | 79/367 [00:14<00:45,  6.30it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  22%|██▏       | 80/367 [00:14<00:44,  6.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  22%|██▏       | 81/367 [00:14<00:47,  6.00it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  22%|██▏       | 82/367 [00:14<00:45,  6.26it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  23%|██▎       | 83/367 [00:14<00:43,  6.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  23%|██▎       | 84/367 [00:14<00:44,  6.39it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  23%|██▎       | 85/367 [00:15<00:46,  6.03it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  23%|██▎       | 86/367 [00:15<00:47,  5.90it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  24%|██▎       | 87/367 [00:15<00:47,  5.89it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  24%|██▍       | 88/367 [00:15<00:51,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  24%|██▍       | 89/367 [00:15<00:50,  5.52it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08593 || acc: 98.12% || lr 7.763e-06:  25%|██▍       | 90/367 [00:16<00:50,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  25%|██▍       | 90/367 [00:16<00:50,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  25%|██▍       | 91/367 [00:16<00:48,  5.73it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  25%|██▌       | 92/367 [00:16<00:47,  5.82it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  25%|██▌       | 93/367 [00:16<00:48,  5.62it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  26%|██▌       | 94/367 [00:16<00:48,  5.62it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  26%|██▌       | 95/367 [00:16<00:49,  5.50it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  26%|██▌       | 96/367 [00:17<00:46,  5.80it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  26%|██▋       | 97/367 [00:17<00:44,  6.05it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  27%|██▋       | 98/367 [00:17<00:46,  5.78it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  27%|██▋       | 99/367 [00:17<00:47,  5.60it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  27%|██▋       | 100/367 [00:17<00:49,  5.34it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  28%|██▊       | 101/367 [00:17<00:48,  5.50it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  28%|██▊       | 102/367 [00:18<00:51,  5.15it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  28%|██▊       | 103/367 [00:18<00:50,  5.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  28%|██▊       | 104/367 [00:18<00:50,  5.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  29%|██▊       | 105/367 [00:18<00:47,  5.56it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  29%|██▉       | 106/367 [00:18<00:47,  5.47it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  29%|██▉       | 107/367 [00:19<00:44,  5.82it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  29%|██▉       | 108/367 [00:19<00:41,  6.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  30%|██▉       | 109/367 [00:19<00:39,  6.46it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.03052 || acc: 98.75% || lr 7.762e-06:  30%|██▉       | 110/367 [00:19<00:40,  6.27it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  30%|██▉       | 110/367 [00:19<00:40,  6.27it/s]  \u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  30%|███       | 111/367 [00:19<00:41,  6.14it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  31%|███       | 112/367 [00:19<00:41,  6.10it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  31%|███       | 113/367 [00:20<00:42,  5.99it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  31%|███       | 114/367 [00:20<00:43,  5.84it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  31%|███▏      | 115/367 [00:20<00:41,  6.04it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  32%|███▏      | 116/367 [00:20<00:42,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  32%|███▏      | 117/367 [00:20<00:45,  5.45it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  32%|███▏      | 118/367 [00:20<00:45,  5.45it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  32%|███▏      | 119/367 [00:21<00:45,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  33%|███▎      | 120/367 [00:21<00:43,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  33%|███▎      | 121/367 [00:21<00:40,  6.13it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  33%|███▎      | 122/367 [00:21<00:43,  5.65it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  34%|███▎      | 123/367 [00:21<00:42,  5.77it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  34%|███▍      | 124/367 [00:21<00:41,  5.87it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  34%|███▍      | 125/367 [00:22<00:39,  6.10it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  34%|███▍      | 126/367 [00:22<00:40,  5.99it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  35%|███▍      | 127/367 [00:22<00:40,  5.86it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  35%|███▍      | 128/367 [00:22<00:40,  5.87it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  35%|███▌      | 129/367 [00:22<00:42,  5.66it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.0728 || acc: 97.50% || lr 7.76e-06:  35%|███▌      | 130/367 [00:23<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  35%|███▌      | 130/367 [00:23<00:42,  5.61it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  36%|███▌      | 131/367 [00:23<00:43,  5.47it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  36%|███▌      | 132/367 [00:23<00:42,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  36%|███▌      | 133/367 [00:23<00:40,  5.81it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  37%|███▋      | 134/367 [00:23<00:42,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  37%|███▋      | 135/367 [00:23<00:43,  5.28it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  37%|███▋      | 136/367 [00:24<00:43,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  37%|███▋      | 137/367 [00:24<00:42,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  38%|███▊      | 138/367 [00:24<00:38,  5.91it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  38%|███▊      | 139/367 [00:24<00:39,  5.84it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  38%|███▊      | 140/367 [00:24<00:40,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  38%|███▊      | 141/367 [00:24<00:40,  5.60it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  39%|███▊      | 142/367 [00:25<00:40,  5.59it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  39%|███▉      | 143/367 [00:25<00:45,  4.88it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  39%|███▉      | 144/367 [00:25<00:42,  5.30it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  40%|███▉      | 145/367 [00:25<00:39,  5.62it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  40%|███▉      | 146/367 [00:25<00:38,  5.67it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  40%|████      | 147/367 [00:26<00:36,  6.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  40%|████      | 148/367 [00:26<00:35,  6.25it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  41%|████      | 149/367 [00:26<00:34,  6.30it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01177 || acc: 100.00% || lr 7.759e-06:  41%|████      | 150/367 [00:26<00:33,  6.51it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  41%|████      | 150/367 [00:26<00:33,  6.51it/s] \u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  41%|████      | 151/367 [00:26<00:35,  6.13it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  41%|████▏     | 152/367 [00:26<00:34,  6.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  42%|████▏     | 153/367 [00:27<00:37,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  42%|████▏     | 154/367 [00:27<00:38,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  42%|████▏     | 155/367 [00:27<00:35,  5.90it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  43%|████▎     | 156/367 [00:27<00:33,  6.22it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  43%|████▎     | 157/367 [00:27<00:34,  6.13it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  43%|████▎     | 158/367 [00:27<00:34,  6.10it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  43%|████▎     | 159/367 [00:27<00:32,  6.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  44%|████▎     | 160/367 [00:28<00:33,  6.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  44%|████▍     | 161/367 [00:28<00:33,  6.11it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  44%|████▍     | 162/367 [00:28<00:37,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  44%|████▍     | 163/367 [00:28<00:37,  5.39it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  45%|████▍     | 164/367 [00:28<00:39,  5.10it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  45%|████▍     | 165/367 [00:29<00:38,  5.22it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  45%|████▌     | 166/367 [00:29<00:38,  5.27it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  46%|████▌     | 167/367 [00:29<00:39,  5.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  46%|████▌     | 168/367 [00:29<00:40,  4.94it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  46%|████▌     | 169/367 [00:29<00:36,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02722 || acc: 98.75% || lr 7.757e-06:  46%|████▋     | 170/367 [00:30<00:35,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  46%|████▋     | 170/367 [00:30<00:35,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  47%|████▋     | 171/367 [00:30<00:33,  5.83it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  47%|████▋     | 172/367 [00:30<00:33,  5.80it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  47%|████▋     | 173/367 [00:30<00:32,  6.01it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  47%|████▋     | 174/367 [00:30<00:30,  6.29it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  48%|████▊     | 175/367 [00:30<00:32,  5.90it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  48%|████▊     | 176/367 [00:31<00:30,  6.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  48%|████▊     | 177/367 [00:31<00:31,  6.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  49%|████▊     | 178/367 [00:31<00:31,  6.00it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  49%|████▉     | 179/367 [00:31<00:31,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  49%|████▉     | 180/367 [00:31<00:32,  5.68it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  49%|████▉     | 181/367 [00:31<00:33,  5.63it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  50%|████▉     | 182/367 [00:32<00:32,  5.61it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  50%|████▉     | 183/367 [00:32<00:32,  5.71it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  50%|█████     | 184/367 [00:32<00:32,  5.66it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  50%|█████     | 185/367 [00:32<00:30,  6.02it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  51%|█████     | 186/367 [00:32<00:31,  5.77it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  51%|█████     | 187/367 [00:32<00:32,  5.56it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  51%|█████     | 188/367 [00:33<00:32,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  51%|█████▏    | 189/367 [00:33<00:33,  5.27it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01183 || acc: 100.00% || lr 7.756e-06:  52%|█████▏    | 190/367 [00:33<00:32,  5.41it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  52%|█████▏    | 190/367 [00:33<00:32,  5.41it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  52%|█████▏    | 191/367 [00:33<00:31,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  52%|█████▏    | 192/367 [00:33<00:29,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  53%|█████▎    | 193/367 [00:34<00:28,  6.15it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  53%|█████▎    | 194/367 [00:34<00:28,  5.97it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  53%|█████▎    | 195/367 [00:34<00:28,  6.07it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  53%|█████▎    | 196/367 [00:34<00:29,  5.76it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  54%|█████▎    | 197/367 [00:34<00:30,  5.58it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  54%|█████▍    | 198/367 [00:34<00:31,  5.29it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  54%|█████▍    | 199/367 [00:35<00:29,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  54%|█████▍    | 200/367 [00:35<00:28,  5.85it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  55%|█████▍    | 201/367 [00:35<00:28,  5.85it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  55%|█████▌    | 202/367 [00:35<00:31,  5.28it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  55%|█████▌    | 203/367 [00:35<00:31,  5.28it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  56%|█████▌    | 204/367 [00:36<00:30,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  56%|█████▌    | 205/367 [00:36<00:29,  5.51it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  56%|█████▌    | 206/367 [00:36<00:29,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  56%|█████▋    | 207/367 [00:36<00:28,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  57%|█████▋    | 208/367 [00:36<00:28,  5.60it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  57%|█████▋    | 209/367 [00:36<00:28,  5.48it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.006784 || acc: 100.00% || lr 7.754e-06:  57%|█████▋    | 210/367 [00:37<00:26,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  57%|█████▋    | 210/367 [00:37<00:26,  5.92it/s]  \u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  57%|█████▋    | 211/367 [00:37<00:27,  5.68it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  58%|█████▊    | 212/367 [00:37<00:27,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  58%|█████▊    | 213/367 [00:37<00:28,  5.38it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  58%|█████▊    | 214/367 [00:37<00:28,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  59%|█████▊    | 215/367 [00:38<00:29,  5.15it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  59%|█████▉    | 216/367 [00:38<00:29,  5.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  59%|█████▉    | 217/367 [00:38<00:28,  5.22it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  59%|█████▉    | 218/367 [00:38<00:27,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  60%|█████▉    | 219/367 [00:38<00:27,  5.42it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  60%|█████▉    | 220/367 [00:38<00:27,  5.33it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  60%|██████    | 221/367 [00:39<00:28,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  60%|██████    | 222/367 [00:39<00:25,  5.67it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  61%|██████    | 223/367 [00:39<00:25,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  61%|██████    | 224/367 [00:39<00:25,  5.57it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  61%|██████▏   | 225/367 [00:39<00:24,  5.84it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  62%|██████▏   | 226/367 [00:39<00:24,  5.86it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  62%|██████▏   | 227/367 [00:40<00:23,  5.85it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  62%|██████▏   | 228/367 [00:40<00:22,  6.18it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  62%|██████▏   | 229/367 [00:40<00:23,  5.98it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.08547 || acc: 97.50% || lr 7.753e-06:  63%|██████▎   | 230/367 [00:40<00:25,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  63%|██████▎   | 230/367 [00:40<00:25,  5.37it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  63%|██████▎   | 231/367 [00:40<00:23,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  63%|██████▎   | 232/367 [00:41<00:23,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  63%|██████▎   | 233/367 [00:41<00:25,  5.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  64%|██████▍   | 234/367 [00:41<00:25,  5.29it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  64%|██████▍   | 235/367 [00:41<00:25,  5.18it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  64%|██████▍   | 236/367 [00:41<00:24,  5.27it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  65%|██████▍   | 237/367 [00:41<00:23,  5.42it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  65%|██████▍   | 238/367 [00:42<00:24,  5.34it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  65%|██████▌   | 239/367 [00:42<00:24,  5.13it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  65%|██████▌   | 240/367 [00:42<00:24,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  66%|██████▌   | 241/367 [00:42<00:22,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  66%|██████▌   | 242/367 [00:42<00:22,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  66%|██████▌   | 243/367 [00:43<00:20,  5.99it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  66%|██████▋   | 244/367 [00:43<00:21,  5.62it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  67%|██████▋   | 245/367 [00:43<00:23,  5.28it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  67%|██████▋   | 246/367 [00:43<00:22,  5.36it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  67%|██████▋   | 247/367 [00:43<00:21,  5.53it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  68%|██████▊   | 248/367 [00:43<00:21,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  68%|██████▊   | 249/367 [00:44<00:21,  5.47it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04277 || acc: 99.38% || lr 7.751e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  68%|██████▊   | 250/367 [00:44<00:21,  5.49it/s] \u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  68%|██████▊   | 251/367 [00:44<00:21,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  69%|██████▊   | 252/367 [00:44<00:21,  5.38it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  69%|██████▉   | 253/367 [00:44<00:19,  5.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  69%|██████▉   | 254/367 [00:45<00:19,  5.77it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  69%|██████▉   | 255/367 [00:45<00:18,  5.96it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  70%|██████▉   | 256/367 [00:45<00:18,  5.95it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  70%|███████   | 257/367 [00:45<00:18,  5.83it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  70%|███████   | 258/367 [00:45<00:17,  6.06it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  71%|███████   | 259/367 [00:45<00:18,  5.75it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  71%|███████   | 260/367 [00:46<00:17,  6.20it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  71%|███████   | 261/367 [00:46<00:17,  6.07it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  71%|███████▏  | 262/367 [00:46<00:17,  5.87it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  72%|███████▏  | 263/367 [00:46<00:17,  6.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  72%|███████▏  | 264/367 [00:46<00:16,  6.07it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  72%|███████▏  | 265/367 [00:46<00:17,  5.96it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  72%|███████▏  | 266/367 [00:47<00:17,  5.89it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  73%|███████▎  | 267/367 [00:47<00:17,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  73%|███████▎  | 268/367 [00:47<00:18,  5.33it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  73%|███████▎  | 269/367 [00:47<00:18,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.04246 || acc: 98.12% || lr 7.75e-06:  74%|███████▎  | 270/367 [00:47<00:16,  5.86it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  74%|███████▎  | 270/367 [00:47<00:16,  5.86it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  74%|███████▍  | 271/367 [00:47<00:16,  5.76it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.83it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  74%|███████▍  | 273/367 [00:48<00:16,  5.82it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  75%|███████▍  | 274/367 [00:48<00:16,  5.71it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  75%|███████▍  | 275/367 [00:48<00:16,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  75%|███████▌  | 276/367 [00:48<00:16,  5.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  75%|███████▌  | 277/367 [00:49<00:16,  5.48it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  76%|███████▌  | 278/367 [00:49<00:16,  5.50it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  76%|███████▌  | 279/367 [00:49<00:16,  5.40it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  76%|███████▋  | 280/367 [00:49<00:16,  5.36it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  77%|███████▋  | 281/367 [00:49<00:16,  5.12it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  77%|███████▋  | 282/367 [00:50<00:16,  5.09it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  77%|███████▋  | 283/367 [00:50<00:17,  4.90it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  77%|███████▋  | 284/367 [00:50<00:16,  5.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  78%|███████▊  | 285/367 [00:50<00:15,  5.29it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  78%|███████▊  | 286/367 [00:50<00:14,  5.51it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  78%|███████▊  | 287/367 [00:50<00:14,  5.45it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  78%|███████▊  | 288/367 [00:51<00:14,  5.35it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  79%|███████▊  | 289/367 [00:51<00:15,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.02805 || acc: 99.38% || lr 7.749e-06:  79%|███████▉  | 290/367 [00:51<00:14,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  79%|███████▉  | 290/367 [00:51<00:14,  5.16it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  79%|███████▉  | 291/367 [00:51<00:14,  5.20it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  80%|███████▉  | 292/367 [00:51<00:13,  5.58it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  80%|███████▉  | 293/367 [00:52<00:13,  5.69it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  80%|████████  | 294/367 [00:52<00:13,  5.40it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  80%|████████  | 295/367 [00:52<00:13,  5.35it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  81%|████████  | 296/367 [00:52<00:13,  5.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  81%|████████  | 297/367 [00:52<00:13,  5.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  81%|████████  | 298/367 [00:53<00:12,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  81%|████████▏ | 299/367 [00:53<00:13,  5.12it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  82%|████████▏ | 300/367 [00:53<00:13,  5.13it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  82%|████████▏ | 301/367 [00:53<00:13,  5.05it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  82%|████████▏ | 302/367 [00:53<00:12,  5.31it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  83%|████████▎ | 303/367 [00:53<00:11,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  83%|████████▎ | 304/367 [00:54<00:10,  5.80it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  83%|████████▎ | 305/367 [00:54<00:10,  6.02it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  83%|████████▎ | 306/367 [00:54<00:10,  5.94it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  84%|████████▎ | 307/367 [00:54<00:09,  6.14it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  84%|████████▍ | 308/367 [00:54<00:10,  5.88it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  84%|████████▍ | 309/367 [00:54<00:09,  6.03it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01164 || acc: 100.00% || lr 7.747e-06:  84%|████████▍ | 310/367 [00:55<00:09,  6.04it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  84%|████████▍ | 310/367 [00:55<00:09,  6.04it/s] \u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.89it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  85%|████████▌ | 312/367 [00:55<00:09,  5.87it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  85%|████████▌ | 313/367 [00:55<00:09,  5.87it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  86%|████████▌ | 314/367 [00:55<00:09,  5.82it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  86%|████████▌ | 315/367 [00:55<00:09,  5.72it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.38it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  86%|████████▋ | 317/367 [00:56<00:09,  5.49it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  87%|████████▋ | 318/367 [00:56<00:07,  6.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  87%|████████▋ | 319/367 [00:56<00:07,  6.25it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  87%|████████▋ | 320/367 [00:56<00:07,  6.65it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  87%|████████▋ | 321/367 [00:56<00:07,  6.45it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  88%|████████▊ | 322/367 [00:57<00:07,  6.07it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  88%|████████▊ | 323/367 [00:57<00:07,  5.79it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  88%|████████▊ | 324/367 [00:57<00:07,  6.06it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  89%|████████▊ | 325/367 [00:57<00:06,  6.02it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  89%|████████▉ | 326/367 [00:57<00:06,  6.43it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  89%|████████▉ | 327/367 [00:57<00:06,  6.29it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  89%|████████▉ | 328/367 [00:58<00:06,  6.14it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  90%|████████▉ | 329/367 [00:58<00:06,  5.65it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.01892 || acc: 99.38% || lr 7.746e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.63it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  90%|████████▉ | 330/367 [00:58<00:06,  5.63it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  90%|█████████ | 331/367 [00:58<00:06,  5.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  90%|█████████ | 332/367 [00:58<00:06,  5.58it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  91%|█████████ | 333/367 [00:58<00:05,  5.89it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  91%|█████████ | 334/367 [00:59<00:06,  5.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  91%|█████████▏| 335/367 [00:59<00:06,  4.98it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  92%|█████████▏| 336/367 [00:59<00:06,  4.96it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  92%|█████████▏| 337/367 [00:59<00:05,  5.19it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  92%|█████████▏| 338/367 [01:00<00:05,  4.99it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  92%|█████████▏| 339/367 [01:00<00:05,  4.96it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  93%|█████████▎| 340/367 [01:00<00:05,  5.00it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  93%|█████████▎| 341/367 [01:00<00:05,  5.00it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  93%|█████████▎| 342/367 [01:00<00:05,  4.74it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  93%|█████████▎| 343/367 [01:01<00:04,  5.03it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  94%|█████████▎| 344/367 [01:01<00:04,  5.17it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  94%|█████████▍| 345/367 [01:01<00:04,  5.14it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  94%|█████████▍| 346/367 [01:01<00:04,  4.89it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  95%|█████████▍| 347/367 [01:01<00:03,  5.03it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  95%|█████████▍| 348/367 [01:02<00:03,  5.01it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  95%|█████████▌| 349/367 [01:02<00:03,  5.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.09976 || acc: 97.50% || lr 7.744e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  95%|█████████▌| 350/367 [01:02<00:03,  5.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  96%|█████████▌| 351/367 [01:02<00:03,  5.08it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  96%|█████████▌| 352/367 [01:02<00:02,  5.32it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  96%|█████████▌| 353/367 [01:02<00:02,  5.44it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  96%|█████████▋| 354/367 [01:03<00:02,  5.24it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  97%|█████████▋| 355/367 [01:03<00:02,  5.63it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  97%|█████████▋| 356/367 [01:03<00:01,  5.60it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  97%|█████████▋| 357/367 [01:03<00:01,  5.66it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  98%|█████████▊| 358/367 [01:03<00:01,  5.64it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  98%|█████████▊| 359/367 [01:04<00:01,  5.92it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  98%|█████████▊| 360/367 [01:04<00:01,  5.86it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  98%|█████████▊| 361/367 [01:04<00:00,  6.05it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  99%|█████████▊| 362/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  99%|█████████▉| 363/367 [01:04<00:00,  5.60it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  99%|█████████▉| 364/367 [01:04<00:00,  5.54it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06:  99%|█████████▉| 365/367 [01:05<00:00,  5.59it/s]\u001b[A\n",
      "Epoch: [10/30] || loss: 0.05593 || acc: 97.50% || lr 7.743e-06: 100%|██████████| 367/367 [01:05<00:00,  5.62it/s]\n",
      "\n",
      "[Validation] Epoch 11:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "[Validation] Epoch 11:   3%|▎         | 3/92 [00:00<00:03, 26.87it/s]\u001b[A\n",
      "[Validation] Epoch 11:   7%|▋         | 6/92 [00:00<00:04, 18.35it/s]\u001b[A\n",
      "[Validation] Epoch 11:  10%|▉         | 9/92 [00:00<00:04, 19.38it/s]\u001b[A\n",
      "[Validation] Epoch 11:  13%|█▎        | 12/92 [00:00<00:04, 18.79it/s]\u001b[A\n",
      "[Validation] Epoch 11:  15%|█▌        | 14/92 [00:00<00:04, 18.73it/s]\u001b[A\n",
      "[Validation] Epoch 11:  17%|█▋        | 16/92 [00:00<00:04, 19.00it/s]\u001b[A\n",
      "[Validation] Epoch 11:  21%|██        | 19/92 [00:00<00:03, 20.07it/s]\u001b[A\n",
      "[Validation] Epoch 11:  24%|██▍       | 22/92 [00:01<00:03, 19.12it/s]\u001b[A\n",
      "[Validation] Epoch 11:  26%|██▌       | 24/92 [00:01<00:03, 18.71it/s]\u001b[A\n",
      "[Validation] Epoch 11:  28%|██▊       | 26/92 [00:01<00:03, 17.75it/s]\u001b[A\n",
      "[Validation] Epoch 11:  32%|███▏      | 29/92 [00:01<00:03, 18.80it/s]\u001b[A\n",
      "[Validation] Epoch 11:  34%|███▎      | 31/92 [00:01<00:03, 18.83it/s]\u001b[A\n",
      "[Validation] Epoch 11:  36%|███▌      | 33/92 [00:01<00:03, 19.11it/s]\u001b[A\n",
      "[Validation] Epoch 11:  39%|███▉      | 36/92 [00:01<00:02, 19.28it/s]\u001b[A\n",
      "[Validation] Epoch 11:  41%|████▏     | 38/92 [00:01<00:02, 19.00it/s]\u001b[A\n",
      "[Validation] Epoch 11:  45%|████▍     | 41/92 [00:02<00:02, 19.63it/s]\u001b[A\n",
      "[Validation] Epoch 11:  47%|████▋     | 43/92 [00:02<00:02, 19.33it/s]\u001b[A\n",
      "[Validation] Epoch 11:  49%|████▉     | 45/92 [00:02<00:02, 18.41it/s]\u001b[A\n",
      "[Validation] Epoch 11:  51%|█████     | 47/92 [00:02<00:02, 18.11it/s]\u001b[A\n",
      "[Validation] Epoch 11:  53%|█████▎    | 49/92 [00:02<00:02, 17.95it/s]\u001b[A\n",
      "[Validation] Epoch 11:  55%|█████▌    | 51/92 [00:02<00:02, 18.02it/s]\u001b[A\n",
      "[Validation] Epoch 11:  58%|█████▊    | 53/92 [00:02<00:02, 18.10it/s]\u001b[A\n",
      "[Validation] Epoch 11:  60%|█████▉    | 55/92 [00:02<00:01, 18.50it/s]\u001b[A\n",
      "[Validation] Epoch 11:  62%|██████▏   | 57/92 [00:03<00:01, 18.75it/s]\u001b[A\n",
      "[Validation] Epoch 11:  65%|██████▌   | 60/92 [00:03<00:01, 19.32it/s]\u001b[A\n",
      "[Validation] Epoch 11:  67%|██████▋   | 62/92 [00:03<00:01, 19.02it/s]\u001b[A\n",
      "[Validation] Epoch 11:  70%|██████▉   | 64/92 [00:03<00:01, 17.80it/s]\u001b[A\n",
      "[Validation] Epoch 11:  72%|███████▏  | 66/92 [00:03<00:01, 17.21it/s]\u001b[A\n",
      "[Validation] Epoch 11:  75%|███████▌  | 69/92 [00:03<00:01, 18.60it/s]\u001b[A\n",
      "[Validation] Epoch 11:  77%|███████▋  | 71/92 [00:03<00:01, 18.46it/s]\u001b[A\n",
      "[Validation] Epoch 11:  79%|███████▉  | 73/92 [00:03<00:01, 17.98it/s]\u001b[A\n",
      "[Validation] Epoch 11:  82%|████████▏ | 75/92 [00:04<00:00, 18.50it/s]\u001b[A\n",
      "[Validation] Epoch 11:  84%|████████▎ | 77/92 [00:04<00:00, 18.82it/s]\u001b[A\n",
      "[Validation] Epoch 11:  86%|████████▌ | 79/92 [00:04<00:00, 18.47it/s]\u001b[A\n",
      "[Validation] Epoch 11:  89%|████████▉ | 82/92 [00:04<00:00, 19.08it/s]\u001b[A\n",
      "[Validation] Epoch 11:  92%|█████████▏| 85/92 [00:04<00:00, 19.02it/s]\u001b[A\n",
      "[Validation] Epoch 11:  95%|█████████▍| 87/92 [00:04<00:00, 18.25it/s]\u001b[A\n",
      "[Validation] Epoch 11:  97%|█████████▋| 89/92 [00:04<00:00, 17.73it/s]\u001b[A\n",
      "[Validation] Epoch 11:  99%|█████████▉| 91/92 [00:04<00:00, 18.28it/s]\u001b[A\n",
      "Validation: [10/30] || loss: 0.01876 || acc: 99.46%: 100%|██████████| 92/92 [00:04<00:00, 18.63it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Saving!\n",
      "Current Best Accuracy: 0.9945652173913043\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 37%|███▋      | 11/30 [13:15<22:46, 71.91s/it]\n",
      "[Training] Epoch 12:   0%|          | 0/367 [00:00<?, ?it/s]\u001b[A\n",
      "[Training] Epoch 12:   0%|          | 1/367 [00:00<01:08,  5.33it/s]\u001b[A\n",
      "[Training] Epoch 12:   1%|          | 2/367 [00:00<01:10,  5.21it/s]\u001b[A\n",
      "[Training] Epoch 12:   1%|          | 3/367 [00:00<01:05,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   1%|          | 3/367 [00:00<01:05,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   1%|          | 4/367 [00:00<01:00,  5.97it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   1%|▏         | 5/367 [00:00<00:58,  6.21it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   2%|▏         | 6/367 [00:01<01:06,  5.40it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   2%|▏         | 7/367 [00:01<01:08,  5.26it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   2%|▏         | 8/367 [00:01<01:04,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   2%|▏         | 9/367 [00:01<01:08,  5.23it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   3%|▎         | 10/367 [00:01<01:10,  5.07it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   3%|▎         | 11/367 [00:02<01:03,  5.57it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   3%|▎         | 12/367 [00:02<01:09,  5.11it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   4%|▎         | 13/367 [00:02<01:07,  5.28it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   4%|▍         | 14/367 [00:02<01:05,  5.35it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   4%|▍         | 15/367 [00:02<01:04,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   4%|▍         | 16/367 [00:02<00:59,  5.91it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   5%|▍         | 17/367 [00:03<01:06,  5.29it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   5%|▍         | 18/367 [00:03<01:05,  5.37it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   5%|▌         | 19/367 [00:03<01:06,  5.26it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   5%|▌         | 20/367 [00:03<01:04,  5.40it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   6%|▌         | 21/367 [00:03<01:02,  5.50it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   6%|▌         | 22/367 [00:04<01:02,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.001721 || acc: 15.00% || lr 7.741e-06:   6%|▋         | 23/367 [00:04<01:07,  5.08it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   6%|▋         | 23/367 [00:04<01:07,  5.08it/s]  \u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   7%|▋         | 24/367 [00:04<01:10,  4.88it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   7%|▋         | 25/367 [00:04<01:04,  5.28it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   7%|▋         | 26/367 [00:04<00:59,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   7%|▋         | 27/367 [00:04<01:00,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   8%|▊         | 28/367 [00:05<00:57,  5.85it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   8%|▊         | 29/367 [00:05<01:01,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   8%|▊         | 30/367 [00:05<00:56,  5.94it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   8%|▊         | 31/367 [00:05<00:55,  6.10it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   9%|▊         | 32/367 [00:05<00:58,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   9%|▉         | 33/367 [00:06<00:58,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:   9%|▉         | 34/367 [00:06<00:58,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  10%|▉         | 35/367 [00:06<01:00,  5.50it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  10%|▉         | 36/367 [00:06<01:01,  5.35it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  10%|█         | 37/367 [00:06<01:08,  4.85it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  10%|█         | 38/367 [00:07<01:07,  4.89it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  11%|█         | 39/367 [00:07<01:05,  5.03it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  11%|█         | 40/367 [00:07<01:02,  5.24it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  11%|█         | 41/367 [00:07<01:01,  5.33it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  11%|█▏        | 42/367 [00:07<01:00,  5.41it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01642 || acc: 99.38% || lr 7.74e-06:  12%|█▏        | 43/367 [00:07<00:59,  5.43it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  12%|█▏        | 43/367 [00:07<00:59,  5.43it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  12%|█▏        | 44/367 [00:08<01:01,  5.21it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  12%|█▏        | 45/367 [00:08<00:57,  5.60it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  13%|█▎        | 46/367 [00:08<00:59,  5.43it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  13%|█▎        | 47/367 [00:08<00:56,  5.68it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  13%|█▎        | 48/367 [00:08<00:55,  5.72it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  13%|█▎        | 49/367 [00:08<00:55,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  14%|█▎        | 50/367 [00:09<00:55,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  14%|█▍        | 51/367 [00:09<00:56,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  14%|█▍        | 52/367 [00:09<00:54,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  14%|█▍        | 53/367 [00:09<00:56,  5.53it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  15%|█▍        | 54/367 [00:09<00:56,  5.50it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  15%|█▍        | 55/367 [00:10<00:57,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  15%|█▌        | 56/367 [00:10<00:55,  5.58it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  16%|█▌        | 57/367 [00:10<00:55,  5.57it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  16%|█▌        | 58/367 [00:10<00:57,  5.36it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  16%|█▌        | 59/367 [00:10<01:00,  5.12it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  16%|█▋        | 60/367 [00:11<00:59,  5.16it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  17%|█▋        | 61/367 [00:11<00:55,  5.51it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  17%|█▋        | 62/367 [00:11<00:56,  5.38it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.08445 || acc: 96.88% || lr 7.738e-06:  17%|█▋        | 63/367 [00:11<00:58,  5.16it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  17%|█▋        | 63/367 [00:11<00:58,  5.16it/s] \u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  17%|█▋        | 64/367 [00:11<00:58,  5.14it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  18%|█▊        | 65/367 [00:11<00:57,  5.26it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  18%|█▊        | 66/367 [00:12<00:53,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  18%|█▊        | 67/367 [00:12<00:54,  5.49it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  19%|█▊        | 68/367 [00:12<00:56,  5.30it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  19%|█▉        | 69/367 [00:12<00:55,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  19%|█▉        | 70/367 [00:12<00:51,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  19%|█▉        | 71/367 [00:13<00:52,  5.66it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  20%|█▉        | 72/367 [00:13<00:52,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  20%|█▉        | 73/367 [00:13<00:53,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  20%|██        | 74/367 [00:13<00:52,  5.58it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  20%|██        | 75/367 [00:13<00:52,  5.57it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  21%|██        | 76/367 [00:13<00:52,  5.50it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  21%|██        | 77/367 [00:14<00:56,  5.14it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  21%|██▏       | 78/367 [00:14<00:53,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  22%|██▏       | 79/367 [00:14<00:49,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  22%|██▏       | 80/367 [00:14<00:49,  5.84it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  22%|██▏       | 81/367 [00:14<00:50,  5.61it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  22%|██▏       | 82/367 [00:15<00:49,  5.75it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0621 || acc: 98.12% || lr 7.737e-06:  23%|██▎       | 83/367 [00:15<00:48,  5.81it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  23%|██▎       | 83/367 [00:15<00:48,  5.81it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  23%|██▎       | 84/367 [00:15<00:52,  5.38it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  23%|██▎       | 85/367 [00:15<00:49,  5.69it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  23%|██▎       | 86/367 [00:15<00:52,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  24%|██▎       | 87/367 [00:15<00:52,  5.36it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  24%|██▍       | 88/367 [00:16<00:48,  5.78it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  24%|██▍       | 89/367 [00:16<00:52,  5.33it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  25%|██▍       | 90/367 [00:16<00:51,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  25%|██▍       | 91/367 [00:16<00:49,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  25%|██▌       | 92/367 [00:16<00:51,  5.32it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  25%|██▌       | 93/367 [00:17<00:50,  5.38it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  26%|██▌       | 94/367 [00:17<00:54,  5.05it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  26%|██▌       | 95/367 [00:17<00:49,  5.45it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  26%|██▌       | 96/367 [00:17<00:48,  5.54it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  26%|██▋       | 97/367 [00:17<00:47,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  27%|██▋       | 98/367 [00:17<00:45,  5.90it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  27%|██▋       | 99/367 [00:18<00:45,  5.92it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  27%|██▋       | 100/367 [00:18<00:44,  5.96it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  28%|██▊       | 101/367 [00:18<00:46,  5.73it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  28%|██▊       | 102/367 [00:18<00:47,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.0504 || acc: 99.38% || lr 7.735e-06:  28%|██▊       | 103/367 [00:18<00:47,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  28%|██▊       | 103/367 [00:18<00:47,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  28%|██▊       | 104/367 [00:19<00:49,  5.27it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  29%|██▊       | 105/367 [00:19<00:48,  5.41it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  29%|██▉       | 106/367 [00:19<00:46,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  29%|██▉       | 107/367 [00:19<00:44,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  29%|██▉       | 108/367 [00:19<00:44,  5.77it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  30%|██▉       | 109/367 [00:19<00:45,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  30%|██▉       | 110/367 [00:20<00:47,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  30%|███       | 111/367 [00:20<00:47,  5.35it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  31%|███       | 112/367 [00:20<00:50,  5.06it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  31%|███       | 113/367 [00:20<00:45,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  31%|███       | 114/367 [00:20<00:42,  6.00it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  31%|███▏      | 115/367 [00:20<00:43,  5.78it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  32%|███▏      | 116/367 [00:21<00:44,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  32%|███▏      | 117/367 [00:21<00:45,  5.53it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  32%|███▏      | 118/367 [00:21<00:44,  5.62it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  32%|███▏      | 119/367 [00:21<00:42,  5.88it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  33%|███▎      | 120/367 [00:21<00:41,  5.94it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  33%|███▎      | 121/367 [00:21<00:40,  6.14it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  33%|███▎      | 122/367 [00:22<00:41,  5.86it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.05202 || acc: 99.38% || lr 7.734e-06:  34%|███▎      | 123/367 [00:22<00:41,  5.87it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  34%|███▎      | 123/367 [00:22<00:41,  5.87it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  34%|███▍      | 124/367 [00:22<00:40,  6.01it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  34%|███▍      | 125/367 [00:22<00:39,  6.16it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  34%|███▍      | 126/367 [00:22<00:40,  5.91it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  35%|███▍      | 127/367 [00:22<00:40,  5.91it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  35%|███▍      | 128/367 [00:23<00:40,  5.89it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  35%|███▌      | 129/367 [00:23<00:40,  5.91it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  35%|███▌      | 130/367 [00:23<00:42,  5.57it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  36%|███▌      | 131/367 [00:23<00:39,  5.97it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  36%|███▌      | 132/367 [00:23<00:39,  5.90it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  36%|███▌      | 133/367 [00:24<00:40,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  37%|███▋      | 134/367 [00:24<00:40,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  37%|███▋      | 135/367 [00:24<00:38,  6.04it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  37%|███▋      | 136/367 [00:24<00:38,  5.99it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  37%|███▋      | 137/367 [00:24<00:39,  5.75it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  38%|███▊      | 138/367 [00:24<00:40,  5.69it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  38%|███▊      | 139/367 [00:25<00:38,  5.93it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  38%|███▊      | 140/367 [00:25<00:38,  5.90it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  38%|███▊      | 141/367 [00:25<00:38,  5.83it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  39%|███▊      | 142/367 [00:25<00:38,  5.88it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03481 || acc: 98.75% || lr 7.732e-06:  39%|███▉      | 143/367 [00:25<00:38,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  39%|███▉      | 143/367 [00:25<00:38,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  39%|███▉      | 144/367 [00:25<00:37,  6.01it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  40%|███▉      | 145/367 [00:26<00:36,  6.04it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  40%|███▉      | 146/367 [00:26<00:36,  6.00it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  40%|████      | 147/367 [00:26<00:36,  5.97it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  40%|████      | 148/367 [00:26<00:37,  5.87it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  41%|████      | 149/367 [00:26<00:37,  5.84it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  41%|████      | 150/367 [00:26<00:37,  5.81it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  41%|████      | 151/367 [00:27<00:34,  6.19it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  41%|████▏     | 152/367 [00:27<00:33,  6.34it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  42%|████▏     | 153/367 [00:27<00:35,  6.00it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  42%|████▏     | 154/367 [00:27<00:35,  5.97it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  42%|████▏     | 155/367 [00:27<00:38,  5.45it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  43%|████▎     | 156/367 [00:27<00:39,  5.30it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  43%|████▎     | 157/367 [00:28<00:39,  5.27it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  43%|████▎     | 158/367 [00:28<00:40,  5.11it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  43%|████▎     | 159/367 [00:28<00:38,  5.46it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  44%|████▎     | 160/367 [00:28<00:36,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  44%|████▍     | 161/367 [00:28<00:36,  5.61it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  44%|████▍     | 162/367 [00:29<00:36,  5.61it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01725 || acc: 99.38% || lr 7.731e-06:  44%|████▍     | 163/367 [00:29<00:34,  5.87it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  44%|████▍     | 163/367 [00:29<00:34,  5.87it/s] \u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  45%|████▍     | 164/367 [00:29<00:37,  5.46it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  45%|████▍     | 165/367 [00:29<00:35,  5.68it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  45%|████▌     | 166/367 [00:29<00:35,  5.68it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  46%|████▌     | 167/367 [00:29<00:37,  5.30it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  46%|████▌     | 168/367 [00:30<00:38,  5.13it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  46%|████▌     | 169/367 [00:30<00:35,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  46%|████▋     | 170/367 [00:30<00:34,  5.66it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  47%|████▋     | 171/367 [00:30<00:34,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  47%|████▋     | 172/367 [00:30<00:34,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  47%|████▋     | 173/367 [00:31<00:36,  5.26it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  47%|████▋     | 174/367 [00:31<00:36,  5.36it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  48%|████▊     | 175/367 [00:31<00:37,  5.12it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  48%|████▊     | 176/367 [00:31<00:35,  5.34it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  48%|████▊     | 177/367 [00:31<00:34,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  49%|████▊     | 178/367 [00:31<00:32,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  49%|████▉     | 179/367 [00:32<00:30,  6.12it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  49%|████▉     | 180/367 [00:32<00:31,  5.94it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  49%|████▉     | 181/367 [00:32<00:32,  5.80it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  50%|████▉     | 182/367 [00:32<00:32,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03874 || acc: 98.12% || lr 7.73e-06:  50%|████▉     | 183/367 [00:32<00:33,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  50%|████▉     | 183/367 [00:32<00:33,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  50%|█████     | 184/367 [00:33<00:33,  5.50it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  50%|█████     | 185/367 [00:33<00:33,  5.44it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  51%|█████     | 186/367 [00:33<00:31,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  51%|█████     | 187/367 [00:33<00:34,  5.29it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  51%|█████     | 188/367 [00:33<00:32,  5.45it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  51%|█████▏    | 189/367 [00:33<00:32,  5.48it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  52%|█████▏    | 190/367 [00:34<00:30,  5.89it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  52%|█████▏    | 191/367 [00:34<00:29,  5.96it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  52%|█████▏    | 192/367 [00:34<00:31,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  53%|█████▎    | 193/367 [00:34<00:30,  5.72it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  53%|█████▎    | 194/367 [00:34<00:30,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  53%|█████▎    | 195/367 [00:34<00:31,  5.49it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  53%|█████▎    | 196/367 [00:35<00:33,  5.15it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  54%|█████▎    | 197/367 [00:35<00:30,  5.62it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  54%|█████▍    | 198/367 [00:35<00:32,  5.19it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  54%|█████▍    | 199/367 [00:35<00:32,  5.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  54%|█████▍    | 200/367 [00:35<00:29,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  55%|█████▍    | 201/367 [00:36<00:28,  5.93it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  55%|█████▌    | 202/367 [00:36<00:30,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01276 || acc: 99.38% || lr 7.728e-06:  55%|█████▌    | 203/367 [00:36<00:29,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  55%|█████▌    | 203/367 [00:36<00:29,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  56%|█████▌    | 204/367 [00:36<00:29,  5.45it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  56%|█████▌    | 205/367 [00:36<00:28,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  56%|█████▌    | 206/367 [00:36<00:27,  5.75it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  56%|█████▋    | 207/367 [00:37<00:27,  5.86it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  57%|█████▋    | 208/367 [00:37<00:27,  5.88it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  57%|█████▋    | 209/367 [00:37<00:27,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  57%|█████▋    | 210/367 [00:37<00:27,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  57%|█████▋    | 211/367 [00:37<00:29,  5.35it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  58%|█████▊    | 212/367 [00:38<00:27,  5.72it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  58%|█████▊    | 213/367 [00:38<00:29,  5.28it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  58%|█████▊    | 214/367 [00:38<00:28,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  59%|█████▊    | 215/367 [00:38<00:26,  5.70it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  59%|█████▉    | 216/367 [00:38<00:26,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  59%|█████▉    | 217/367 [00:38<00:26,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  59%|█████▉    | 218/367 [00:39<00:26,  5.60it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  60%|█████▉    | 219/367 [00:39<00:26,  5.54it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  60%|█████▉    | 220/367 [00:39<00:27,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  60%|██████    | 221/367 [00:39<00:28,  5.18it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  60%|██████    | 222/367 [00:39<00:27,  5.30it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03247 || acc: 99.38% || lr 7.727e-06:  61%|██████    | 223/367 [00:40<00:25,  5.62it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  61%|██████    | 223/367 [00:40<00:25,  5.62it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  61%|██████    | 224/367 [00:40<00:26,  5.32it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  61%|██████▏   | 225/367 [00:40<00:26,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  62%|██████▏   | 226/367 [00:40<00:26,  5.34it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  62%|██████▏   | 227/367 [00:40<00:25,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  62%|██████▏   | 228/367 [00:40<00:25,  5.53it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  62%|██████▏   | 229/367 [00:41<00:25,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  63%|██████▎   | 230/367 [00:41<00:25,  5.41it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  63%|██████▎   | 231/367 [00:41<00:26,  5.16it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  63%|██████▎   | 232/367 [00:41<00:25,  5.32it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  63%|██████▎   | 233/367 [00:41<00:24,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  64%|██████▍   | 234/367 [00:42<00:24,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  64%|██████▍   | 235/367 [00:42<00:22,  5.82it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  64%|██████▍   | 236/367 [00:42<00:20,  6.33it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  65%|██████▍   | 237/367 [00:42<00:20,  6.43it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  65%|██████▍   | 238/367 [00:42<00:21,  6.03it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  65%|██████▌   | 239/367 [00:42<00:21,  6.05it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  65%|██████▌   | 240/367 [00:43<00:22,  5.77it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  66%|██████▌   | 241/367 [00:43<00:24,  5.24it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  66%|██████▌   | 242/367 [00:43<00:23,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.02678 || acc: 98.75% || lr 7.725e-06:  66%|██████▌   | 243/367 [00:43<00:23,  5.21it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  66%|██████▌   | 243/367 [00:43<00:23,  5.21it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  66%|██████▋   | 244/367 [00:43<00:23,  5.14it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  67%|██████▋   | 245/367 [00:44<00:23,  5.27it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  67%|██████▋   | 246/367 [00:44<00:21,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  67%|██████▋   | 247/367 [00:44<00:21,  5.47it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  68%|██████▊   | 248/367 [00:44<00:21,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  68%|██████▊   | 249/367 [00:44<00:20,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  68%|██████▊   | 250/367 [00:44<00:19,  5.86it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  68%|██████▊   | 251/367 [00:45<00:20,  5.76it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  69%|██████▊   | 252/367 [00:45<00:20,  5.57it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  69%|██████▉   | 253/367 [00:45<00:21,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  69%|██████▉   | 254/367 [00:45<00:19,  5.76it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  69%|██████▉   | 255/367 [00:45<00:19,  5.71it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  70%|██████▉   | 256/367 [00:45<00:18,  5.92it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  70%|███████   | 257/367 [00:46<00:19,  5.69it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  70%|███████   | 258/367 [00:46<00:20,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  71%|███████   | 259/367 [00:46<00:19,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  71%|███████   | 260/367 [00:46<00:19,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  71%|███████   | 261/367 [00:46<00:18,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  71%|███████▏  | 262/367 [00:47<00:18,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.01369 || acc: 99.38% || lr 7.724e-06:  72%|███████▏  | 263/367 [00:47<00:18,  5.49it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  72%|███████▏  | 263/367 [00:47<00:18,  5.49it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  72%|███████▏  | 264/367 [00:47<00:19,  5.25it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  72%|███████▏  | 265/367 [00:47<00:18,  5.39it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  72%|███████▏  | 266/367 [00:47<00:18,  5.51it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  73%|███████▎  | 267/367 [00:47<00:18,  5.41it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  73%|███████▎  | 268/367 [00:48<00:19,  5.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  73%|███████▎  | 269/367 [00:48<00:17,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  74%|███████▎  | 270/367 [00:48<00:17,  5.45it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  74%|███████▍  | 271/367 [00:48<00:18,  5.22it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  74%|███████▍  | 272/367 [00:48<00:16,  5.69it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  74%|███████▍  | 273/367 [00:49<00:15,  6.04it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  75%|███████▍  | 274/367 [00:49<00:15,  6.04it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  75%|███████▍  | 275/367 [00:49<00:15,  5.94it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  75%|███████▌  | 276/367 [00:49<00:15,  5.79it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  75%|███████▌  | 277/367 [00:49<00:15,  5.78it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  76%|███████▌  | 278/367 [00:49<00:15,  5.74it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  76%|███████▌  | 279/367 [00:50<00:15,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  76%|███████▋  | 280/367 [00:50<00:14,  5.80it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  77%|███████▋  | 281/367 [00:50<00:15,  5.51it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  77%|███████▋  | 282/367 [00:50<00:15,  5.55it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.04272 || acc: 99.38% || lr 7.722e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  77%|███████▋  | 283/367 [00:50<00:15,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  77%|███████▋  | 284/367 [00:50<00:14,  5.58it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  78%|███████▊  | 285/367 [00:51<00:13,  5.87it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  78%|███████▊  | 286/367 [00:51<00:14,  5.54it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  78%|███████▊  | 287/367 [00:51<00:13,  5.85it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  78%|███████▊  | 288/367 [00:51<00:12,  6.19it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  79%|███████▊  | 289/367 [00:51<00:13,  5.80it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  79%|███████▉  | 290/367 [00:51<00:13,  5.59it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  79%|███████▉  | 291/367 [00:52<00:13,  5.66it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  80%|███████▉  | 292/367 [00:52<00:13,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  80%|███████▉  | 293/367 [00:52<00:12,  5.88it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  80%|████████  | 294/367 [00:52<00:11,  6.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  80%|████████  | 295/367 [00:52<00:11,  6.38it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  81%|████████  | 296/367 [00:52<00:11,  6.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  81%|████████  | 297/367 [00:53<00:12,  5.51it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  81%|████████  | 298/367 [00:53<00:12,  5.66it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  81%|████████▏ | 299/367 [00:53<00:11,  5.73it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  82%|████████▏ | 300/367 [00:53<00:11,  5.75it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  82%|████████▏ | 301/367 [00:53<00:12,  5.31it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  82%|████████▏ | 302/367 [00:54<00:11,  5.52it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03642 || acc: 98.75% || lr 7.721e-06:  83%|████████▎ | 303/367 [00:54<00:12,  5.19it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  83%|████████▎ | 303/367 [00:54<00:12,  5.19it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  83%|████████▎ | 304/367 [00:54<00:11,  5.25it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  83%|████████▎ | 305/367 [00:54<00:11,  5.33it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  83%|████████▎ | 306/367 [00:54<00:11,  5.29it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  84%|████████▎ | 307/367 [00:55<00:11,  5.36it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  84%|████████▍ | 308/367 [00:55<00:10,  5.49it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  84%|████████▍ | 309/367 [00:55<00:10,  5.62it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  84%|████████▍ | 310/367 [00:55<00:10,  5.29it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  85%|████████▍ | 311/367 [00:55<00:09,  5.65it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  85%|████████▌ | 312/367 [00:55<00:10,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  85%|████████▌ | 313/367 [00:56<00:09,  5.53it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  86%|████████▌ | 314/367 [00:56<00:09,  5.41it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  86%|████████▌ | 315/367 [00:56<00:09,  5.32it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  86%|████████▌ | 316/367 [00:56<00:09,  5.60it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  86%|████████▋ | 317/367 [00:56<00:09,  5.32it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  87%|████████▋ | 318/367 [00:57<00:09,  5.40it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  87%|████████▋ | 319/367 [00:57<00:09,  5.16it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  87%|████████▋ | 320/367 [00:57<00:09,  5.14it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  87%|████████▋ | 321/367 [00:57<00:08,  5.38it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  88%|████████▊ | 322/367 [00:57<00:08,  5.42it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.07137 || acc: 97.50% || lr 7.719e-06:  88%|████████▊ | 323/367 [00:58<00:08,  5.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  88%|████████▊ | 323/367 [00:58<00:08,  5.20it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  88%|████████▊ | 324/367 [00:58<00:07,  5.66it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  89%|████████▊ | 325/367 [00:58<00:07,  5.76it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  89%|████████▉ | 326/367 [00:58<00:07,  5.34it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  89%|████████▉ | 327/367 [00:58<00:07,  5.46it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  89%|████████▉ | 328/367 [00:58<00:07,  5.56it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  90%|████████▉ | 329/367 [00:59<00:06,  5.67it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  90%|████████▉ | 330/367 [00:59<00:06,  5.55it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  90%|█████████ | 331/367 [00:59<00:06,  5.63it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  90%|█████████ | 332/367 [00:59<00:06,  5.65it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  91%|█████████ | 333/367 [00:59<00:05,  6.00it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  91%|█████████ | 334/367 [00:59<00:05,  6.01it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  91%|█████████▏| 335/367 [01:00<00:05,  5.64it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  92%|█████████▏| 336/367 [01:00<00:05,  5.61it/s]\u001b[A\n",
      "Epoch: [11/30] || loss: 0.03579 || acc: 98.75% || lr 7.718e-06:  92%|█████████▏| 337/367 [01:00<00:05,  5.47it/s]\u001b[A"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "54946c2456d9451e8b394f6d3bcb43d2",
      "3739e8216905493daf9f8ae361a36db5",
      "981d812b3a5143de949fefe3dac3de35",
      "0ae165ef145b4f7a9c8ddb82f3e66951",
      "378116917b1e4955ab128ec0aca39d7d",
      "4cad7541d3bd471dab2e4b7e0cebeba8",
      "ad17e33c69024c17a1f7da4de347d085",
      "ed9a6e9e3e934ffbb56420ceacc09b94"
     ]
    },
    "id": "sNtOL89QdxQk",
    "outputId": "73af7626-d576-42e0-c9be-6420785a26ae"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bigbird Inference"
   ],
   "metadata": {
    "id": "Y-5NaSa_KGLQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "Eval = Inference(config, 'bigbird')\n",
    "Eval.inference()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a288b7b466f74da6ba9b7d4e1019964c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/870 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40ac814faa14a738a4df4b493fcdd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2881a9f96bdc4a3987346224b7334339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f7ee2edc8344b5bc50d968fa9f0241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/236k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0cf5e813ba46518a543599551df12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb3bf62a7044ffbbc9301377665b1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/169 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inference:   0%|          | 0/350 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 144 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Inference: 100%|██████████| 350/350 [00:04<00:00, 70.66it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy is 75.00%. Congrats!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "a288b7b466f74da6ba9b7d4e1019964c",
      "dbefd2df3ee34540be2f9da9c8440585",
      "d2a9ef2097334ec3908420f884904ed3",
      "239eaecaa4cd4c588da35ca082fd1243",
      "55f37e201126405ab04cb246ad106844",
      "b36ba57a89c14ee7994e8bf0f57cddee",
      "d5722b61f9f74fd59faadb5938da7e9c",
      "9e4590eae85a430e9c26fecb316045b5",
      "c03137af8bcd45988dd0cefcbc909e68",
      "e89518e6106f48aead64f1562dac4e8e",
      "60ecee145296478e938aa3d5caf52de2",
      "c40ac814faa14a738a4df4b493fcdd0b",
      "0c77fbd4922c4bcbb0ca09b48c1d4ea8",
      "f3cd89c129644dab97380cb1d5953c9d",
      "2127645f0b7041f6ad0cafe01c9550ec",
      "1a193511bb3a4f889f2cff8c17b67050",
      "9942dcc5f39445cea78b550a005b23f6",
      "ced45f67ff3848449911db2f6265aa24",
      "3ea1f4bb538d4f0598b0288e624a3aa6",
      "c3e2bc48f34b49719fc901949865f305",
      "a0d514ec9e814c92824c4f6a68c7b156",
      "9df3e2ffe3e9495197abbb5193228820",
      "2881a9f96bdc4a3987346224b7334339",
      "365ecd5f5fb548af8640fdb37cc73f4a",
      "0691c3337c29400cb5ba4effb3f08ad0",
      "e44fb34e24b74d11b242676d09b1f31d",
      "c809a39e2d5c4a5aa591ed6901d17ce9",
      "80e4f2f494e144abb16a16b620622719",
      "e92ddd30ded04dc7be218d8183afddbd",
      "5a9fae08e09c481c80bcbe37812e1cb1",
      "466d04a61e17412dafad0c9905e03d44",
      "77ed642bdced46f6845c096003a33027",
      "6d4e708d994c430b94d365c2b2fbf99e",
      "14f7ee2edc8344b5bc50d968fa9f0241",
      "95082759a60d4dfb82ec0ad979f3c9d1",
      "8766155677ed4804a7e4634c57590b81",
      "b828f116ae38428c8d338505a8c81b70",
      "928b316af2bb4d4881a47ff4a5c836fd",
      "2ad304de84fb4b259e158f40598892fe",
      "d8b7d504deb24cdab527596aaa705aec",
      "c8ce996dce3747c8b2a31130b688387a",
      "7dc22060108242e1ab1ebc6f7a57ce73",
      "315ca1e2ef87450b8ee9b54a4c0b314c",
      "6af38e0475de4c96bad4b3aa88094f47",
      "fb0cf5e813ba46518a543599551df12c",
      "d561f326caaa4d3abb9cd619a1975113",
      "2623322ba8014e8abfd528f6f0c9c0ac",
      "f8b45fdc57244471a76e8c07da60d7ea",
      "4b26321fa2f449bd858e1d90181a7912",
      "42ea5b47c26340939799b2bccf406c57",
      "be491d7ae3cf4f739aafcdbef9ccedff",
      "6ff8e203373343f2a2963f291d48966b",
      "bfb36c97ff72495380b42a8a8988b2c8",
      "e69f12b2212b4100a6f163b90b44266b",
      "745cc41e00ce405080f82a46aaa54f76",
      "3fb3bf62a7044ffbbc9301377665b1f3",
      "452c6f42978d4318bc4b48d3564d1360",
      "668f838fbb1b4ca5b5868e8a9f5e94a2",
      "d3815e6757414b64b03c0e38cfab8c85",
      "90bd122293dc4cc0b9d963f6d3fd9f60",
      "885aa50de7f347758fb79c13c4abd08b",
      "ba6f17a1420b4f88b96756692882e633",
      "26cca8cec1f5470191af88c0f0680a20",
      "712fa8c8869140a4829adbd8fbe46db1",
      "19dcdc114e9848baa06406654e3be105",
      "2ceed783fa7840019eee8cb6935590e9"
     ]
    },
    "id": "_QpuSFF0PaP0",
    "outputId": "1cd98afc-db28-4a8e-b22c-ff923b6587ff"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Roborta"
   ],
   "metadata": {
    "id": "J6VkSq3YWGb8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'roberta'\n",
    "\n",
    "if config.mode_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project='HyunJin-BoolQ', name=f\"hello_{model_name}\")\n",
    "\n",
    "Trainer = BoolQ_Model_Train(config, model_name)\n",
    "Trainer.fit(epoch = 30)"
   ],
   "outputs": [],
   "metadata": {
    "id": "9XeNBXH8Wmr2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Roberta Inference"
   ],
   "metadata": {
    "id": "KE1WUdF7Waik"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "Eval = Inference(config, 'roberta')\n",
    "Eval.inference()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ae5a348fa94970bdd62253914eb5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15a04adf12b48efad01b7fa0b7255d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baebb2960f034c9386c212878a4b0fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc941dd085ea448a9119a81a7b49ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157d73ff8bae4730839f951681d75b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b5768cc35d41c29afa1434a40f4e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inference: 100%|██████████| 350/350 [00:12<00:00, 27.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy is 80.71%. Congrats!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433,
     "referenced_widgets": [
      "61ae5a348fa94970bdd62253914eb5fb",
      "03e37abdd57a4f4da229ab2530294692",
      "81d22a8a750f4b7b83483901b541158c",
      "ddbd1da2072b4afab86c714b2904c75f",
      "fa97bec0381149f5a8f8b8f44045ed8d",
      "7402824f259e4042bb398664274b365f",
      "2a38f769b47f48a49dec54c1178149b1",
      "a91d7c5d6faa4fc8bddfbbd7ab4b8dd6",
      "07bce04cf9334305aa95a2a915457b90",
      "d36477a8ede14ddebddc0e004dce4f3f",
      "4c6cdd4950c148ff9ede164046b1c3d7",
      "a15a04adf12b48efad01b7fa0b7255d6",
      "b65e4c0426e14d98a20ad0e3cb7aafea",
      "5f9fa9c123bc48e9ad5bd353751fabd3",
      "d75a9597cdbb46baa5f884dfa8e53534",
      "1e857ff5c1bf48279e22b290ac6d79c3",
      "b714d0b7f20f420db7b9a46cd6d7f4c9",
      "937d69c974704395b85d6766a8263d43",
      "150cb5182be449baa178ee7137800711",
      "2f721ccfc1e047f399bb5d8747674008",
      "45aec85ecde740a98278812ae3091e9d",
      "ada66b8623a14087949b4ceed1e15be6",
      "baebb2960f034c9386c212878a4b0fcc",
      "18d95ff2cb2b4ca38da9f57082a2c3ed",
      "c57fe9701ae749d99f8329d86ca05d60",
      "84da553a82da4135a4c51afce89bab80",
      "1b2e7911666f45de85b77520f613ff42",
      "e68712119a84476eb27315af20145ba0",
      "bfaa62780356469a8b3b219ac0972569",
      "1121ff9a6ddf4660ad559cb24e943f98",
      "a66a6fb8b27b47fe98349758b787c090",
      "72349876170e4cdd8c523f6877fa1760",
      "a520d796f98443c89ee053be62785757",
      "bc941dd085ea448a9119a81a7b49ba9e",
      "0df27d717cc64026b6fa6745f1b74341",
      "2616fd77810047969bd97cd6cd7cda76",
      "305dee1e9cd143679778ae98a15b69b3",
      "39edf1f6a9b542138ffe4beb4458a606",
      "7eaabdd1ae564e99a5811b10f022d154",
      "ae86c5e1a7874217be829fb3d987999f",
      "03d7142f330643228c2e1ce8c483d3c3",
      "f6294ecb476e488ea96b72a4e1088f0d",
      "733edd9f38bf4533a6ff3057b079e94b",
      "0d98397ef86446cf9374bbdaa1a078d7",
      "157d73ff8bae4730839f951681d75b0b",
      "b48d3a55910b4974a59161d531843a6a",
      "499daaacfeb6408eafb4ddf211a24414",
      "bc454a9290d443dbb32368a9c48b5dab",
      "59712ac47245473c9cdc1285e3eab567",
      "82743d1c9f55448ea9d85f2dbb52f225",
      "4143a3128fc34a9295b274f2c1106246",
      "a41c6191069d4c4481627914df61787b",
      "0f8c2ccf496b4aa8812d33c4c7b02604",
      "8e823a7db5624878a2ef0b0169932487",
      "de237a43032744ff9efca2e196903a8a",
      "16b5768cc35d41c29afa1434a40f4e02",
      "fbafeb7f009d4f8cb329c9a37134a324",
      "ea45eff878c44029b1c18db0cac12081",
      "bfbf9a8fa1cf4d978fe64a188389817d",
      "ac99799583d84ee7a969b3b0f9a453c6",
      "a018ede9e8a449588392d56657dff54f",
      "435bc40ebcce45fb844438a716be3aed",
      "1a50334fed014d3fa0884042d9a7fb51",
      "39f683768b9740aeb86bcf4b1cd59c15",
      "205638f366754ddca767e454e7f209bc",
      "bb182a14c1d34befab2cabb428b6106f"
     ]
    },
    "id": "Z_sbb3fSWqy1",
    "outputId": "b5f002a8-f5a7-4b5d-c315-6ad406d8419c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Electra"
   ],
   "metadata": {
    "id": "BP8Q5G55WJ7T"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'electra'\n",
    "\n",
    "if config.mode_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project='HyunJin-BoolQ', name=f\"hello_{model_name}\")\n",
    "\n",
    "Trainer = BoolQ_Model_Train(config, model_name)\n",
    "Trainer.fit(epoch = 30)"
   ],
   "outputs": [],
   "metadata": {
    "id": "7pd-VWEQWnRC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Electra Inference"
   ],
   "metadata": {
    "id": "DCSDfDN3WcIG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "Eval = Inference(config, 'electra')\n",
    "Eval.inference()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8402d3672ab64e87ab7863a47e21095f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9e005cd4584008adfdca5bb8ccb1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b281645c744c82ac159c3dad746e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207c5b77935144ed8ff40efce4a4b347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/257k [00:02<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inference: 100%|██████████| 350/350 [00:04<00:00, 79.88it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy is 80.57%. Congrats!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250,
     "referenced_widgets": [
      "8402d3672ab64e87ab7863a47e21095f",
      "faf004f3e57941b6a680e6af34a23c40",
      "c56ab1282aab45c3b631ef8e6750e4fe",
      "92dcc9a253c7479db324d2d368b07ce6",
      "996a8bbe2aeb4d4c9f85f75138aaaf94",
      "4a579b03570d41ab9427600643bea5df",
      "779b06eab63c4de288b7b6686ea44c6a",
      "d8c0f308efd744bab94187c87d52f852",
      "bacdb1634cd44a1babd19e8f0b2ac854",
      "2f036717e4a142f9962ad930d6bf852e",
      "19fbe7928db54b83a1347202ab9641f3",
      "aa9e005cd4584008adfdca5bb8ccb1fd",
      "f11618dabcab49c59ffe576a6999a857",
      "1f9e7f724d534eba8345d45d4fbe4536",
      "dead70fc1bf84cc4bcb9cb17ebedde93",
      "2f6d2f6081cb4ec995ae066f78bb5e1e",
      "8ee3b30511c44ff0a34da75feb79a0ef",
      "a098a139e26d42c69434983c6d7c7183",
      "e11b3c1246b74247ba0393805d178696",
      "cd38c3b323934ea2b49fd712b8362804",
      "9b5458a7f1f244a492cccd24d93f85bc",
      "13210fed8f264b50b721c4d1ed34cdf6",
      "f3b281645c744c82ac159c3dad746e5a",
      "09431b70b47643f8b74e68852a302c36",
      "c54ce25c7e964e45a7e295c1fdb009c9",
      "590a832ca17c4c7aa4e8c52f98de7903",
      "ca165a4a073c4355bbb003ac2cace739",
      "3f349e96009b4660bba2fcf543c2c29f",
      "deb88077950b4175920722ba0567b2c3",
      "3b60470a647042debdf05f47fe543842",
      "d411ff164df64dc0b4272493c6e3cc6e",
      "0b1efdf5bb8e4164a26dea0c47a59526",
      "98484095a7914b19adde8b70b67e5af9",
      "207c5b77935144ed8ff40efce4a4b347",
      "c494c03c69044acc85eef383f007b556",
      "7e94a32f1df14334b6492a86d839dcb1",
      "168fc960fcb342e6be87f7ac95599164",
      "6fc5e6e9f2ee487eb26de1ae647b993e",
      "0334780c57934604b24778390ef74f7b",
      "878f966a71454e6c88a9d3fd9408f491",
      "3cedb9431d524ffbbd27554a53cf5d08",
      "54fd69d7e3c3400496e98665f4850ccf",
      "716c5f5a51914c8c99b1013f151a9451",
      "5823afaf6c3b45d68bdeea03ee4cf635"
     ]
    },
    "id": "u17Eq1v3WtzQ",
    "outputId": "20c75f3a-0ed2-4d24-e37c-f68fde252925"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) Albert (koreAlbert)"
   ],
   "metadata": {
    "id": "4Mzoy-6ce0Lb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'albert'\n",
    "\n",
    "if config.mode_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project='HyunJin-BoolQ', name=f\"hello_{model_name}\")\n",
    "\n",
    "Trainer = BoolQ_Model_Train(config, model_name)\n",
    "Trainer.fit(epoch = 30)"
   ],
   "outputs": [],
   "metadata": {
    "id": "uJyfMqjXezgr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Albert Inference"
   ],
   "metadata": {
    "id": "YEhfFCMSfNdS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Eval = Inference(config, 'albert')\n",
    "Eval.inference()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3cfa3d315af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'albert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Inference' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "wGQqJxS_fO6C",
    "outputId": "5155d3d0-b4f6-4658-d2a1-a322674d01e0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logit ensamble of 3 model"
   ],
   "metadata": {
    "id": "UbgRQozww2Ti"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class InferenceLogitEnsemble():\n",
    "  \"\"\"\n",
    "    Logit Ensemble of 3 well-trained model\n",
    "  \"\"\"\n",
    "  def __init__(self, config):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    self.device = device\n",
    "    self.config = config\n",
    "\n",
    "    #####################\n",
    "    ### Configuration ###\n",
    "    #####################\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "\n",
    "    # make a list of dictionary the well-trained model saved.\n",
    "    save_model_path = [os.path.join(config.cur_path, 'result/best', name) for name in config.model_list.keys()]\n",
    "\n",
    "    # make a model_config of the well-trained models saved.\n",
    "    config_list = [AutoConfig.from_pretrained(config.model_list[name]) for name in config.model_list.keys()]\n",
    "    config_list[0].num_labels = 2\n",
    "    config_list[1].num_labels = 2\n",
    "    config_list[2].num_labels = 2\n",
    "\n",
    "    # load trained models (no Albert)\n",
    "    self.model_r = Roberta_BoolQ.from_pretrained(save_model_path[0], config=config_list[0]).to(device).eval()\n",
    "    self.model_b = BigBird_BoolQ.from_pretrained(save_model_path[1], config=config_list[1]).to(device).eval()\n",
    "    self.model_e = Electra_BoolQ.from_pretrained(save_model_path[2], config=config_list[2]).to(device).eval()\n",
    "    \n",
    "\n",
    "    \"\"\" Tokenizer \"\"\"\n",
    "    self.tokenizer_list = [AutoTokenizer.from_pretrained(config.model_list[name]) for name in list(config.model_list.keys())[:3]]\n",
    "\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "\n",
    "    # train_dataset\n",
    "    self.test_dataset = BoolQ_Dataset(config, False)\n",
    "    \n",
    "    # batch_size\n",
    "    self.batch_size = config.inf_batch_size\n",
    "\n",
    "\n",
    "\n",
    "  def inference(self):\n",
    "    ### test dataloader\n",
    "    loader_list = [DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        collate_fn = self.ensemble_fn(self.tokenizer_list[i])) for i in range(3)\n",
    "    ]\n",
    "\n",
    "    # get accuracy.\n",
    "    tot_acc = 0.\n",
    "    with torch.no_grad():\n",
    "      pbar = tqdm(total = len(loader_list[0]), desc = \"Inference\")\n",
    "      for (t_r, labels), (t_b, _), (t_e, _) in zip(loader_list[0], loader_list[1], loader_list[2]):\n",
    "        ### simple function to allocate to cuda (or cpu)\n",
    "        convert_text = lambda t: {key: torch.tensor(value).to(self.device) for key, value in t.items()}\n",
    "        convert_label = lambda l: torch.tensor(l).to(self.device)\n",
    "\n",
    "        t_r, t_b, t_e = convert_text(t_r), convert_text(t_b), convert_text(t_e)\n",
    "        \n",
    "        y_pred_r = self.model_r(**t_r)[0]\n",
    "        y_pred_b = self.model_b(**t_b)[0]\n",
    "        y_pred_e = self.model_e(**t_e)[0]\n",
    "\n",
    "        y_pred = (y_pred_r + y_pred_b + y_pred_e)/3\n",
    "\n",
    "        preds = torch.argmax(y_pred, dim=-1).to('cpu')\n",
    "        tot_acc += (preds == torch.tensor(labels)).sum().item() / self.batch_size\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "    tot_acc /= len(loader_list[0])\n",
    "    print(f\"Test Accuracy is {tot_acc:4.2%}. Congrats!\")\n",
    "      \n",
    "  def ensemble_fn(self, tokenizer):\n",
    "    fn = lambda batch: self.collate_fn(batch, tokenizer = tokenizer)\n",
    "    return fn\n",
    "\n",
    "  def collate_fn(self, batch, tokenizer):\n",
    "    \"\"\"\n",
    "      Collate a batch of dataset to same length of text.\n",
    "\n",
    "    ? INPUT\n",
    "    dataset: {text: string, question: string, label: int}\n",
    "\n",
    "    ? OUTPUT\n",
    "    padded token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # integrate from dataset (dict) into list\n",
    "    text_list = [b['text'] for b in batch]\n",
    "    query_list = [b['question'] for b in batch]\n",
    "    label_list = [b['label'] for b in batch]\n",
    "    \n",
    "    # tokenize\n",
    "    text_query_list = list(zip(text_list, query_list))\n",
    "\n",
    "    tokenized_sentence = tokenizer(\n",
    "        text_query_list,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = False\n",
    "    )\n",
    "\n",
    "    # output of tokenized_sentence: {input_ids, token_type_ids, attention_mask}\n",
    "    return tokenized_sentence, label_list\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "Nk_DOajaw2BE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble Inference!"
   ],
   "metadata": {
    "id": "nooyTBl16wT8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#torch.cuda.empty_cache()\n",
    "Eval = InferenceLogitEnsemble(config)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21e7415de074d4d8f870d177284a149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "a21e7415de074d4d8f870d177284a149",
      "b19d5a84e03e4095b56425d25bbb7451",
      "ec80fceb38414763ac9378e6816de4d4",
      "9321d237746c49a78ee667d1463d60e4",
      "f055a648c7ad45039b0fda5342ab2d31",
      "52a8c843f8a3434e938f99ca87c256f5",
      "3036b535e9c24d56819388cb011c1cc3",
      "6dd193b1554a4ff696d84a4c99331624",
      "8ac5f46e57e04418b6520eff3a8d8d65",
      "3f78041ec0ca4345a2680c7a94f6cf15",
      "b9664c0df51a4cb59625224480c34097"
     ]
    },
    "id": "98xs7AD76yGg",
    "outputId": "de5ec46c-3eb6-41be-c9c9-09da5cad4c63"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "Eval.inference()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inference:   0%|          | 0/350 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 144 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Inference: 100%|██████████| 350/350 [00:21<00:00, 16.20it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy is 81.86%. Congrats!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZET5d6jSd0Uq",
    "outputId": "0b150714-86dc-40df-dfe4-c79230b4f0e2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Roberta Ensemble\n",
    "\n",
    "Train and inference with two models which be taken by input of sequence of (question, answer) and (answer, question) respectively."
   ],
   "metadata": {
    "id": "NE0Gjwbb1ZDx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, BertTokenizerFast\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# https://visionhong.tistory.com/30\n",
    "# Here is the code for pl.\n",
    "\n",
    "class BoolQ_Model_Ensemble_Train():\n",
    "  def __init__(self, config, model_name):\n",
    "    super().__init__()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    self.device = device\n",
    "    self.config = config\n",
    "\n",
    "    #####################\n",
    "    ### Configuration ###\n",
    "    #####################\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "\n",
    "    assert model_name in config.model_list.keys(), \"[Training] Please Give Correct Model Name which have been listed.\"\n",
    "    self.model_name = model_name\n",
    "\n",
    "    # load configuration of pretrained model\n",
    "    MODEL_CONFIG = AutoConfig.from_pretrained(config.model_list[model_name])\n",
    "    MODEL_CONFIG.num_labels = 2\n",
    "\n",
    "    if model_name == \"roberta\":\n",
    "      self.model = Roberta_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"bigbird\":\n",
    "      self.model = BigBird_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"electra\":\n",
    "      self.model = Electra_BoolQ(MODEL_CONFIG)\n",
    "    elif model_name == \"albert\":\n",
    "      self.model = Albert_BoolQ(MODEL_CONFIG)\n",
    "\n",
    "    self.model.to(device)\n",
    "\n",
    "\n",
    "    \"\"\" Tokenizer \"\"\"\n",
    "    if model_name == 'albert':\n",
    "      self.tokenizer = BertTokenizerFast.from_pretrained(config.model_list[model_name])\n",
    "    else:\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(config.model_list[model_name])\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "\n",
    "    # train_dataset\n",
    "    self.train_dataset = BoolQ_Dataset(config)\n",
    "\n",
    "    # k_fold index\n",
    "    skf_iris = StratifiedKFold(n_splits=config.k_fold)\n",
    "    self.kfold = config.k_fold\n",
    "    self.KFold_index = list(skf_iris.split(\n",
    "        self.train_dataset.dataset['text'], self.train_dataset.dataset['label']))\n",
    "    \n",
    "    # batch_size\n",
    "    self.batch_size = config.batch_size\n",
    "\n",
    "\n",
    "    \"\"\" optimizer, scheduler (in fit() function), criterion \"\"\"\n",
    "\n",
    "    self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.learning_rate)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    \"\"\" Training Saving \"\"\"\n",
    "\n",
    "    self.log_interval = config.log_interval\n",
    "    self.load_step = 0\n",
    "    self.best_acc = 0\n",
    "    self.wandb = config.mode_wandb\n",
    "    self.save_dir = config.save_dir\n",
    "\n",
    "\n",
    "\n",
    "  def fit(self, epoch):\n",
    "    # schedular\n",
    "    self.scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "      self.optimizer, \n",
    "      num_warmup_steps=config.warmup_steps, \n",
    "      num_training_steps=len(self.train_dataset) * epoch, \n",
    "      last_epoch= -1\n",
    "    )\n",
    "\n",
    "    \n",
    "    \"\"\" GO TRAINING. \"\"\"\n",
    "    self.epoch = epoch\n",
    "\n",
    "    for epo in tqdm(range(epoch), position=0):\n",
    "      ### Stratified KFold\n",
    "      train_idx, val_idx = self.KFold_index[epo % self.kfold]\n",
    "\n",
    "      training_set = Subset(self.train_dataset, train_idx)\n",
    "      validation_set = Subset(self.train_dataset, val_idx)\n",
    "\n",
    "      ### make dataloader\n",
    "      train_loader = DataLoader(training_set, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "      val_loader = DataLoader(validation_set, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "      ### train\n",
    "      self.training_step(train_loader, epo)\n",
    "\n",
    "      ### val\n",
    "      self.validation_step(val_loader, epo)\n",
    "\n",
    "      ### Best model save\n",
    "      if self.best_acc < self.val_acc:\n",
    "        self.best_acc = self.val_acc\n",
    "\n",
    "        print(\"Best Model Saving!\")\n",
    "        print(f\"Current Best Accuracy: {self.best_acc}\")\n",
    "\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(f\"{self.save_dir}/best/{self.model_name}\")\n",
    "        torch.save(self.config, os.path.join(f\"{self.save_dir}/best/{self.model_name}\", \"training_config.bin\"))\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "  def training_step(self, train_loader, epo):\n",
    "    # allocate model to train mode\n",
    "    self.model.train()\n",
    "    tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar = tqdm(total = len(train_loader), desc=\"[Training] Epoch {}\".format(epo+1), position=1)\n",
    "\n",
    "    for texts, labels in train_loader:\n",
    "      ### allocate to cuda or not.\n",
    "      # texts -> cpu tensor, labels -> array.\n",
    "      # texts: {input_ids, token_type_ids, attention_mask}\n",
    "      texts = {key: torch.tensor(value).to(self.device) for key, value in texts.items()}\n",
    "      labels = torch.tensor(labels).to(self.device)\n",
    "\n",
    "      ###########################################\n",
    "      # 1) zero_grad\n",
    "      self.optimizer.zero_grad()\n",
    "\n",
    "      # 2) forward\n",
    "      y_pred = self.model(**texts)[0]\n",
    "\n",
    "      # 3) calculate loss\n",
    "      loss = self.criterion(y_pred, labels)\n",
    "\n",
    "      # 4) backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5) optimier step\n",
    "      self.optimizer.step()\n",
    "\n",
    "      # 6) scheduler step\n",
    "      self.scheduler.step()\n",
    "\n",
    "      ###########################################\n",
    "\n",
    "\n",
    "      ### update, and cumulate match and loss\n",
    "      pbar.update()\n",
    "      self.load_step += 1\n",
    "\n",
    "      preds = torch.argmax(y_pred, dim=-1)\n",
    "      tot_loss += loss.item()\n",
    "      tot_acc += (preds == labels).sum().item() / self.batch_size\n",
    "\n",
    "      ### saving to log\n",
    "      if self.load_step % self.log_interval == 0:\n",
    "        train_loss = tot_loss / self.log_interval\n",
    "        train_acc = tot_acc / self.log_interval\n",
    "        current_lr = self.get_lr(self.optimizer)\n",
    "\n",
    "        pbar.set_description(f\"Epoch: [{epo}/{self.epoch}] || loss: {train_loss:4.4} || acc: {train_acc:4.2%} || lr {current_lr:4.4}\")\n",
    "\n",
    "        self.train_loss = train_loss\n",
    "        self.train_acc = train_acc\n",
    "        self.current_lr = current_lr\n",
    "\n",
    "        tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "\n",
    "  def validation_step(self, val_loader, epo):\n",
    "    # allocate model to eval mode\n",
    "    self.model.eval()\n",
    "    tot_acc, tot_loss = 0., 0.\n",
    "\n",
    "    pbar = tqdm(total = len(val_loader), desc=\"[Validation] Epoch {}\".format(epo+1), position=1)\n",
    "    with torch.no_grad():\n",
    "      for texts, labels in val_loader:\n",
    "        ### allocate to cuda or not.\n",
    "        # texts -> cpu tensor, labels -> array.\n",
    "        # texts: {input_ids, token_type_ids, attention_mask}\n",
    "        texts = {key: torch.tensor(value).to(self.device) for key, value in texts.items()}\n",
    "        labels = torch.tensor(labels).to(self.device)\n",
    "\n",
    "        ###########################################\n",
    "        # 1) forward\n",
    "        y_pred = self.model(**texts)[0]\n",
    "\n",
    "        # 2) calculate loss\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "\n",
    "        ###########################################\n",
    "        \"\"\" Update and save loss \"\"\"\n",
    "\n",
    "        pbar.update()\n",
    "    \n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        tot_loss += loss.item()\n",
    "        tot_acc += (preds == labels).sum().item() / self.batch_size\n",
    "\n",
    "        ############################################\n",
    "        \n",
    "\n",
    "    val_loss = tot_loss / len(val_loader)\n",
    "    val_acc = tot_acc / len(val_loader)\n",
    "\n",
    "    pbar.set_description(f\"Validation: [{epo}/{self.epoch}] || loss: {val_loss:4.4} || acc: {val_acc:4.2%}\")\n",
    "    pbar.close()\n",
    "\n",
    "    if self.wandb:\n",
    "        wandb.log({\"train_loss\": self.train_loss, \"train_acc\": self.train_acc,\n",
    "            \"lr\":self.current_lr, \"valid_loss\":val_loss, \"valid_acc\":val_acc\n",
    "        })\n",
    "\n",
    "    self.val_acc = val_acc\n",
    "\n",
    "\n",
    "\n",
    "  def collate_fn(self, batch):\n",
    "    \"\"\"\n",
    "      Collate a batch of dataset to same length of text.\n",
    "\n",
    "    ? INPUT\n",
    "    dataset: {text: string, question: string, label: int}\n",
    "\n",
    "    ? OUTPUT\n",
    "    padded token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # integrate from dataset (dict) into list\n",
    "    text_list = [b['text'] for b in batch]\n",
    "    query_list = [b['question'] for b in batch]\n",
    "    label_list = [b['label'] for b in batch]\n",
    "    \n",
    "    # tokenize\n",
    "    text_query_list = list(zip(text_list, query_list))\n",
    "\n",
    "    if self.model_name == 'bigbird':\n",
    "      max_length = 1024\n",
    "    else:\n",
    "      max_length = 512\n",
    "\n",
    "    tokenized_sentence = self.tokenizer(\n",
    "        text_query_list,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = False\n",
    "    )\n",
    "\n",
    "    # output of tokenized_sentence: {input_ids, token_type_ids, attention_mask}\n",
    "    return tokenized_sentence, label_list\n",
    "\n",
    "  def get_lr(self, optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "      return param_group['lr']\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "d8RyKvrR2jGX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Test Code"
   ],
   "metadata": {
    "id": "HTHtMZkcdrMc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(config.model_list.keys())"
   ],
   "outputs": [],
   "metadata": {
    "id": "QgfEwMxT8qwc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for (i, x), (j, y) in zip(enumerate(range(3)), enumerate(range(3))):\n",
    "  print(x, y)"
   ],
   "outputs": [],
   "metadata": {
    "id": "N2MkCKDm4HX2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def _collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate a batch of dataset to same length of text.\n",
    "\n",
    "    ? INPUT\n",
    "    dataset: {text: string, question: string, label: int}\n",
    "\n",
    "    ? OUTPUT\n",
    "    padded token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # integrate from dataset (dict) into list\n",
    "    text_list = [b['text'] for b in batch]\n",
    "    query_list = [b['question'] for b in batch]\n",
    "    label_list = [b['label'] for b in batch]\n",
    "\n",
    "    # tokenize\n",
    "    text_query_list = list(zip(text_list, query_list))\n",
    "\n",
    "\n",
    "    tokenized_sentence = tokenizer(\n",
    "        text_query_list,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = True\n",
    "    )\n",
    "\n",
    "# output of tokenized_sentence: {input_ids, token_type_ids, attention_mask}\n",
    "    return tokenized_sentence, label_list\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "EeHI9fuO7YFI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = BoolQ_Dataset(config)\n",
    "for data in Subset(dataset, idx):\n",
    "    print(data)"
   ],
   "outputs": [],
   "metadata": {
    "id": "KAkGMWAH-Uxw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, BigBirdTokenizer, BertTokenizerFast\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobigbird-bert-base\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"kykim/albert-kor-base\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "dataset = BoolQ_Dataset(config)\n",
    "print(dataset)\n",
    "idx = np.asarray([1, 3, 5, 6])\n",
    "print(Subset(dataset, idx))\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 8,\n",
    "    shuffle = True,\n",
    "    collate_fn = _collate_fn\n",
    ")\n",
    "\n",
    "for batch, label_list in loader:\n",
    "  print(batch)\n",
    "  print(batch['input_ids'].shape)\n",
    "  print(batch['token_type_ids'].shape)\n",
    "  print(batch['attention_mask'].shape)\n",
    "\n",
    "  print(tokenizer.batch_decode(batch['input_ids'].tolist()))\n",
    "  print(label_list)\n",
    "  break"
   ],
   "outputs": [],
   "metadata": {
    "id": "VV7rvaaI9UDE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"kykim/albert-kor-base\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "FMT7OlDWgaDn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import functools\n",
    "\n",
    "def foo(a):\n",
    "  fn = lambda b: bar(a, b)\n",
    "  return fn\n",
    "\n",
    "def bar(a, b):\n",
    "  return a+b\n",
    "\n",
    "c = foo(5)\n",
    "c(3)"
   ],
   "outputs": [],
   "metadata": {
    "id": "DCt-EfPK1AjP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 여기서부터 COPA (ㅇ\n",
    "---\n",
    "- Pretrained Model : klue/Roberta-large "
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 아래 실행하여 라이브러리 설치\n",
    "-``` pip install BackTranslation```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모듈 임포트"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from time import sleep\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertPreTrainedModel,\n",
    "    ElectraModel,\n",
    "    ElectraPreTrainedModel,\n",
    "    XLMRobertaModel,\n",
    "    BartModel,\n",
    "    BartPretrainedModel,\n",
    "    T5Model,\n",
    "    RobertaModel,\n",
    ")\n",
    "from transformers import MBartModel, MBartConfig\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from BackTranslation import BackTranslation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation by Backtranslation\n",
    "---\n",
    "- Google Translation 사용\n",
    "- 매우 오래걸리므로 전처리된 파일 사용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "original_train_data = \"dataset/copa/SKT_COPA_Train.tsv\"\n",
    "augmented_train_data = \"dataset/copa/SKT_COPA_Train_aug.tsv\"\n",
    "valid_data = \"dataset/copa/SKT_COPA_Dev.tsv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset = pd.read_csv(\n",
    "    original_train_data,\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"ID\", \"sentence\", \"question\", \"1\", \"2\", \"answer\"],\n",
    "    header=0,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 아래와 같은 코드를 사용하여 backtranslate하였음"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "saved_backtranslated = \"dataset/copa/en_new_sentences.pth\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# trans = BackTranslation(url=['translate.google.co.kr',])\n",
    "# def augment_sentence(trans, s, tmp='en'):\n",
    "#     return trans.translate(s, src='ko', tmp=tmp).result_text\n",
    "# tmps = [en']\n",
    "# new_datasets = dict()\n",
    "# new_sentences = dict()\n",
    "\n",
    "# for tmp in tmps:\n",
    "#     new_dataset = copy.deepcopy(dataset)\n",
    "#     sentences = new_dataset['sentence'].tolist()\n",
    "#     new_sentences[tmp] = list()\n",
    "#     for sent in tqdm(sentences):\n",
    "#         new_sentences[tmp].append(augment_sentence(trans, sent, tmp=tmp))\n",
    "\n",
    "# torch.save(new_sentences, saved_backtranslated)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sent_en = torch.load(saved_backtranslated)\n",
    "sent = dict()\n",
    "sent['en'] = sent_en['en']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 원본 데이터셋"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이퀄라이저로 저음 음역대 소리 크기를 키웠다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>음료에 초콜렛 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>남자는 휴대폰을 호수에 빠뜨렸다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>옆 집 사람이 이사를 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                   sentence question                   1  \\\n",
       "0   1  이퀄라이저로 저음 음역대 소리 크기를 키웠다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1   2           음료에 초콜렛 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2   3         남자는 휴대폰을 호수에 빠뜨렸다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3   4           옆 집 사람이 이사를 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4   5                    문을 밀었다.       결과             문이 잠겼다.   \n",
       "\n",
       "                     2  answer  \n",
       "0  베이스 소리가 들리지 않게 되었다.       1  \n",
       "1          음료수가 차가워졌다.       1  \n",
       "2           휴대폰이 고장났다.       2  \n",
       "3    옆 집 사람은 계약을 연장했다.       1  \n",
       "4              문이 열렸다.       2  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "new_dataset = copy.deepcopy(dataset)\n",
    "new_dataset['ID'] += len(dataset)\n",
    "new_dataset['sentence'] = sent['en']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BackTranslate로 augment한 데이터셋"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "new_dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3081</td>\n",
       "      <td>이퀄라이저는베이스 스캔의 사운드를 올렸습니다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3082</td>\n",
       "      <td>나는 음료에 초콜릿 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3083</td>\n",
       "      <td>그 남자는 호수에 휴대 전화를 넣었습니다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3084</td>\n",
       "      <td>집 옆에있는 사람이 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3085</td>\n",
       "      <td>나는 문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                   sentence question                   1  \\\n",
       "0  3081  이퀄라이저는베이스 스캔의 사운드를 올렸습니다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1  3082        나는 음료에 초콜릿 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2  3083    그 남자는 호수에 휴대 전화를 넣었습니다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3  3084            집 옆에있는 사람이 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4  3085                 나는 문을 밀었다.       결과             문이 잠겼다.   \n",
       "\n",
       "                     2  answer  \n",
       "0  베이스 소리가 들리지 않게 되었다.       1  \n",
       "1          음료수가 차가워졌다.       1  \n",
       "2           휴대폰이 고장났다.       2  \n",
       "3    옆 집 사람은 계약을 연장했다.       1  \n",
       "4              문이 열렸다.       2  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 합병"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "new_dataset = dataset.append(new_dataset)\n",
    "new_dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이퀄라이저로 저음 음역대 소리 크기를 키웠다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>음료에 초콜렛 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>남자는 휴대폰을 호수에 빠뜨렸다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>옆 집 사람이 이사를 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>6156</td>\n",
       "      <td>계약자로 일한 남자들은 떠났다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>계약을 연장했다.</td>\n",
       "      <td>계약이 종료되었다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>6157</td>\n",
       "      <td>목 마른.</td>\n",
       "      <td>원인</td>\n",
       "      <td>물을 마시지 못했다.</td>\n",
       "      <td>텀블러를 샀다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>6158</td>\n",
       "      <td>나는 그 노래를 오랫동안 전화 했어.</td>\n",
       "      <td>결과</td>\n",
       "      <td>목이 아프다.</td>\n",
       "      <td>노래방이 폐업했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>6159</td>\n",
       "      <td>사람들은 한 번 함께 일하고 있습니다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>우리나라 축구팀이 골을 넣었다.</td>\n",
       "      <td>우리나라 축구팀이 경기에서 패배했다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>6160</td>\n",
       "      <td>가수의 목이 쉬워졌습니다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>가수가 3시간 동안 춤을 추었다.</td>\n",
       "      <td>가수가 3시간 동안 노래를 불렀다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                   sentence question                   1  \\\n",
       "0        1  이퀄라이저로 저음 음역대 소리 크기를 키웠다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1        2           음료에 초콜렛 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2        3         남자는 휴대폰을 호수에 빠뜨렸다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3        4           옆 집 사람이 이사를 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4        5                    문을 밀었다.       결과             문이 잠겼다.   \n",
       "...    ...                        ...      ...                 ...   \n",
       "3075  6156          계약자로 일한 남자들은 떠났다.       원인           계약을 연장했다.   \n",
       "3076  6157                      목 마른.       원인         물을 마시지 못했다.   \n",
       "3077  6158       나는 그 노래를 오랫동안 전화 했어.       결과             목이 아프다.   \n",
       "3078  6159      사람들은 한 번 함께 일하고 있습니다.       원인   우리나라 축구팀이 골을 넣었다.   \n",
       "3079  6160             가수의 목이 쉬워졌습니다.       원인  가수가 3시간 동안 춤을 추었다.   \n",
       "\n",
       "                         2  answer  \n",
       "0      베이스 소리가 들리지 않게 되었다.       1  \n",
       "1              음료수가 차가워졌다.       1  \n",
       "2               휴대폰이 고장났다.       2  \n",
       "3        옆 집 사람은 계약을 연장했다.       1  \n",
       "4                  문이 열렸다.       2  \n",
       "...                    ...     ...  \n",
       "3075            계약이 종료되었다.       2  \n",
       "3076              텀블러를 샀다.       1  \n",
       "3077            노래방이 폐업했다.       1  \n",
       "3078  우리나라 축구팀이 경기에서 패배했다.       2  \n",
       "3079   가수가 3시간 동안 노래를 불렀다.       2  \n",
       "\n",
       "[6160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "new_dataset.to_csv(augmented_train_data, sep='\\t')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COPA 학습 & Inference to json 코드\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformers의 Wrapper Class와 일부 테스트 모델 선언 및 구현부"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class PoolingHead(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim: int, inner_dim: int, pooler_dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, inner_dim)\n",
    "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = torch.tanh(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class Bert(BertPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Bert, self).__init__(config)\n",
    "        self.bert = BertModel(config=config)  # Load pretrained bert\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.bert(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class XLMRoberta(XLMRobertaModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(XLMRoberta, self).__init__(config)\n",
    "        self.xlmroberta = XLMRobertaModel.from_pretrained(\n",
    "            \"xlm-roberta-large\", config=config\n",
    "        )  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.xlmroberta(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.xlmroberta(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class Electra_BoolQ(ElectraPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Electra_BoolQ, self).__init__(config)\n",
    "\n",
    "        # self.num_labels = config.num_labels\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = ElectraModel.from_pretrained(\n",
    "            \"monologg/koelectra-base-v3-discriminator\", config=config\n",
    "        )\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "        # self.sparse = Sparsemax()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.model(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.model(\n",
    "            input_ids2, attention_mask=attention_mask2, token_type_ids=token_type_ids2\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class Roberta(RobertaModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Roberta, self).__init__(config)\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            \"klue/roberta-large\", config=config\n",
    "        )  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.roberta(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 전처리부\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.tokenized_dataset.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def load_data(dataset_dir):\n",
    "    dataset = pd.read_csv(\n",
    "        dataset_dir,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"ID\", \"sentence\", \"question\", \"1\", \"2\", \"answer\"],\n",
    "        header=0,\n",
    "    )\n",
    "    dataset[\"label\"] = dataset[\"answer\"].astype(int) - 1\n",
    "\n",
    "    new_sentence1_1 = []\n",
    "    new_sentence1_2 = []\n",
    "    new_sentence2_1 = []\n",
    "    new_sentence2_2 = []\n",
    "    for i in range(len(dataset)):\n",
    "        s = dataset.iloc[i][\"sentence\"]\n",
    "        q = dataset.iloc[i][\"question\"]\n",
    "        s1 = dataset.iloc[i][\"1\"]\n",
    "        s2 = dataset.iloc[i][\"2\"]\n",
    "        lb = dataset.iloc[i][\"label\"]\n",
    "        if q == \"결과\":\n",
    "            new_sentence1_1.append(\"[결과]\" + s)\n",
    "            # new_sentence1_1.append(s)\n",
    "            new_sentence1_2.append(s1)\n",
    "            new_sentence2_1.append(\"[결과]\" + s)\n",
    "            # new_sentence2_1.append(s)\n",
    "            new_sentence2_2.append(s2)\n",
    "\n",
    "        else:\n",
    "            new_sentence1_1.append(\"[원인]\" + s1)\n",
    "            # new_sentence1_1.append(s1)\n",
    "            new_sentence1_2.append(s)\n",
    "            new_sentence2_1.append(\"[원인]\" + s2)\n",
    "            # new_sentence2_1.append(s2)\n",
    "            new_sentence2_2.append(s)\n",
    "\n",
    "    dataset[\"new_sentence1_1\"] = new_sentence1_1\n",
    "    dataset[\"new_sentence1_2\"] = new_sentence1_2\n",
    "    dataset[\"new_sentence2_1\"] = new_sentence2_1\n",
    "    dataset[\"new_sentence2_2\"] = new_sentence2_2\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenized_dataset(dataset, tokenizer, arch=\"encoder\"):\n",
    "    sentence1_1 = dataset[\"new_sentence1_1\"].tolist()\n",
    "    sentence1_2 = dataset[\"new_sentence1_2\"].tolist()\n",
    "    sentence2_1 = dataset[\"new_sentence2_1\"].tolist()\n",
    "    sentence2_2 = dataset[\"new_sentence2_2\"].tolist()\n",
    "\n",
    "    tokenized_sentences = tokenizer(\n",
    "        sentence1_1,\n",
    "        sentence1_2,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=150,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    tokenized_sentences2 = tokenizer(\n",
    "        sentence2_1,\n",
    "        sentence2_2,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=150,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    for key, value in tokenized_sentences2.items():\n",
    "        tokenized_sentences[key + \"2\"] = value\n",
    "\n",
    "    return tokenized_sentences\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 트레이닝"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def check_arch(model_type):\n",
    "    archs = {\n",
    "        \"encoder\": [\"Bert\", \"Electra\", \"XLMRoberta\", \"Electra_BoolQ\", \"Roberta\"],\n",
    "        \"encoder-decoder\": [\"T5\", \"Bart\", \"Bart_BoolQ\"],\n",
    "    }\n",
    "    for arch in archs:\n",
    "        if model_type in archs[arch]:\n",
    "            return arch\n",
    "    raise ValueError(f\"Model [{model_type}] no defined archtecture\")\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }\n",
    "\n",
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "    path = Path(output_path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\"\n",
    "\n",
    "def train(model_dir, args):\n",
    "\n",
    "    seed_everything(args.seed)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"device(GPU) : {torch.cuda.is_available()}\")\n",
    "    num_classes = 2\n",
    "\n",
    "    # load model and tokenizerƒ\n",
    "    MODEL_NAME = args.pretrained_model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # load dataset\n",
    "    train_dataset = load_data(augmented_train_data)\n",
    "    val_dataset = load_data(valid_data)\n",
    "\n",
    "    train_label = train_dataset[\"label\"].values\n",
    "    val_label = val_dataset[\"label\"].values\n",
    "\n",
    "    # tokenizing dataset\n",
    "    tokenized_train = tokenized_dataset(\n",
    "        train_dataset, tokenizer, check_arch(args.model_type)\n",
    "    )\n",
    "    tokenized_val = tokenized_dataset(\n",
    "        val_dataset, tokenizer, check_arch(args.model_type)\n",
    "    )\n",
    "\n",
    "    # make dataset for pytorch.\n",
    "    train_dataset = CustomDataset(tokenized_train, train_label)\n",
    "    val_dataset = CustomDataset(tokenized_val, val_label)\n",
    "    # -- data_loader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=args.valid_batch_size, shuffle=False, drop_last=False,\n",
    "    )\n",
    "\n",
    "    # setting model hyperparameter\n",
    "    if args.model_type == \"Electra_BoolQ\":\n",
    "        config_module = ElectraConfig\n",
    "    else:\n",
    "        config_module = getattr(\n",
    "            import_module(\"transformers\"), args.model_type + \"Config\"\n",
    "        )\n",
    "\n",
    "    model_config = config_module.from_pretrained(MODEL_NAME)\n",
    "    model_config.num_labels = 2\n",
    "\n",
    "    model_module = eval(args.model_type)\n",
    "\n",
    "    if args.model_type in [\"BERT\", \"Electra\"]:\n",
    "        model = model_module.from_pretrained(\n",
    "            MODEL_NAME, config=model_config, args=args\n",
    "        )\n",
    "    else:\n",
    "        model = model_module(config=model_config, args=args)\n",
    "\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "    save_dir = increment_output_dir(os.path.join(model_dir, args.name, str(args.kfold)))\n",
    "\n",
    "    # Freeze Parameter\n",
    "    for name, param in model.named_parameters():\n",
    "        if (\"cls_fc_layer\" not in name) and (\n",
    "            \"label_classifier\" not in name\n",
    "        ):  # classifier layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # -- loss & metric\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    opt_module = getattr(import_module(\"transformers\"), args.optimizer)\n",
    "    optimizer = opt_module(\n",
    "        model.parameters(), lr=args.lr, weight_decay=args.weight_decay, eps=1e-8\n",
    "    )\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=args.warmup_steps,\n",
    "        num_training_steps=len(train_loader) * args.epochs,\n",
    "        last_epoch=-1,\n",
    "    )\n",
    "\n",
    "    # -- logging\n",
    "    start_time = time.time()\n",
    "    logger = SummaryWriter(log_dir=save_dir)\n",
    "    with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(vars(args), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(args.epochs):\n",
    "        # train loop\n",
    "        # unFreeze parameters\n",
    "        if epoch == args.freeze_epoch:\n",
    "            for name, param in model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, items in enumerate(train_loader):\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(**item)\n",
    "            loss = criterion(outs[0], item[\"labels\"])\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == item[\"labels\"]).sum().item()\n",
    "            if (idx + 1) % args.log_interval == 0:\n",
    "                train_loss = loss_value / args.log_interval\n",
    "                train_acc = matches / args.batch_size / args.log_interval\n",
    "                current_lr = get_lr(optimizer)\n",
    "                print(\n",
    "                    f\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "                )\n",
    "\n",
    "                logger.add_scalar(\n",
    "                    \"Train/loss\", train_loss, epoch * len(train_loader) + idx\n",
    "                )\n",
    "                logger.add_scalar(\n",
    "                    \"Train/accuracy\", train_acc, epoch * len(train_loader) + idx\n",
    "                )\n",
    "                logger.add_scalar(\"LR\", current_lr, epoch * len(train_loader) + idx)\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "\n",
    "        # val loop\n",
    "        with torch.no_grad():\n",
    "            print(\"Calculating validation results...\")\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items = []\n",
    "            acc_okay = 0\n",
    "            count_all = 0\n",
    "            for idx, items in enumerate(tqdm(val_loader)):\n",
    "                sleep(0.01)\n",
    "                item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "                outs = model(**item)\n",
    "\n",
    "                preds = torch.argmax(outs[0], dim=-1)\n",
    "                loss = criterion(outs[0], item[\"labels\"]).item()\n",
    "\n",
    "                acc_item = (item[\"labels\"] == preds).sum().item()\n",
    "\n",
    "                val_loss_items.append(loss)\n",
    "                val_acc_items.append(acc_item)\n",
    "                acc_okay += acc_item\n",
    "                count_all += len(preds)\n",
    "\n",
    "            val_loss = np.sum(val_loss_items) / len(val_loss_items)\n",
    "            val_acc = acc_okay / count_all\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                print(\n",
    "                    f\"New best model for val acc : {val_acc:4.2%}! saving the best model..\"\n",
    "                )\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "                torch.save(args, os.path.join(f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "            print(\n",
    "                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.4}|| \"\n",
    "                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.4}\"\n",
    "            )\n",
    "\n",
    "            logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "            logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "            s = f\"Time elapsed: {(time.time() - start_time)/60: .2f} min\"\n",
    "            print(s)\n",
    "            print()\n",
    "            if epoch > 24:\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "                torch.save(args, os.path.join(f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "                break\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Configuration\n",
    "---\n",
    "1. Roberta-large pretrained model 사용하여 fine-tune\n",
    "2. 10epoch 내외로 수렴하는 것을 확인해서 15epoch만 돌림"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "args  = EasyDict(dict(\n",
    "    epochs = 15,\n",
    "    model_type = \"Roberta\",\n",
    "    pretrained_model = \"klue/roberta-large\",\n",
    "    lr = 8e-6,\n",
    "    batch_size = 32,\n",
    "    freeze_epoch = 0,\n",
    "    valid_batch_size = 128,\n",
    "    val_ratio = 0.2,\n",
    "    dropout_rate = 0.1,\n",
    "    criterion = 'cross_entropy',\n",
    "    optimizer = 'AdamW',\n",
    "    weight_decay = 0.01,\n",
    "    warmup_steps = 500,\n",
    "    seed = 42,\n",
    "    log_interval = 20,\n",
    "    kfold = 1,\n",
    "    model_dir = \"./copa_data_results/results\",\n",
    "))\n",
    "    \n",
    "    \n",
    "    \n",
    "args.name = f'TrainAll_{args.model_type}_{args.lr}'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model = train(args.model_dir, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device(GPU) : True\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch[0/15](20/192) || training loss 0.6938 || training accuracy 50.62% || lr 3.2e-07\n",
      "Epoch[0/15](40/192) || training loss 0.6936 || training accuracy 48.44% || lr 6.4e-07\n",
      "Epoch[0/15](60/192) || training loss 0.6956 || training accuracy 47.34% || lr 9.6e-07\n",
      "Epoch[0/15](80/192) || training loss 0.6906 || training accuracy 52.81% || lr 1.28e-06\n",
      "Epoch[0/15](100/192) || training loss 0.6913 || training accuracy 54.22% || lr 1.6e-06\n",
      "Epoch[0/15](120/192) || training loss 0.6918 || training accuracy 53.59% || lr 1.92e-06\n",
      "Epoch[0/15](140/192) || training loss 0.6883 || training accuracy 56.41% || lr 2.24e-06\n",
      "Epoch[0/15](160/192) || training loss 0.6875 || training accuracy 54.53% || lr 2.56e-06\n",
      "Epoch[0/15](180/192) || training loss 0.6704 || training accuracy 61.09% || lr 2.88e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5386d635dcc4d9aa8b4705ed887c2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New best model for val acc : 78.80%! saving the best model..\n",
      "[Val] acc : 78.80%, loss: 0.4907|| best acc : 78.80%, best loss: 0.4907\n",
      "Time elapsed:  1.08 min\n",
      "\n",
      "Epoch[1/15](20/192) || training loss 0.4782 || training accuracy 77.50% || lr 3.392e-06\n",
      "Epoch[1/15](40/192) || training loss 0.381 || training accuracy 84.06% || lr 3.712e-06\n",
      "Epoch[1/15](60/192) || training loss 0.4154 || training accuracy 82.19% || lr 4.032e-06\n",
      "Epoch[1/15](80/192) || training loss 0.3368 || training accuracy 85.62% || lr 4.352e-06\n",
      "Epoch[1/15](100/192) || training loss 0.3439 || training accuracy 85.47% || lr 4.6719999999999995e-06\n",
      "Epoch[1/15](120/192) || training loss 0.3751 || training accuracy 82.97% || lr 4.992e-06\n",
      "Epoch[1/15](140/192) || training loss 0.2885 || training accuracy 88.28% || lr 5.312e-06\n",
      "Epoch[1/15](160/192) || training loss 0.2783 || training accuracy 86.72% || lr 5.632e-06\n",
      "Epoch[1/15](180/192) || training loss 0.3064 || training accuracy 87.81% || lr 5.952e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feb5b838e38464dbf00014380d5eec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New best model for val acc : 91.20%! saving the best model..\n",
      "[Val] acc : 91.20%, loss: 0.2792|| best acc : 91.20%, best loss: 0.2792\n",
      "Time elapsed:  2.26 min\n",
      "\n",
      "Epoch[2/15](20/192) || training loss 0.1712 || training accuracy 93.28% || lr 6.464e-06\n",
      "Epoch[2/15](40/192) || training loss 0.1538 || training accuracy 92.97% || lr 6.784e-06\n",
      "Epoch[2/15](60/192) || training loss 0.1435 || training accuracy 94.38% || lr 7.104e-06\n",
      "Epoch[2/15](80/192) || training loss 0.1839 || training accuracy 92.50% || lr 7.424e-06\n",
      "Epoch[2/15](100/192) || training loss 0.1547 || training accuracy 94.38% || lr 7.743999999999999e-06\n",
      "Epoch[2/15](120/192) || training loss 0.1975 || training accuracy 92.81% || lr 7.986554621848738e-06\n",
      "Epoch[2/15](140/192) || training loss 0.1413 || training accuracy 95.00% || lr 7.919327731092437e-06\n",
      "Epoch[2/15](160/192) || training loss 0.141 || training accuracy 95.16% || lr 7.852100840336134e-06\n",
      "Epoch[2/15](180/192) || training loss 0.1112 || training accuracy 95.47% || lr 7.784873949579831e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0195235b67420d91d981cf78fa599e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New best model for val acc : 91.60%! saving the best model..\n",
      "[Val] acc : 91.60%, loss: 0.3272|| best acc : 91.60%, best loss: 0.2792\n",
      "Time elapsed:  3.43 min\n",
      "\n",
      "Epoch[3/15](20/192) || training loss 0.06428 || training accuracy 97.34% || lr 7.677310924369748e-06\n",
      "Epoch[3/15](40/192) || training loss 0.066 || training accuracy 97.97% || lr 7.610084033613444e-06\n",
      "Epoch[3/15](60/192) || training loss 0.06924 || training accuracy 97.97% || lr 7.542857142857142e-06\n",
      "Epoch[3/15](80/192) || training loss 0.05448 || training accuracy 98.28% || lr 7.47563025210084e-06\n",
      "Epoch[3/15](100/192) || training loss 0.05794 || training accuracy 97.97% || lr 7.408403361344538e-06\n",
      "Epoch[3/15](120/192) || training loss 0.0687 || training accuracy 97.66% || lr 7.341176470588234e-06\n",
      "Epoch[3/15](140/192) || training loss 0.04584 || training accuracy 99.06% || lr 7.273949579831932e-06\n",
      "Epoch[3/15](160/192) || training loss 0.03607 || training accuracy 99.06% || lr 7.20672268907563e-06\n",
      "Epoch[3/15](180/192) || training loss 0.05669 || training accuracy 98.12% || lr 7.139495798319327e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e04832952a74a1fadcd92098cffc955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 90.60%, loss: 0.4094|| best acc : 91.60%, best loss: 0.2792\n",
      "Time elapsed:  4.46 min\n",
      "\n",
      "Epoch[4/15](20/192) || training loss 0.04117 || training accuracy 98.59% || lr 7.031932773109243e-06\n",
      "Epoch[4/15](40/192) || training loss 0.03569 || training accuracy 98.75% || lr 6.964705882352941e-06\n",
      "Epoch[4/15](60/192) || training loss 0.02685 || training accuracy 99.06% || lr 6.897478991596638e-06\n",
      "Epoch[4/15](80/192) || training loss 0.03934 || training accuracy 98.12% || lr 6.830252100840335e-06\n",
      "Epoch[4/15](100/192) || training loss 0.02512 || training accuracy 99.22% || lr 6.763025210084033e-06\n",
      "Epoch[4/15](120/192) || training loss 0.02224 || training accuracy 99.38% || lr 6.695798319327731e-06\n",
      "Epoch[4/15](140/192) || training loss 0.02148 || training accuracy 99.69% || lr 6.628571428571428e-06\n",
      "Epoch[4/15](160/192) || training loss 0.02032 || training accuracy 99.06% || lr 6.5613445378151255e-06\n",
      "Epoch[4/15](180/192) || training loss 0.02397 || training accuracy 99.38% || lr 6.4941176470588234e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937eb1dd6b4e41e28d12ce99fc6679f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New best model for val acc : 92.00%! saving the best model..\n",
      "[Val] acc : 92.00%, loss: 0.3837|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  5.64 min\n",
      "\n",
      "Epoch[5/15](20/192) || training loss 0.02074 || training accuracy 99.06% || lr 6.386554621848739e-06\n",
      "Epoch[5/15](40/192) || training loss 0.01713 || training accuracy 99.53% || lr 6.319327731092436e-06\n",
      "Epoch[5/15](60/192) || training loss 0.02199 || training accuracy 99.22% || lr 6.252100840336134e-06\n",
      "Epoch[5/15](80/192) || training loss 0.02969 || training accuracy 98.75% || lr 6.184873949579832e-06\n",
      "Epoch[5/15](100/192) || training loss 0.01875 || training accuracy 99.69% || lr 6.1176470588235285e-06\n",
      "Epoch[5/15](120/192) || training loss 0.0256 || training accuracy 98.91% || lr 6.0504201680672265e-06\n",
      "Epoch[5/15](140/192) || training loss 0.02173 || training accuracy 99.69% || lr 5.9831932773109244e-06\n",
      "Epoch[5/15](160/192) || training loss 0.01657 || training accuracy 99.53% || lr 5.9159663865546215e-06\n",
      "Epoch[5/15](180/192) || training loss 0.022 || training accuracy 99.22% || lr 5.848739495798319e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd4f1a66e744db19fbe0ab74ba77703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.20%, loss: 0.4203|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  6.66 min\n",
      "\n",
      "Epoch[6/15](20/192) || training loss 0.01329 || training accuracy 99.69% || lr 5.741176470588235e-06\n",
      "Epoch[6/15](40/192) || training loss 0.02177 || training accuracy 99.69% || lr 5.6739495798319324e-06\n",
      "Epoch[6/15](60/192) || training loss 0.01304 || training accuracy 99.69% || lr 5.6067226890756295e-06\n",
      "Epoch[6/15](80/192) || training loss 0.009519 || training accuracy 99.84% || lr 5.5394957983193275e-06\n",
      "Epoch[6/15](100/192) || training loss 0.01774 || training accuracy 99.53% || lr 5.472268907563025e-06\n",
      "Epoch[6/15](120/192) || training loss 0.01284 || training accuracy 99.69% || lr 5.4050420168067225e-06\n",
      "Epoch[6/15](140/192) || training loss 0.008861 || training accuracy 99.69% || lr 5.33781512605042e-06\n",
      "Epoch[6/15](160/192) || training loss 0.009139 || training accuracy 99.84% || lr 5.2705882352941176e-06\n",
      "Epoch[6/15](180/192) || training loss 0.01358 || training accuracy 99.53% || lr 5.203361344537815e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe25dfb07bf49de8fc8e5d4ecc9e752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.80%, loss: 0.4458|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  7.69 min\n",
      "\n",
      "Epoch[7/15](20/192) || training loss 0.01839 || training accuracy 99.22% || lr 5.0957983193277305e-06\n",
      "Epoch[7/15](40/192) || training loss 0.01006 || training accuracy 99.69% || lr 5.0285714285714285e-06\n",
      "Epoch[7/15](60/192) || training loss 0.009921 || training accuracy 99.84% || lr 4.9613445378151256e-06\n",
      "Epoch[7/15](80/192) || training loss 0.006946 || training accuracy 99.84% || lr 4.8941176470588235e-06\n",
      "Epoch[7/15](100/192) || training loss 0.01625 || training accuracy 99.53% || lr 4.826890756302521e-06\n",
      "Epoch[7/15](120/192) || training loss 0.009226 || training accuracy 99.69% || lr 4.7596638655462185e-06\n",
      "Epoch[7/15](140/192) || training loss 0.01174 || training accuracy 99.69% || lr 4.692436974789916e-06\n",
      "Epoch[7/15](160/192) || training loss 0.005835 || training accuracy 100.00% || lr 4.625210084033614e-06\n",
      "Epoch[7/15](180/192) || training loss 0.007438 || training accuracy 99.84% || lr 4.557983193277311e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61da387e7a4448bb10ca7f32f39450f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.80%, loss: 0.4472|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  8.72 min\n",
      "\n",
      "Epoch[8/15](20/192) || training loss 0.006374 || training accuracy 100.00% || lr 4.4504201680672266e-06\n",
      "Epoch[8/15](40/192) || training loss 0.006707 || training accuracy 99.84% || lr 4.3831932773109245e-06\n",
      "Epoch[8/15](60/192) || training loss 0.006601 || training accuracy 99.84% || lr 4.315966386554622e-06\n",
      "Epoch[8/15](80/192) || training loss 0.007672 || training accuracy 99.84% || lr 4.2487394957983195e-06\n",
      "Epoch[8/15](100/192) || training loss 0.005372 || training accuracy 99.84% || lr 4.181512605042017e-06\n",
      "Epoch[8/15](120/192) || training loss 0.008952 || training accuracy 99.69% || lr 4.114285714285714e-06\n",
      "Epoch[8/15](140/192) || training loss 0.006693 || training accuracy 99.69% || lr 4.047058823529412e-06\n",
      "Epoch[8/15](160/192) || training loss 0.004281 || training accuracy 100.00% || lr 3.979831932773109e-06\n",
      "Epoch[8/15](180/192) || training loss 0.003682 || training accuracy 100.00% || lr 3.912605042016807e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4ab561033e4b8eb6259513978e0826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 92.00%, loss: 0.483|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  9.74 min\n",
      "\n",
      "Epoch[9/15](20/192) || training loss 0.002338 || training accuracy 100.00% || lr 3.805042016806722e-06\n",
      "Epoch[9/15](40/192) || training loss 0.003144 || training accuracy 100.00% || lr 3.73781512605042e-06\n",
      "Epoch[9/15](60/192) || training loss 0.001843 || training accuracy 100.00% || lr 3.670588235294117e-06\n",
      "Epoch[9/15](80/192) || training loss 0.009822 || training accuracy 99.53% || lr 3.603361344537815e-06\n",
      "Epoch[9/15](100/192) || training loss 0.007631 || training accuracy 99.69% || lr 3.5361344537815122e-06\n",
      "Epoch[9/15](120/192) || training loss 0.00453 || training accuracy 100.00% || lr 3.46890756302521e-06\n",
      "Epoch[9/15](140/192) || training loss 0.002018 || training accuracy 100.00% || lr 3.4016806722689073e-06\n",
      "Epoch[9/15](160/192) || training loss 0.005038 || training accuracy 100.00% || lr 3.3344537815126052e-06\n",
      "Epoch[9/15](180/192) || training loss 0.01228 || training accuracy 99.69% || lr 3.2672268907563023e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20631899fd4d433796ae354fd75fa3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 90.40%, loss: 0.4537|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  10.77 min\n",
      "\n",
      "Epoch[10/15](20/192) || training loss 0.001722 || training accuracy 100.00% || lr 3.159663865546218e-06\n",
      "Epoch[10/15](40/192) || training loss 0.004434 || training accuracy 100.00% || lr 3.092436974789916e-06\n",
      "Epoch[10/15](60/192) || training loss 0.004272 || training accuracy 99.84% || lr 3.0252100840336132e-06\n",
      "Epoch[10/15](80/192) || training loss 0.002358 || training accuracy 100.00% || lr 2.9579831932773108e-06\n",
      "Epoch[10/15](100/192) || training loss 0.001988 || training accuracy 100.00% || lr 2.8907563025210083e-06\n",
      "Epoch[10/15](120/192) || training loss 0.005524 || training accuracy 99.84% || lr 2.823529411764706e-06\n",
      "Epoch[10/15](140/192) || training loss 0.001401 || training accuracy 100.00% || lr 2.7563025210084033e-06\n",
      "Epoch[10/15](160/192) || training loss 0.005311 || training accuracy 99.84% || lr 2.689075630252101e-06\n",
      "Epoch[10/15](180/192) || training loss 0.002814 || training accuracy 100.00% || lr 2.6218487394957984e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf7883e0ed74524a6500c5385d1507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 90.80%, loss: 0.4928|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  11.79 min\n",
      "\n",
      "Epoch[11/15](20/192) || training loss 0.006685 || training accuracy 99.53% || lr 2.5142857142857142e-06\n",
      "Epoch[11/15](40/192) || training loss 0.001531 || training accuracy 100.00% || lr 2.4470588235294118e-06\n",
      "Epoch[11/15](60/192) || training loss 0.002856 || training accuracy 99.84% || lr 2.3798319327731093e-06\n",
      "Epoch[11/15](80/192) || training loss 0.004037 || training accuracy 99.84% || lr 2.312605042016807e-06\n",
      "Epoch[11/15](100/192) || training loss 0.003251 || training accuracy 100.00% || lr 2.2453781512605043e-06\n",
      "Epoch[11/15](120/192) || training loss 0.007113 || training accuracy 99.84% || lr 2.1781512605042014e-06\n",
      "Epoch[11/15](140/192) || training loss 0.001861 || training accuracy 100.00% || lr 2.110924369747899e-06\n",
      "Epoch[11/15](160/192) || training loss 0.001811 || training accuracy 100.00% || lr 2.0436974789915965e-06\n",
      "Epoch[11/15](180/192) || training loss 0.001926 || training accuracy 100.00% || lr 1.976470588235294e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139242c988fb488195159e6ac47e71cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 90.80%, loss: 0.4789|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  12.82 min\n",
      "\n",
      "Epoch[12/15](20/192) || training loss 0.002779 || training accuracy 99.84% || lr 1.86890756302521e-06\n",
      "Epoch[12/15](40/192) || training loss 0.00307 || training accuracy 100.00% || lr 1.8016806722689076e-06\n",
      "Epoch[12/15](60/192) || training loss 0.003593 || training accuracy 99.84% || lr 1.734453781512605e-06\n",
      "Epoch[12/15](80/192) || training loss 0.003506 || training accuracy 100.00% || lr 1.6672268907563026e-06\n",
      "Epoch[12/15](100/192) || training loss 0.00425 || training accuracy 100.00% || lr 1.6e-06\n",
      "Epoch[12/15](120/192) || training loss 0.001967 || training accuracy 100.00% || lr 1.5327731092436974e-06\n",
      "Epoch[12/15](140/192) || training loss 0.004414 || training accuracy 99.84% || lr 1.4655462184873948e-06\n",
      "Epoch[12/15](160/192) || training loss 0.002093 || training accuracy 100.00% || lr 1.3983193277310923e-06\n",
      "Epoch[12/15](180/192) || training loss 0.005751 || training accuracy 99.84% || lr 1.3310924369747898e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c676344a0dc94952b9234873de66386c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.40%, loss: 0.479|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  13.85 min\n",
      "\n",
      "Epoch[13/15](20/192) || training loss 0.001776 || training accuracy 100.00% || lr 1.2235294117647059e-06\n",
      "Epoch[13/15](40/192) || training loss 0.001028 || training accuracy 100.00% || lr 1.1563025210084034e-06\n",
      "Epoch[13/15](60/192) || training loss 0.002657 || training accuracy 100.00% || lr 1.0890756302521007e-06\n",
      "Epoch[13/15](80/192) || training loss 0.0009199 || training accuracy 100.00% || lr 1.0218487394957982e-06\n",
      "Epoch[13/15](100/192) || training loss 0.004904 || training accuracy 99.84% || lr 9.546218487394957e-07\n",
      "Epoch[13/15](120/192) || training loss 0.001452 || training accuracy 100.00% || lr 8.873949579831932e-07\n",
      "Epoch[13/15](140/192) || training loss 0.002073 || training accuracy 100.00% || lr 8.201680672268907e-07\n",
      "Epoch[13/15](160/192) || training loss 0.002645 || training accuracy 100.00% || lr 7.529411764705882e-07\n",
      "Epoch[13/15](180/192) || training loss 0.00177 || training accuracy 100.00% || lr 6.857142857142857e-07\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fe06e1941041d4b2b668d6eafa9af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.00%, loss: 0.4957|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  14.88 min\n",
      "\n",
      "Epoch[14/15](20/192) || training loss 0.0006829 || training accuracy 100.00% || lr 5.781512605042017e-07\n",
      "Epoch[14/15](40/192) || training loss 0.005888 || training accuracy 99.84% || lr 5.109243697478991e-07\n",
      "Epoch[14/15](60/192) || training loss 0.004824 || training accuracy 99.69% || lr 4.436974789915966e-07\n",
      "Epoch[14/15](80/192) || training loss 0.001067 || training accuracy 100.00% || lr 3.764705882352941e-07\n",
      "Epoch[14/15](100/192) || training loss 0.003102 || training accuracy 100.00% || lr 3.0924369747899157e-07\n",
      "Epoch[14/15](120/192) || training loss 0.001379 || training accuracy 100.00% || lr 2.4201680672268904e-07\n",
      "Epoch[14/15](140/192) || training loss 0.001097 || training accuracy 100.00% || lr 1.7478991596638653e-07\n",
      "Epoch[14/15](160/192) || training loss 0.002399 || training accuracy 100.00% || lr 1.0756302521008403e-07\n",
      "Epoch[14/15](180/192) || training loss 0.0005987 || training accuracy 100.00% || lr 4.033613445378151e-08\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaf93bbc06045c7876a9c294c17a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Val] acc : 91.00%, loss: 0.4968|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  15.91 min\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference : \n",
    "---\n",
    "- target_dir(Best Val Accuracy model) 를 상황에 맞게 수정해야 함."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_dir = \"copa_data_results/results/TrainAll_Roberta_8e-06/1/best\"\n",
    "model_module = eval(args.model_type)\n",
    "model = model_module.from_pretrained(target_dir, args=args)\n",
    "model.parameters\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\"\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "dataset = load_data(valid_data)\n",
    "test_label = dataset[\"label\"].values\n",
    "\n",
    "tokenized_test = tokenized_dataset(dataset, tokenizer, check_arch(args.model_type))\n",
    "test_dataset = CustomDataset(tokenized_test, test_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def inference(model, tokenized_sent, device):\n",
    "    dataloader = DataLoader(tokenized_sent, batch_size=8, shuffle=False)\n",
    "    model.eval()\n",
    "    results = []\n",
    "    preds = []\n",
    "\n",
    "    for i, items in enumerate(tqdm(dataloader)):\n",
    "        item = {key: val.to(device) for key, val in items.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**item)\n",
    "        logits = outputs[0]\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(logits)\n",
    "        logits = logits.detach().cpu().numpy()  # (Batch_size, 5)  5개의 클래스 확률형태\n",
    "        pred = logits[:, 1]\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "        results += result.tolist()\n",
    "        preds += pred.tolist()\n",
    "\n",
    "    return np.array(results).flatten(), np.array(preds).flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "pred_answer, preds = inference(model, tokenized_sent=test_dataset, device=device)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1964b96cd7a4551862dd950f42b57eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# make json\n",
    "submission_json = {\"copa\": []}\n",
    "for i, pred in enumerate(pred_answer.tolist()):\n",
    "    submission_json[\"copa\"].append({\"idx\": i, \"label\": int(pred + 1)})\n",
    "with open(\"submission.json\", \"w\") as fp:\n",
    "    json.dump(submission_json, fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dataset[\"model_answer\"] = pred_answer\n",
    "dataset[\"model_pred\"] = preds\n",
    "dataset.to_csv(\"copa_result.csv\", index=False, encoding=\"utf-8-sig\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 여기까지 COPA (인과추론)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CoLA (문법성 판단)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "import re\n",
    "\n",
    "from Korpora import Korpora"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fetch additional data\n",
    "추가 학습을 위해 KorSTS와 KorNLI 데이터셋에서 텍스트만 가져온다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 추가적으로 사용할 추가 데이터 가져오기\n",
    "def create_additional_text(name):\n",
    "    path = Path('.')\n",
    "    root_dir = path / 'dataset'\n",
    "    Korpora.fetch(name, root_dir = root_dir)\n",
    "    corpus = Korpora.load(name)\n",
    "    additional_text = corpus.get_all_texts()\n",
    "\n",
    "    temp = []\n",
    "    for i, text in enumerate(tqdm(additional_text)):\n",
    "        temp.append(text+'\\n')\n",
    "\n",
    "    additional_text = set(temp)\n",
    "    del temp\n",
    "    additional_text = list(additional_text)\n",
    "    \n",
    "    new_file = root_dir / 'additional.txt'\n",
    "    with open(new_file, 'a+', encoding='utf-8') as writer:\n",
    "        writer.writelines(additional_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#create_additional_text(\"korsts\")\n",
    "#create_additional_text(\"kornli\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "1. 추가 데이터셋에서 일부러 조사가 틀린 텍스트를 만들어서 문법이 틀린 데이터도 증강"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from pyjosa import josa, jonsung"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class SabotageSentence(object):\n",
    "    def __init__(self, sentence: str):\n",
    "        self.sentence = sentence\n",
    "        self.josa_dict = {\n",
    "            'for_jongsung':['을','은','이','과'], \n",
    "            'no_jongsung':['를','는','가','와','나','로','야','랑','며']\n",
    "        }\n",
    "\n",
    "\n",
    "    @property\n",
    "    def get_all_josa(self):\n",
    "        return self.josa_dict\n",
    "\n",
    "\n",
    "    def jongsung_wrong_josa(self) -> str:\n",
    "        new_sent = ''\n",
    "        for _, word in enumerate(self.sentence.split()):\n",
    "            tmp_word = word[:-1]\n",
    "            if word[-1] in self.josa_dict['for_jongsung']:\n",
    "                tmp_word+=random.choice(self.josa_dict['no_jongsung'])\n",
    "                new_sent+=tmp_word\n",
    "                new_sent+=' '\n",
    "            elif word[-1] in self.josa_dict['no_jongsung']:\n",
    "                tmp_word+=random.choice(self.josa_dict['for_jongsung'])\n",
    "                new_sent+=tmp_word\n",
    "                new_sent+=' '\n",
    "            else:\n",
    "                new_sent+=word\n",
    "                new_sent+=' '\n",
    "\n",
    "        return new_sent\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 기존 데이터셋을 pandas DataFrame으로 변환"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def load_data(filename):\n",
    "    data_dir = Path(\"./dataset/cola/\") / filename\n",
    "    dataset = pd.read_csv(\n",
    "        data_dir, \n",
    "        sep=\"\\t\", \n",
    "        header=0, \n",
    "        encoding='utf-8', \n",
    "        names=['source', 'acceptability_label', 'source_annotation', 'sentence']\n",
    "    )\n",
    "    dataset['label'] = dataset['acceptability_label'].astype(int)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def augment_data_orig(new_data: List[str]):\n",
    "    tmp_data_holder = {'source':[], 'label':[], 'source_annotation':[], 'sentence':[]}\n",
    "    for i, row in enumerate(new_data):\n",
    "        if (re.match('[a-zA-Z]', row) is not None) or (len(row) >= 70) or (len(row) == 0) or (row[-2:]!='.\\n'):\n",
    "            continue\n",
    "        else:\n",
    "            tmp_data_holder['source'].append('T'+str(10001+i))\n",
    "            tmp_data_holder['label'].append(1)\n",
    "            tmp_data_holder['source_annotation'].append('*')\n",
    "            assert type(row) == str\n",
    "            tmp_data_holder['sentence'].append(row.replace('\\n',''))\n",
    "\n",
    "    dataset = pd.DataFrame(tmp_data_holder)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def augment_data(data):\n",
    "    tmp_data_holder = {'source':[], 'label':[], 'source_annotation':[], 'sentence':[]}\n",
    "    for _, row in data.iterrows():\n",
    "        tmp_data_holder['source'].append(row['source'])\n",
    "        tmp_data_holder['label'].append(0)\n",
    "        tmp_data_holder['source_annotation'].append(np.NaN)\n",
    "        \n",
    "        text = SabotageSentence(row['sentence']).jongsung_wrong_josa()\n",
    "        tmp_data_holder['sentence'].append(text)\n",
    "\n",
    "    dataset = pd.DataFrame(tmp_data_holder)\n",
    "    return dataset\n",
    "\n",
    "    \n",
    "def read_txt(path='./dataset/additional.txt') -> List[str]:\n",
    "    with open(path, 'r+', encoding='utf-8') as reader:\n",
    "        new_data = reader.readlines()\n",
    "    \n",
    "    tmp_list = []\n",
    "    for text in new_data:\n",
    "        text.rstrip('\\n')\n",
    "        text.replace('\\n','')\n",
    "        tmp_list.append(text)\n",
    "    new_data = tmp_list\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def multiprocess_aug(orig_dataset, func_name):\n",
    "    num_process = multiprocessing.cpu_count()\n",
    "    \n",
    "    chunk_size = int(orig_dataset.shape[0] / num_process)\n",
    "    chunks = [orig_dataset.iloc[orig_dataset.index[i:i+chunk_size]] for i in range(0, orig_dataset.shape[0], chunk_size)]\n",
    "    assert len(chunks) != 0\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_process) as pool:\n",
    "        results = pool.map(func_name, chunks)\n",
    "        \n",
    "        new_dataset = pd.concat(results)\n",
    "        dataset = pd.concat([orig_dataset, new_dataset])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenize_datasets(dataset, tokenizer, arch=\"encoder\"):\n",
    "    sentence = dataset['sentence'].tolist()\n",
    "    tokenize_sent = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 200,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = True\n",
    "    )\n",
    "\n",
    "    return tokenize_sent"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Dataset Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class ColaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels= None, test=False):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, ElectraPreTrainedModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class Electra(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(Electra, self).__init__(config)\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.electra(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        output = outputs[0][:, 0, :]\n",
    "        output = self.linear(self.dropout(output))\n",
    "        output = torch.tanh(output)\n",
    "        logits = self.classifier(output)\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        \"\"\"\n",
    "        :param inputs: predictions\n",
    "        :param target: target labels\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        loss = self.CE(inputs, target)\n",
    "        return loss\n",
    "\n",
    "_criterion_entrypoints = {\n",
    "    'cross_entropy': CrossEntropy,\n",
    "}\n",
    "\n",
    "def criterion_entrypoint(criterion_name):\n",
    "    return _criterion_entrypoints[criterion_name]\n",
    "\n",
    "def is_criterion(criterion_name):\n",
    "    return criterion_name in _criterion_entrypoints\n",
    "\n",
    "def create_criterion(criterion_name, **kwargs):\n",
    "    if is_criterion(criterion_name):\n",
    "        create_fn = criterion_entrypoint(criterion_name)\n",
    "        criterion = create_fn(**kwargs)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n",
    "    return criterion"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility function(s)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def check_arch(model_type):\n",
    "  archs = {\n",
    "    \"encoder\" : [\"Bert\", \"Electra\", \"XLMRoberta\", \"Electra_BoolQ\", \"Roberta\"],\n",
    "    \"encoder-decoder\" : [\"T5\", \"Bart\", \"Bart_BoolQ\"]\n",
    "  }\n",
    "  for arch in archs:\n",
    "    if model_type in archs[arch]:\n",
    "      return arch\n",
    "  raise ValueError(f\"Model [{model_type}] no defined archtecture\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import os\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set seed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "def output_dir(output_path, exist_ok = False):\n",
    "    path = Path(output_path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def train(args):\n",
    "    model_dir = args.model_dir\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # tokenizer\n",
    "    MODEL_NAME = args.pretrained_model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # load dataset\n",
    "    datasets_ = load_data(\"./NIKL_CoLA_train.tsv\")\n",
    "\n",
    "    # 아래 코드는 데이터를 증강하는 코드지만 MCC에 도움이 되지 않는 관계로 주석처리함\n",
    "    # new_data = read_txt()\n",
    "    # new_data = augment_data_orig(new_data)\n",
    "    # new_data_corrupt = multiprocess_aug(new_data, augment_data)\n",
    "    # datasets_ = pd.concat([datasets_, new_data, new_data_corrupt], ignore_index=True)\n",
    "\n",
    "    # make validation sets from training set\n",
    "    labels_ = datasets_[\"label\"]\n",
    "    length = len(labels_)\n",
    "    kf = args.kfold\n",
    "    class_indexs = defaultdict(list)\n",
    "    for i, label_ in enumerate(labels_):\n",
    "        class_indexs[np.argmax(label_)].append(i)\n",
    "    val_indices = set()\n",
    "    for index in class_indexs: \n",
    "        val_indices = (val_indices | set(class_indexs[index][int(\n",
    "            len(class_indexs[index])*(kf-1)/9): int(len(class_indexs[index])*kf/9)]))\n",
    "    train_indices = set(range(length)) - val_indices\n",
    "\n",
    "    train_dataset = datasets_.loc[np.array(list(train_indices))]\n",
    "    val_dataset = datasets_.loc[np.array(list(val_indices))]\n",
    "\n",
    "    train_label = train_dataset['label'].values\n",
    "    val_label = val_dataset['label'].values\n",
    "\n",
    "    tokenized_train = tokenize_datasets(\n",
    "        train_dataset, tokenizer, check_arch(args.model_type))\n",
    "    tokenized_val = tokenize_datasets(\n",
    "        val_dataset, tokenizer, check_arch(args.model_type))\n",
    "\n",
    "    train_dataset = ColaDataset(tokenized_train, train_label)\n",
    "    val_dataset = ColaDataset(tokenized_val, val_label)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.valid_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    config_module = getattr(import_module(\n",
    "        \"transformers\"), args.model_type + \"Config\")\n",
    "\n",
    "    model_config = config_module.from_pretrained(MODEL_NAME)\n",
    "    model_config.num_labels = 2\n",
    "\n",
    "    model = Electra.from_pretrained(MODEL_NAME, config=model_config)\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "\n",
    "    save_dir = output_dir(os.path.join(model_dir, args.name, str(args.kfold)))\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if ('cls_fc_layer' not in name) and ('label_classifier' not in name):  # classifier layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "    criterion = create_criterion(args.criterion)  # default: cross_entropy\n",
    "    opt_module = getattr(import_module(\"transformers\"), args.optimizer)\n",
    "    optimizer = opt_module(\n",
    "        model.parameters(),\n",
    "        lr=args.lr,\n",
    "        weight_decay=args.weight_decay,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=args.warmup_steps,\n",
    "        num_training_steps=len(train_loader) * args.epochs,\n",
    "        last_epoch=- 1\n",
    "    )\n",
    "\n",
    "    # logging\n",
    "    best_val_mcc = -1\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(args.epochs):\n",
    "        pbar = tqdm(train_loader, dynamic_ncols=True)\n",
    "        if epoch == args.freeze_epoch:\n",
    "            for name, param in model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, items in enumerate(pbar):\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(**item)\n",
    "            loss = criterion(outs[0], item['labels'])\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == item['labels']).sum().item()\n",
    "            if (idx + 1) % args.log_interval == 0:\n",
    "                train_loss = loss_value / args.log_interval\n",
    "                train_acc = matches / args.batch_size / args.log_interval\n",
    "                current_lr = get_lr(optimizer)\n",
    "                pbar.set_description(\n",
    "                    f\"Epoch: [{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || loss: {train_loss:4.4} || acc: {train_acc:4.2%} || lr {current_lr:4.4}\")\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, dynamic_ncols=True)\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        acc_okay = 0\n",
    "        count_all = 0\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        eps = 1e-9\n",
    "        for idx, items in enumerate(pbar):\n",
    "            sleep(0.01)\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            outs = model(**item)\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "            loss = criterion(outs[0], item['labels']).item()\n",
    "\n",
    "            acc_item = (item['labels'] == preds).sum().item()\n",
    "\n",
    "            TRUE = (item['labels'] == preds)\n",
    "            FALSE = (item['labels'] != preds)\n",
    "\n",
    "            TP += (TRUE * preds).sum().item()\n",
    "            TN += (TRUE * (preds == 0)).sum().item()\n",
    "            FP += (FALSE * preds).sum().item()\n",
    "            FN += (FALSE * (preds == 0)).sum().item()\n",
    "\n",
    "            val_loss_items.append(loss)\n",
    "            val_acc_items.append(acc_item)\n",
    "            acc_okay += acc_item\n",
    "            count_all += len(preds)\n",
    "\n",
    "            # Calculate MCC\n",
    "            MCC = ((TP*TN) - (FP*FN)) / \\\n",
    "                (((TP+FP+eps)*(TP+FN+eps)*(TN+FP+eps)*(TN+FN+eps))**0.5)\n",
    "\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: [{epoch}/{args.epochs}]({idx + 1}/{len(val_loader)}) || val_loss: {loss:4.4} || acc: {acc_okay/count_all:4.2%} || MCC: {MCC:4.2%}\")\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loss_items)\n",
    "        val_acc = acc_okay / count_all\n",
    "\n",
    "        if MCC > best_val_mcc:\n",
    "            print(\n",
    "                f\"New best model for val mcc : {MCC:4.2%}! saving the best model..\")\n",
    "            model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "            model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "            torch.save(args, os.path.join(\n",
    "                f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "            best_val_mcc = MCC\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.4}|| \"\n",
    "            f\"best mcc : {best_val_mcc:4.2%}, best loss: {best_val_loss:4.4}|| \"\n",
    "            f\"MCC : {MCC:4.2%}|| \"\n",
    "            f\"TP:{TP} / TN:{TN} / FP:{FP} / FN:{FN}\"\n",
    "        )\n",
    "\n",
    "    time.sleep(5)\n",
    "    torch.cuda.empty_cache()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training arguments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1,2,3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "args = argparse.Namespace(\n",
    "    seed = 42,\n",
    "    epochs = 30,\n",
    "    freeze_epoch=0,\n",
    "    optimizer = 'AdamW',\n",
    "    weight_decay = 0.01,\n",
    "    warmup_steps = 500,\n",
    "    log_interval = 20,\n",
    "    kfold = 9,\n",
    "\n",
    "    criterion = 'cross_entropy',\n",
    "    dropout_rate = 0.1,\n",
    "    model_type = \"Electra\",\n",
    "    pretrained_model = \"tunib/electra-ko-base\",\n",
    "    lr = 4e-6,\n",
    "    batch_size = 32,\n",
    "    valid_batch_size = 128,\n",
    "\n",
    "    val_ratio=0.2,\n",
    "    name = 'exp',\n",
    "    model_dir = os.environ.get('SM_MODEL_DIR', './results'),\n",
    "    custompretrain = \"\"\n",
    ")\n",
    "\n",
    "args.name = f'{args.model_type}_{args.lr}_{args.kfold}'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print('='*40)\n",
    "print(f\"k-fold num : {args.kfold}\")\n",
    "print('='*40)\n",
    "\n",
    "train(args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\n",
      "k-fold num : 9\n",
      "========================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing Electra: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing Electra from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Electra from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Electra were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.bias', 'linear.bias', 'classifier.weight', 'linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: [0/30](440/441) || loss: 0.5605 || acc: 74.53% || lr 3.52e-06: 100%|██████████| 441/441 [01:57<00:00,  3.74it/s]\n",
      "Epoch: [1/30](440/441) || loss: 0.4917 || acc: 78.44% || lr 3.88e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [2/30](440/441) || loss: 0.4534 || acc: 80.31% || lr 3.742e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [3/30](440/441) || loss: 0.4011 || acc: 82.66% || lr 3.603e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [4/30](440/441) || loss: 0.3474 || acc: 86.41% || lr 3.465e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [5/30](440/441) || loss: 0.3023 || acc: 87.19% || lr 3.326e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [6/30](440/441) || loss: 0.3168 || acc: 88.12% || lr 3.187e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [7/30](440/441) || loss: 0.2279 || acc: 91.41% || lr 3.049e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [8/30](440/441) || loss: 0.258 || acc: 89.53% || lr 2.91e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [9/30](440/441) || loss: 0.1729 || acc: 92.50% || lr 2.772e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [10/30](440/441) || loss: 0.1754 || acc: 92.03% || lr 2.633e-06: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [11/30](440/441) || loss: 0.16 || acc: 93.91% || lr 2.495e-06: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [12/30](440/441) || loss: 0.1762 || acc: 94.84% || lr 2.356e-06: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [13/30](440/441) || loss: 0.1419 || acc: 95.00% || lr 2.217e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [14/30](440/441) || loss: 0.1195 || acc: 95.62% || lr 2.079e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [15/30](440/441) || loss: 0.1356 || acc: 94.84% || lr 1.94e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [16/30](440/441) || loss: 0.1306 || acc: 95.94% || lr 1.802e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [17/30](440/441) || loss: 0.08656 || acc: 96.72% || lr 1.663e-06: 100%|██████████| 441/441 [01:51<00:00,  3.95it/s]\n",
      "Epoch: [18/30](440/441) || loss: 0.08457 || acc: 96.41% || lr 1.525e-06: 100%|██████████| 441/441 [01:51<00:00,  3.97it/s]\n",
      "Epoch: [19/30](440/441) || loss: 0.09354 || acc: 96.56% || lr 1.386e-06: 100%|██████████| 441/441 [01:51<00:00,  3.96it/s]\n",
      "Epoch: [20/30](440/441) || loss: 0.07041 || acc: 97.66% || lr 1.247e-06: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [21/30](440/441) || loss: 0.08624 || acc: 96.41% || lr 1.109e-06: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [22/30](440/441) || loss: 0.06864 || acc: 97.50% || lr 9.703e-07: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [23/30](440/441) || loss: 0.05669 || acc: 98.12% || lr 8.317e-07: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [24/30](440/441) || loss: 0.06478 || acc: 97.97% || lr 6.932e-07: 100%|██████████| 441/441 [01:52<00:00,  3.94it/s]\n",
      "Epoch: [25/30](440/441) || loss: 0.09108 || acc: 97.03% || lr 5.546e-07: 100%|██████████| 441/441 [01:52<00:00,  3.93it/s]\n",
      "Epoch: [26/30](440/441) || loss: 0.04714 || acc: 98.59% || lr 4.16e-07: 100%|██████████| 441/441 [01:52<00:00,  3.94it/s]\n",
      "Epoch: [27/30](440/441) || loss: 0.04634 || acc: 98.12% || lr 2.775e-07: 100%|██████████| 441/441 [01:52<00:00,  3.94it/s]\n",
      "Epoch: [28/30](440/441) || loss: 0.06097 || acc: 98.28% || lr 1.389e-07: 100%|██████████| 441/441 [01:52<00:00,  3.93it/s]\n",
      "Epoch: [29/30](440/441) || loss: 0.05658 || acc: 97.97% || lr 3.142e-10: 100%|██████████| 441/441 [01:51<00:00,  3.94it/s]\n",
      "Epoch: [29/30](1/14) || val_loss: 0.8176 || acc: 83.59% || MCC: 67.18%:   7%|▋         | 1/14 [00:00<00:01,  6.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch: [29/30](14/14) || val_loss: 0.7995 || acc: 80.67% || MCC: 61.83%: 100%|██████████| 14/14 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New best model for val mcc : 61.83%! saving the best model..\n",
      "[Val] acc : 80.67%, loss: 0.8838|| best mcc : 61.83%, best loss: 0.8838|| MCC : 61.83%|| TP:779 / TN:644 / FP:229 / FN:112\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def evaluate(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "    file = 'NIKL_CoLA_dev.tsv'\n",
    "    dataset = load_data(file)\n",
    "    tokenized_test = tokenize_datasets(dataset, tokenizer)\n",
    "    test_label = dataset['label'].values\n",
    "    test_dataset = ColaDataset(tokenized_test, test_label)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = Electra.from_pretrained(args.model_dir) \n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(test_loader)\n",
    "    print(\"Calculating validation results...\")\n",
    "    test_acc_items = []\n",
    "    acc_okay = 0\n",
    "    count_all = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    eps = 1e-9\n",
    "\n",
    "    for idx, items in enumerate(pbar):\n",
    "        sleep(0.01)\n",
    "\n",
    "        item = {key: val.to(device) for key, val in items.items()}\n",
    "        with torch.no_grad():\n",
    "            outs = model(**item)\n",
    "\n",
    "        preds = torch.argmax(outs[0], dim=-1)\n",
    "        labels = item['labels']\n",
    "\n",
    "        acc_item = (labels == preds).sum().item()\n",
    "\n",
    "        TRUE = (labels == preds)\n",
    "        FALSE = (labels != preds)\n",
    "\n",
    "        TP += (TRUE * preds).sum().item()\n",
    "        TN += (TRUE * (preds==0)).sum().item()\n",
    "        FP += (FALSE * preds).sum().item()\n",
    "        FN += (FALSE * (preds==0)).sum().item()\n",
    "\n",
    "        MCC = ((TP*TN) - (FP*FN)) / (((TP+FP+eps)*(TP+FN+eps)*(TN+FP+eps)*(TN+FN+eps))**0.5)\n",
    "\n",
    "        test_acc_items.append(acc_item)\n",
    "        acc_okay += acc_item\n",
    "        count_all += len(preds)\n",
    "\n",
    "        pbar.set_description(f\"({idx + 1}/{len(test_loader)}) || acc: {acc_okay/count_all:4.2%} || MCC: {MCC:4.2%}\")\n",
    "\n",
    "    test_acc = acc_okay / count_all\n",
    "\n",
    "    print(\n",
    "        f\"[Test] acc : {test_acc:4.2%}|| \"\n",
    "        f\"MCC : {MCC:4.2%}|| \"\n",
    "        f\"TP:{TP} / TN:{TN} / FP:{FP} / FN:{FN}\\n\"\n",
    "        f\"======================================\\n\"\n",
    "        f\"Test MCC: {MCC:4.2%}\"\n",
    "    )\n",
    "    time.sleep(5)\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation arguments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#eval args\n",
    "args = argparse.Namespace(\n",
    "    model_type = \"Electra\",\n",
    "    pretrained_model = \"tunib/electra-ko-base\",\n",
    "\n",
    "    model_dir = './results/Electra_4e-06_9/97/best',\n",
    "    criterion = 'cross_entropy',\n",
    "    num_labels=2,\n",
    "\n",
    "    test_batch_size=8\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "evaluate(args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "(9/254) || acc: 76.39% || MCC: 53.29%:   2%|▏         | 5/254 [00:00<00:05, 49.35it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating validation results...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "(254/254) || acc: 75.84% || MCC: 51.64%: 100%|██████████| 254/254 [00:05<00:00, 48.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Test] acc : 75.84%|| MCC : 51.64%|| TP:892 / TN:649 / FP:312 / FN:179\n",
      "======================================\n",
      "Test MCC: 51.64%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 동형이의어 task 시작"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- pretrained model : klue/Roberta-large\n",
    "- R-BERT : pretrained model의 [CLS], entity1, entity2 부분의 embedding 값을 concat하여 최종 분류"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, RobertaPreTrainedModel\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x) \n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class R_RoBERTa_WiC(RobertaPreTrainedModel):\n",
    "    def __init__(self,  model_name, config, dropout_rate):\n",
    "        super(R_RoBERTa_WiC, self).__init__(config)\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=config)\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer1 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer2 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels, e1_mask, e2_mask):\n",
    "        outputs = self.model(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        sequence_output = outputs[0] #batch, max_len, hidden_size  \n",
    "\n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        sentence_representation = self.cls_fc_layer(outputs.pooler_output)\n",
    "\n",
    "        e1_h = self.entity_fc_layer1(e1_h)\n",
    "        e2_h = self.entity_fc_layer2(e2_h)\n",
    "        # Concat -> fc_layer\n",
    "        concat_h = torch.cat([sentence_representation, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        # Softmax\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Lodaer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class WICDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_data(dataset_dir, mode = 'train'):\n",
    "    dataset = pd.read_csv(dataset_dir, delimiter='\\t')\n",
    "    li = []\n",
    "    for s1, s2 in zip(list(dataset['SENTENCE1']), list(dataset['SENTENCE2'])):\n",
    "        li.append(s1+' '+s2)\n",
    "    dataset[\"ANSWER\"] = dataset[\"ANSWER\"].astype(int)\n",
    "    if mode == 'test':\n",
    "        dataset[\"ANSWER\"] = [0] * len(dataset)\n",
    "    return dataset\n",
    "\n",
    "def convert_sentence_to_features(train_dataset, tokenizer, max_len):\n",
    "    \n",
    "    max_seq_len=max_len\n",
    "    pad_token=tokenizer.pad_token_id\n",
    "    add_sep_token=False\n",
    "    mask_padding_with_zero=True\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_e1_mask=[]\n",
    "    all_e2_mask=[]\n",
    "    all_label=[]\n",
    "    m_len=0\n",
    "    for idx in tqdm(range(len(train_dataset))):\n",
    "        sentence = '<s>' + train_dataset['SENTENCE1'][idx][:train_dataset['start_s1'][idx]] \\\n",
    "            + ' <e1> ' + train_dataset['SENTENCE1'][idx][train_dataset['start_s1'][idx]:train_dataset['end_s1'][idx]] \\\n",
    "            + ' </e1> ' + train_dataset['SENTENCE1'][idx][train_dataset['end_s1'][idx]:] + '</s>' \\\n",
    "            + ' ' \\\n",
    "            + '<s>' + train_dataset['SENTENCE2'][idx][:train_dataset['start_s2'][idx]] \\\n",
    "            + ' <e2> ' + train_dataset['SENTENCE2'][idx][train_dataset['start_s2'][idx]:train_dataset['end_s2'][idx]] \\\n",
    "            + ' </e2> ' + train_dataset['SENTENCE2'][idx][train_dataset['end_s2'][idx]:] + '</s>'\n",
    "        \n",
    "        token = tokenizer.tokenize(sentence)\n",
    "        m_len = max(m_len, len(token))\n",
    "        e11_p = token.index(\"<e1>\")  # the start position of entity1\n",
    "        e12_p = token.index(\"</e1>\")  # the end position of entity1\n",
    "        e21_p = token.index(\"<e2>\")  # the start position of entity2\n",
    "        e22_p = token.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        token[e11_p] = \"$\"\n",
    "        token[e12_p] = \"$\"\n",
    "        token[e21_p] = \"#\"\n",
    "        token[e22_p] = \"#\"\n",
    "\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "        special_tokens_count = 1\n",
    "\n",
    "        if len(token) < max_seq_len - special_tokens_count:\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            padding_length = max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "            assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "                len(attention_mask), max_seq_len\n",
    "            )\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "            all_label.append(train_dataset['ANSWER'][idx])\n",
    "\n",
    "    all_features = {\n",
    "        'input_ids' : torch.tensor(all_input_ids),\n",
    "        'attention_mask' : torch.tensor(all_attention_mask),\n",
    "        'e1_mask' : torch.tensor(all_e1_mask),\n",
    "        'e2_mask' : torch.tensor(all_e2_mask)\n",
    "    }  \n",
    "    return WICDataset(all_features, all_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = \"./\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModel, AutoConfig\n",
    "import argparse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# seed 고정 \n",
    "def seed_everything(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def acc_and_f1(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "    }\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, model_dir = None,train_dataset=None, dev_dataset=None, test_dataset=None,tokenizer=None):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_dir = model_dir \n",
    "        self.best_score = 0\n",
    "        self.hold_epoch = 0\n",
    "\n",
    "        self.eval_batch_size = args.eval_batch_size\n",
    "        self.train_batch_size = args.train_batch_size\n",
    "        self.max_steps = args.max_steps\n",
    "        self.weight_decay = args.weight_decay\n",
    "        self.learning_rate = args.lr\n",
    "        self.adam_epsilon= args.adam_epsilon\n",
    "        self.warmup_steps = args.warmup_steps\n",
    "        self.num_train_epochs = args.num_train_epochs\n",
    "        self.logging_steps = args.logging_steps\n",
    "        self.max_grad_norm = args.max_grad_norm\n",
    "        self.dropout_rate = args.dropout_rate\n",
    "        self.gradient_accumulation_steps = args.gradient_accumulation_steps\n",
    "        \n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            \"klue/roberta-large\",\n",
    "            num_labels = 2\n",
    "        )\n",
    "        self.model = R_RoBERTa_WiC(\n",
    "           \"klue/roberta-large\", \n",
    "            config=self.config, \n",
    "            dropout_rate = self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        init_logger()\n",
    "        seed_everything(args.seed)\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            batch_size=self.train_batch_size,\n",
    "        )\n",
    "\n",
    "        if self.max_steps > 0:\n",
    "            t_total = self.max_steps\n",
    "            self.num_train_epochs = (\n",
    "                self.max_steps // (len(train_dataloader) // self.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.gradient_accumulation_steps * self.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.learning_rate,\n",
    "            eps=self.adam_epsilon,\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "        \n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.logging_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = tqdm(range(int(self.num_train_epochs)), desc=\"Epoch\")\n",
    "\n",
    "        for epo_step in train_iterator:\n",
    "            self.global_epo = epo_step\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(batch[t].to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"labels\": batch[4],\n",
    "                    \"e1_mask\": batch[2],\n",
    "                    \"e2_mask\": batch[3]\n",
    "                }\n",
    "                \n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                if self.logging_steps > 0 and global_step % self.logging_steps == 0:\n",
    "                    logger.info(\"  global steps = %d\", global_step)\n",
    "\n",
    "                if 0 < self.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "            \n",
    "            self.evaluate(\"dev\")\n",
    "            if self.hold_epoch > 4:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "                \n",
    "            if 0 < self.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "          \n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "    \n",
    "   \n",
    "    def evaluate(self, mode):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        elif mode == \"train\":\n",
    "            dataset = self.train_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info('---------------------------------------------------')\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(batch[t].to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"labels\": batch[4],\n",
    "                    \"e1_mask\": batch[2],\n",
    "                    \"e2_mask\": batch[3],\n",
    "                }\n",
    "                #with torch.cuda.amp.autocast():\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        results = {\"loss\": eval_loss}\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        result = compute_metrics(preds, out_label_ids)\n",
    "        \n",
    "        if mode == \"dev\":\n",
    "            if result['acc']>self.best_score:\n",
    "                self.save_model()\n",
    "                self.best_score = result['acc']\n",
    "                print('save new best model acc : ',str(self.best_score))\n",
    "                self.hold_epoch = 0\n",
    "            else:\n",
    "                self.hold_epoch += 1\n",
    "        \n",
    "        \n",
    "        results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "        logger.info(\"---------------------------------------------------\")\n",
    "        return results\n",
    "        \n",
    "\n",
    "    def save_model(self,new_dir=None):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        if new_dir == None:\n",
    "            pass\n",
    "        else:\n",
    "            if not os.path.exists(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "            self.model_dir = new_dir\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(self.model_dir)\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.model_dir)\n",
    "\n",
    "  \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- train 과정은 서버에서 진행하였고, ipynb에서는 중간에 중단하였습니다.\n",
    "- data augmentation은 두 문장의 순서를 바꾸어 train dataset을 2배로 증강하였고, 이는 외부에서 실행하여 파일로 저장했습니다.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    " \n",
    "        \"num_train_epochs\": 10,\n",
    "        \"train_batch_size\": 4,\n",
    "        \"eval_batch_size\": 4,\n",
    "        \"max_steps\": -1,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"lr\" : 1e-5,\n",
    "        \"adam_epsilon\" : 1e-8,\n",
    "        \"weight_decay\" : 0.01,\n",
    "        \"warmup_steps\" : 64,\n",
    "        \"seed\" : 42,\n",
    "        \"logging_steps\" : 500,\n",
    "        \"max_grad_norm\" : 1.0,\n",
    "        \"gradient_accumulation_steps\" : 1,\n",
    "        \"train_data_dir\" : f\"{BASE_DIR}dataset/wic/NIKL_SKT_WiC_Train.tsv\",\n",
    "        \"dev_data_dir\" : f\"{BASE_DIR}dataset/wic/NIKL_SKT_WiC_Dev.tsv\" \n",
    "})\n",
    "\n",
    "train_dataset = load_data(args.train_data_dir)\n",
    "dev_dataset = load_data(args.dev_data_dir)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\", return_token_type_ids=False)\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "concat_dataset = train_dataset\n",
    "\n",
    "def make_fold(x):\n",
    "  if x <= concat_dataset.shape[0]*0.2:\n",
    "      return 0\n",
    "  elif x > concat_dataset.shape[0]*0.2 and x <= concat_dataset.shape[0]*0.4:\n",
    "      return 1\n",
    "  elif x > concat_dataset.shape[0]*0.4 and x <= concat_dataset.shape[0]*0.6 :\n",
    "      return 2\n",
    "  elif x > concat_dataset.shape[0]*0.6 and x <= concat_dataset.shape[0]*0.8 :\n",
    "      return 3\n",
    "  else:\n",
    "      return 4\n",
    "\n",
    "concat_dataset['fold']= concat_dataset['ID'].apply(make_fold)\n",
    "concat_dataset = concat_dataset.drop(['ID', 'Target'],axis=1)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "for fold in tqdm(range(5)): \n",
    "  trn_idx = concat_dataset[concat_dataset['fold'] != fold].index\n",
    "  val_idx = concat_dataset[concat_dataset['fold'] == fold].index\n",
    "\n",
    "  half_val_len = len(val_idx)//2\n",
    "  add_trn_idx = val_idx[:half_val_len]\n",
    "\n",
    "  trn_idx.append(add_trn_idx)\n",
    "  val_idx = val_idx[half_val_len:]\n",
    "\n",
    "  train_folds = concat_dataset.loc[trn_idx].reset_index(drop=True).drop(['fold'],axis=1)\n",
    "  valid_folds = concat_dataset.loc[val_idx].reset_index(drop=True).drop(['fold'],axis=1)\n",
    "\n",
    "  train_Dataset = convert_sentence_to_features(train_dataset, tokenizer, max_len = 280)\n",
    "  valid_Dataset = convert_sentence_to_features(dev_dataset, tokenizer, max_len= 280)\n",
    "\n",
    "  trainer = Trainer(args,\n",
    "                  train_dataset=train_Dataset,\n",
    "                  dev_dataset=valid_Dataset,\n",
    "                  tokenizer =tokenizer,\n",
    "                  model_dir = f'{BASE_DIR}roberta_model_fold_{str(fold)}')\n",
    "\n",
    "  trainer.train()\n",
    "  trainer.save_model(new_dir=f'{BASE_DIR}roberta_model_final_fold_{str(fold)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 15496/15496 [00:15<00:00, 984.14it/s]\n",
      "100%|██████████| 1166/1166 [00:01<00:00, 752.67it/s]\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:08:42 - INFO - __main__ -   ***** Running training *****\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Num examples = 15496\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Num Epochs = 10\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Total train batch size = 4\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Total optimization steps = 38740\n",
      "12/06/2021 10:08:42 - INFO - __main__ -     Logging steps = 500\n",
      "\n",
      "\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Iteration:   1%|          | 38/3874 [00:17<28:45,  2.22it/s]\n",
      "Epoch:   0%|          | 0/10 [00:17<?, ?it/s]\n",
      "  0%|          | 0/5 [00:50<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be6ac42cfec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                   model_dir = f'{BASE_DIR}/roberta_model_fold_{str(fold)}')\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{BASE_DIR}/roberta_model_final_fold_{str(fold)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8356b4579662>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import chain\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer,AutoModel, RobertaPreTrainedModel, AutoConfig, RobertaModel\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "class Roberta_WiC(RobertaPreTrainedModel):\n",
    "    def __init__(self,  model_name, config, dropout_rate):\n",
    "        super(Roberta_WiC, self).__init__(config)\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=config)  # Load pretrained XLMRoberta\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer1 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer2 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels, e1_mask, e2_mask):\n",
    "        outputs = self.model(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  \n",
    "        sequence_output = outputs[0] \n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "\n",
    "        sentence_representation = self.cls_fc_layer(outputs.pooler_output)\n",
    "        \n",
    "        e1_h = self.entity_fc_layer1(e1_h)\n",
    "        e2_h = self.entity_fc_layer2(e2_h)\n",
    "\n",
    "        concat_h = torch.cat([sentence_representation, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        # Softmax\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    \n",
    "\n",
    "def test_pred(test_dataset, eval_batch_size, model):\n",
    "    test_dataset = test_dataset\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=eval_batch_size)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    init_logger()\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation on %s dataset *****\", \"test\")\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "        batch = tuple(batch[t].to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"labels\": None,\n",
    "                \"e1_mask\": batch[2],\n",
    "                \"e2_mask\": batch[3],\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            pred = outputs[0]\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        if preds is None:\n",
    "            preds = pred.detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, pred.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    preds_label = np.argmax(preds, axis=1)\n",
    "    df = pd.DataFrame(preds, columns=['pred_0','pred_1'])\n",
    "    df['label'] = preds_label\n",
    "    preds = preds.astype(int)\n",
    "    return df \n",
    "\n",
    "\n",
    "def load_test_data(dataset_dir):\n",
    "    dataset = pd.read_csv(dataset_dir, delimiter='\\t')\n",
    "    li = []\n",
    "    for s1, s2 in zip(list(dataset['SENTENCE1']), list(dataset['SENTENCE2'])):\n",
    "        li.append(s1+' '+s2)\n",
    "    dataset[\"ANSWER\"] = dataset[\"ANSWER\"].astype(int)\n",
    "    return dataset\n",
    "\n",
    "def convert_sentence_to_features(train_dataset, tokenizer, max_len, mode='train'):\n",
    "    max_seq_len=max_len\n",
    "    pad_token=tokenizer.pad_token_id\n",
    "    add_sep_token=False\n",
    "    mask_padding_with_zero=True\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_e1_mask=[]\n",
    "    all_e2_mask=[]\n",
    "    all_label=[]\n",
    "    m_len=0\n",
    "    for idx in tqdm(range(len(train_dataset))):\n",
    "        sentence = '<s>' + train_dataset['SENTENCE1'][idx][:train_dataset['start_s1'][idx]] \\\n",
    "            + ' <e1> ' + train_dataset['SENTENCE1'][idx][train_dataset['start_s1'][idx]:train_dataset['end_s1'][idx]] \\\n",
    "            + ' </e1> ' + train_dataset['SENTENCE1'][idx][train_dataset['end_s1'][idx]:] + '</s>' \\\n",
    "            + ' ' \\\n",
    "            + '<s>' + train_dataset['SENTENCE2'][idx][:train_dataset['start_s2'][idx]] \\\n",
    "            + ' <e2> ' + train_dataset['SENTENCE2'][idx][train_dataset['start_s2'][idx]:train_dataset['end_s2'][idx]] \\\n",
    "            + ' </e2> ' + train_dataset['SENTENCE2'][idx][train_dataset['end_s2'][idx]:] + '</s>'\n",
    "\n",
    "            \n",
    "        \n",
    "        token = tokenizer.tokenize(sentence)\n",
    "        m_len = max(m_len, len(token))\n",
    "        e11_p = token.index(\"<e1>\")  # the start position of entity1\n",
    "        e12_p = token.index(\"</e1>\")  # the end position of entity1\n",
    "        e21_p = token.index(\"<e2>\")  # the start position of entity2\n",
    "        e22_p = token.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        token[e11_p] = \"$\"\n",
    "        token[e12_p] = \"$\"\n",
    "        token[e21_p] = \"#\"\n",
    "        token[e22_p] = \"#\"\n",
    "\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "        special_tokens_count = 1\n",
    "\n",
    "        if len(token) < max_seq_len - special_tokens_count:\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            padding_length = max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "            assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "                len(attention_mask), max_seq_len\n",
    "            )\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "            all_label.append(train_dataset['ANSWER'][idx])\n",
    "\n",
    "    all_features = {\n",
    "        'input_ids' : torch.tensor(all_input_ids),\n",
    "        'attention_mask' : torch.tensor(all_attention_mask),\n",
    "        'e1_mask' : torch.tensor(all_e1_mask),\n",
    "        'e2_mask' : torch.tensor(all_e2_mask)\n",
    "    }  \n",
    "    return RE_Dataset(all_features, all_label)\n",
    "\n",
    "def softmax(sr):\n",
    "    \n",
    "    max_val = np.max(sr)\n",
    "    exp_a = np.exp(sr-max_val)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def acc_and_f1(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "    }\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "eval_batch_size = 4\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\", return_token_type_ids=False)\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "test_dataset = load_test_data(f\"{BASE_DIR}dataset/wic/NIKL_SKT_WiC_Dev.tsv\")\n",
    "test_Dataset = convert_sentence_to_features(test_dataset, tokenizer, max_len= 280, mode='eval')\n",
    "\n",
    "n_fold = 5\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for fold in tqdm(range(n_fold)):\n",
    "    config = AutoConfig.from_pretrained(\n",
    "            \"klue/roberta-large\",\n",
    "            num_labels= 2\n",
    "        )\n",
    "    model = Roberta_WiC(\n",
    "            'klue/roberta-large',\n",
    "            config= config, \n",
    "            dropout_rate = 0.1\n",
    "        )\n",
    "    model.load_state_dict(torch.load(f'{BASE_DIR}roberta_model_final_fold_'+str(fold)+'/pytorch_model.bin', map_location=device))\n",
    "    model.eval()\n",
    "    result = test_pred(test_Dataset, eval_batch_size, model)\n",
    "    result.to_csv(f'{BASE_DIR}{str(fold)}_rbt_result.csv', index=False)\n",
    "\n",
    "ensemble= pd.DataFrame()\n",
    "for fold in range(n_fold):\n",
    "    df = pd.read_csv(f'{BASE_DIR}{str(fold)}_rbt_result.csv')\n",
    "    ensemble['label'+str(fold)]= df['label']\n",
    "\n",
    "\n",
    "soft_ensemble= pd.DataFrame()\n",
    "soft_ensemble['pred_0'] = ensemble['label0']\n",
    "soft_ensemble['pred_1'] = ensemble['label0']\n",
    "soft_ensemble['pred_0'] = 0\n",
    "soft_ensemble['pred_1'] = 0\n",
    "\n",
    "for fold in range(n_fold):\n",
    "    df = pd.read_csv(f'{BASE_DIR}{str(fold)}_rbt_result.csv')\n",
    "    df= df.drop('label',axis=1)\n",
    "    df = df.apply(softmax,axis=1)\n",
    "    soft_ensemble['pred_0'] += df['pred_0']\n",
    "    soft_ensemble['pred_1'] += df['pred_1']\n",
    "\n",
    "soft_ensemble['predicted'] = [1 if p_0 < p_1 else 0 for p_0, p_1 in zip(soft_ensemble['pred_0'], soft_ensemble['pred_1'])]\n",
    "result = compute_metrics(soft_ensemble['predicted'], test_dataset['ANSWER'])\n",
    "print('================= devset acc =================')\n",
    "print(f\"accuracy : {result['acc']}\")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19bd773a29a4364b33e8f2bdde4c0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1166.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58042987ad5041af8a3b1f28296e740e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:09:23 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "12/06/2021 10:09:23 - INFO - __main__ -     Batch size = 4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790a9b55a8c4b498b7caa1c85ed6fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=292.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:09:55 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "12/06/2021 10:09:55 - INFO - __main__ -     Batch size = 4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e572b1b62844329b133fb8b40b7e6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=292.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:10:28 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "12/06/2021 10:10:28 - INFO - __main__ -     Batch size = 4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57569d2047f470282c7bbb79602bffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=292.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:11:00 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "12/06/2021 10:11:00 - INFO - __main__ -     Batch size = 4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1df3029cb75496cab4c83deb15e12c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=292.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/06/2021 10:11:33 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "12/06/2021 10:11:33 - INFO - __main__ -     Batch size = 4\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094eefdeb5744d62ba93090c848635d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=292.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "================= devset acc =================\n",
      "accuracy : 0.934819897084048\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 동형이의어 task 끝"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NE0Gjwbb1ZDx"
   ],
   "machine_shape": "hm",
   "name": "BoolQ.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad783e95c017c6a0ffc7d9d3277599f38f5f101d4b63a62b683952e68d1e005f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0334780c57934604b24778390ef74f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "03d7142f330643228c2e1ce8c483d3c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "03e37abdd57a4f4da229ab2530294692": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0691c3337c29400cb5ba4effb3f08ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e92ddd30ded04dc7be218d8183afddbd",
      "placeholder": "​",
      "style": "IPY_MODEL_80e4f2f494e144abb16a16b620622719",
      "value": "Downloading: 100%"
     }
    },
    "07bce04cf9334305aa95a2a915457b90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09431b70b47643f8b74e68852a302c36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ae165ef145b4f7a9c8ddb82f3e66951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9a6e9e3e934ffbb56420ceacc09b94",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad17e33c69024c17a1f7da4de347d085",
      "value": 1
     }
    },
    "0b1efdf5bb8e4164a26dea0c47a59526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c77fbd4922c4bcbb0ca09b48c1d4ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d98397ef86446cf9374bbdaa1a078d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0df27d717cc64026b6fa6745f1b74341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f8c2ccf496b4aa8812d33c4c7b02604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1121ff9a6ddf4660ad559cb24e943f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13210fed8f264b50b721c4d1ed34cdf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14f7ee2edc8344b5bc50d968fa9f0241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8766155677ed4804a7e4634c57590b81",
       "IPY_MODEL_b828f116ae38428c8d338505a8c81b70",
       "IPY_MODEL_928b316af2bb4d4881a47ff4a5c836fd"
      ],
      "layout": "IPY_MODEL_95082759a60d4dfb82ec0ad979f3c9d1"
     }
    },
    "150cb5182be449baa178ee7137800711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "157d73ff8bae4730839f951681d75b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_499daaacfeb6408eafb4ddf211a24414",
       "IPY_MODEL_bc454a9290d443dbb32368a9c48b5dab",
       "IPY_MODEL_59712ac47245473c9cdc1285e3eab567"
      ],
      "layout": "IPY_MODEL_b48d3a55910b4974a59161d531843a6a"
     }
    },
    "168fc960fcb342e6be87f7ac95599164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54fd69d7e3c3400496e98665f4850ccf",
      "max": 263326,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cedb9431d524ffbbd27554a53cf5d08",
      "value": 263326
     }
    },
    "16b5768cc35d41c29afa1434a40f4e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea45eff878c44029b1c18db0cac12081",
       "IPY_MODEL_bfbf9a8fa1cf4d978fe64a188389817d",
       "IPY_MODEL_ac99799583d84ee7a969b3b0f9a453c6"
      ],
      "layout": "IPY_MODEL_fbafeb7f009d4f8cb329c9a37134a324"
     }
    },
    "18d95ff2cb2b4ca38da9f57082a2c3ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19dcdc114e9848baa06406654e3be105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19fbe7928db54b83a1347202ab9641f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a193511bb3a4f889f2cff8c17b67050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9df3e2ffe3e9495197abbb5193228820",
      "placeholder": "​",
      "style": "IPY_MODEL_a0d514ec9e814c92824c4f6a68c7b156",
      "value": " 436M/436M [00:08&lt;00:00, 61.8MB/s]"
     }
    },
    "1a50334fed014d3fa0884042d9a7fb51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b2e7911666f45de85b77520f613ff42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a520d796f98443c89ee053be62785757",
      "placeholder": "​",
      "style": "IPY_MODEL_72349876170e4cdd8c523f6877fa1760",
      "value": " 375/375 [00:00&lt;00:00, 15.5kB/s]"
     }
    },
    "1e857ff5c1bf48279e22b290ac6d79c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ada66b8623a14087949b4ceed1e15be6",
      "placeholder": "​",
      "style": "IPY_MODEL_45aec85ecde740a98278812ae3091e9d",
      "value": " 1.25G/1.25G [00:46&lt;00:00, 52.8MB/s]"
     }
    },
    "1f9e7f724d534eba8345d45d4fbe4536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a098a139e26d42c69434983c6d7c7183",
      "placeholder": "​",
      "style": "IPY_MODEL_8ee3b30511c44ff0a34da75feb79a0ef",
      "value": "Downloading: 100%"
     }
    },
    "205638f366754ddca767e454e7f209bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "207c5b77935144ed8ff40efce4a4b347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e94a32f1df14334b6492a86d839dcb1",
       "IPY_MODEL_168fc960fcb342e6be87f7ac95599164",
       "IPY_MODEL_6fc5e6e9f2ee487eb26de1ae647b993e"
      ],
      "layout": "IPY_MODEL_c494c03c69044acc85eef383f007b556"
     }
    },
    "2127645f0b7041f6ad0cafe01c9550ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3e2bc48f34b49719fc901949865f305",
      "max": 457600984,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ea1f4bb538d4f0598b0288e624a3aa6",
      "value": 457600984
     }
    },
    "239eaecaa4cd4c588da35ca082fd1243": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c03137af8bcd45988dd0cefcbc909e68",
      "max": 870,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e4590eae85a430e9c26fecb316045b5",
      "value": 870
     }
    },
    "2616fd77810047969bd97cd6cd7cda76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae86c5e1a7874217be829fb3d987999f",
      "placeholder": "​",
      "style": "IPY_MODEL_7eaabdd1ae564e99a5811b10f022d154",
      "value": "Downloading: 100%"
     }
    },
    "2623322ba8014e8abfd528f6f0c9c0ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be491d7ae3cf4f739aafcdbef9ccedff",
      "placeholder": "​",
      "style": "IPY_MODEL_42ea5b47c26340939799b2bccf406c57",
      "value": "Downloading: 100%"
     }
    },
    "26cca8cec1f5470191af88c0f0680a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2881a9f96bdc4a3987346224b7334339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0691c3337c29400cb5ba4effb3f08ad0",
       "IPY_MODEL_e44fb34e24b74d11b242676d09b1f31d",
       "IPY_MODEL_c809a39e2d5c4a5aa591ed6901d17ce9"
      ],
      "layout": "IPY_MODEL_365ecd5f5fb548af8640fdb37cc73f4a"
     }
    },
    "2a38f769b47f48a49dec54c1178149b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ad304de84fb4b259e158f40598892fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ceed783fa7840019eee8cb6935590e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f036717e4a142f9962ad930d6bf852e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f6d2f6081cb4ec995ae066f78bb5e1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13210fed8f264b50b721c4d1ed34cdf6",
      "placeholder": "​",
      "style": "IPY_MODEL_9b5458a7f1f244a492cccd24d93f85bc",
      "value": " 431M/431M [00:08&lt;00:00, 62.3MB/s]"
     }
    },
    "2f721ccfc1e047f399bb5d8747674008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3036b535e9c24d56819388cb011c1cc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305dee1e9cd143679778ae98a15b69b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6294ecb476e488ea96b72a4e1088f0d",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03d7142f330643228c2e1ce8c483d3c3",
      "value": 248477
     }
    },
    "315ca1e2ef87450b8ee9b54a4c0b314c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "365ecd5f5fb548af8640fdb37cc73f4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3739e8216905493daf9f8ae361a36db5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "378116917b1e4955ab128ec0aca39d7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39edf1f6a9b542138ffe4beb4458a606": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d98397ef86446cf9374bbdaa1a078d7",
      "placeholder": "​",
      "style": "IPY_MODEL_733edd9f38bf4533a6ff3057b079e94b",
      "value": " 243k/243k [00:00&lt;00:00, 376kB/s]"
     }
    },
    "39f683768b9740aeb86bcf4b1cd59c15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b60470a647042debdf05f47fe543842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3cedb9431d524ffbbd27554a53cf5d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ea1f4bb538d4f0598b0288e624a3aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f349e96009b4660bba2fcf543c2c29f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f78041ec0ca4345a2680c7a94f6cf15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fb3bf62a7044ffbbc9301377665b1f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_668f838fbb1b4ca5b5868e8a9f5e94a2",
       "IPY_MODEL_d3815e6757414b64b03c0e38cfab8c85",
       "IPY_MODEL_90bd122293dc4cc0b9d963f6d3fd9f60"
      ],
      "layout": "IPY_MODEL_452c6f42978d4318bc4b48d3564d1360"
     }
    },
    "4143a3128fc34a9295b274f2c1106246": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ea5b47c26340939799b2bccf406c57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "435bc40ebcce45fb844438a716be3aed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "452c6f42978d4318bc4b48d3564d1360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45aec85ecde740a98278812ae3091e9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "466d04a61e17412dafad0c9905e03d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "499daaacfeb6408eafb4ddf211a24414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4143a3128fc34a9295b274f2c1106246",
      "placeholder": "​",
      "style": "IPY_MODEL_82743d1c9f55448ea9d85f2dbb52f225",
      "value": "Downloading: 100%"
     }
    },
    "4a579b03570d41ab9427600643bea5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b26321fa2f449bd858e1d90181a7912": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_745cc41e00ce405080f82a46aaa54f76",
      "placeholder": "​",
      "style": "IPY_MODEL_e69f12b2212b4100a6f163b90b44266b",
      "value": " 480k/480k [00:00&lt;00:00, 701kB/s]"
     }
    },
    "4c6cdd4950c148ff9ede164046b1c3d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cad7541d3bd471dab2e4b7e0cebeba8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52a8c843f8a3434e938f99ca87c256f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54946c2456d9451e8b394f6d3bcb43d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_981d812b3a5143de949fefe3dac3de35",
       "IPY_MODEL_0ae165ef145b4f7a9c8ddb82f3e66951"
      ],
      "layout": "IPY_MODEL_3739e8216905493daf9f8ae361a36db5"
     }
    },
    "54fd69d7e3c3400496e98665f4850ccf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55f37e201126405ab04cb246ad106844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ecee145296478e938aa3d5caf52de2",
      "placeholder": "​",
      "style": "IPY_MODEL_e89518e6106f48aead64f1562dac4e8e",
      "value": " 870/870 [00:00&lt;00:00, 34.0kB/s]"
     }
    },
    "5823afaf6c3b45d68bdeea03ee4cf635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "590a832ca17c4c7aa4e8c52f98de7903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d411ff164df64dc0b4272493c6e3cc6e",
      "max": 61,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b60470a647042debdf05f47fe543842",
      "value": 61
     }
    },
    "59712ac47245473c9cdc1285e3eab567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de237a43032744ff9efca2e196903a8a",
      "placeholder": "​",
      "style": "IPY_MODEL_8e823a7db5624878a2ef0b0169932487",
      "value": " 734k/734k [00:00&lt;00:00, 724kB/s]"
     }
    },
    "5a9fae08e09c481c80bcbe37812e1cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f9fa9c123bc48e9ad5bd353751fabd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_937d69c974704395b85d6766a8263d43",
      "placeholder": "​",
      "style": "IPY_MODEL_b714d0b7f20f420db7b9a46cd6d7f4c9",
      "value": "Downloading: 100%"
     }
    },
    "60ecee145296478e938aa3d5caf52de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61ae5a348fa94970bdd62253914eb5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81d22a8a750f4b7b83483901b541158c",
       "IPY_MODEL_ddbd1da2072b4afab86c714b2904c75f",
       "IPY_MODEL_fa97bec0381149f5a8f8b8f44045ed8d"
      ],
      "layout": "IPY_MODEL_03e37abdd57a4f4da229ab2530294692"
     }
    },
    "668f838fbb1b4ca5b5868e8a9f5e94a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba6f17a1420b4f88b96756692882e633",
      "placeholder": "​",
      "style": "IPY_MODEL_885aa50de7f347758fb79c13c4abd08b",
      "value": "Downloading: 100%"
     }
    },
    "6af38e0475de4c96bad4b3aa88094f47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d4e708d994c430b94d365c2b2fbf99e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dd193b1554a4ff696d84a4c99331624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fc5e6e9f2ee487eb26de1ae647b993e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5823afaf6c3b45d68bdeea03ee4cf635",
      "placeholder": "​",
      "style": "IPY_MODEL_716c5f5a51914c8c99b1013f151a9451",
      "value": " 257k/257k [00:02&lt;00:00, 96.4kB/s]"
     }
    },
    "6ff8e203373343f2a2963f291d48966b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "712fa8c8869140a4829adbd8fbe46db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "716c5f5a51914c8c99b1013f151a9451": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72349876170e4cdd8c523f6877fa1760": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "733edd9f38bf4533a6ff3057b079e94b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7402824f259e4042bb398664274b365f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "745cc41e00ce405080f82a46aaa54f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "779b06eab63c4de288b7b6686ea44c6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ed642bdced46f6845c096003a33027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7dc22060108242e1ab1ebc6f7a57ce73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e94a32f1df14334b6492a86d839dcb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_878f966a71454e6c88a9d3fd9408f491",
      "placeholder": "​",
      "style": "IPY_MODEL_0334780c57934604b24778390ef74f7b",
      "value": "Downloading: 100%"
     }
    },
    "7eaabdd1ae564e99a5811b10f022d154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80e4f2f494e144abb16a16b620622719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81d22a8a750f4b7b83483901b541158c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a38f769b47f48a49dec54c1178149b1",
      "placeholder": "​",
      "style": "IPY_MODEL_7402824f259e4042bb398664274b365f",
      "value": "Downloading: 100%"
     }
    },
    "82743d1c9f55448ea9d85f2dbb52f225": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8402d3672ab64e87ab7863a47e21095f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c56ab1282aab45c3b631ef8e6750e4fe",
       "IPY_MODEL_92dcc9a253c7479db324d2d368b07ce6",
       "IPY_MODEL_996a8bbe2aeb4d4c9f85f75138aaaf94"
      ],
      "layout": "IPY_MODEL_faf004f3e57941b6a680e6af34a23c40"
     }
    },
    "84da553a82da4135a4c51afce89bab80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a66a6fb8b27b47fe98349758b787c090",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1121ff9a6ddf4660ad559cb24e943f98",
      "value": 375
     }
    },
    "8766155677ed4804a7e4634c57590b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b7d504deb24cdab527596aaa705aec",
      "placeholder": "​",
      "style": "IPY_MODEL_2ad304de84fb4b259e158f40598892fe",
      "value": "Downloading: 100%"
     }
    },
    "878f966a71454e6c88a9d3fd9408f491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "885aa50de7f347758fb79c13c4abd08b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ac5f46e57e04418b6520eff3a8d8d65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e823a7db5624878a2ef0b0169932487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ee3b30511c44ff0a34da75feb79a0ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90bd122293dc4cc0b9d963f6d3fd9f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ceed783fa7840019eee8cb6935590e9",
      "placeholder": "​",
      "style": "IPY_MODEL_19dcdc114e9848baa06406654e3be105",
      "value": " 169/169 [00:00&lt;00:00, 3.86kB/s]"
     }
    },
    "928b316af2bb4d4881a47ff4a5c836fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6af38e0475de4c96bad4b3aa88094f47",
      "placeholder": "​",
      "style": "IPY_MODEL_315ca1e2ef87450b8ee9b54a4c0b314c",
      "value": " 236k/236k [00:00&lt;00:00, 365kB/s]"
     }
    },
    "92dcc9a253c7479db324d2d368b07ce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bacdb1634cd44a1babd19e8f0b2ac854",
      "max": 467,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8c0f308efd744bab94187c87d52f852",
      "value": 467
     }
    },
    "9321d237746c49a78ee667d1463d60e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ac5f46e57e04418b6520eff3a8d8d65",
      "max": 684,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6dd193b1554a4ff696d84a4c99331624",
      "value": 684
     }
    },
    "937d69c974704395b85d6766a8263d43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95082759a60d4dfb82ec0ad979f3c9d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "981d812b3a5143de949fefe3dac3de35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cad7541d3bd471dab2e4b7e0cebeba8",
      "placeholder": "​",
      "style": "IPY_MODEL_378116917b1e4955ab128ec0aca39d7d",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "98484095a7914b19adde8b70b67e5af9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9942dcc5f39445cea78b550a005b23f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "996a8bbe2aeb4d4c9f85f75138aaaf94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19fbe7928db54b83a1347202ab9641f3",
      "placeholder": "​",
      "style": "IPY_MODEL_2f036717e4a142f9962ad930d6bf852e",
      "value": " 467/467 [00:00&lt;00:00, 18.0kB/s]"
     }
    },
    "9b5458a7f1f244a492cccd24d93f85bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9df3e2ffe3e9495197abbb5193228820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e4590eae85a430e9c26fecb316045b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a018ede9e8a449588392d56657dff54f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a098a139e26d42c69434983c6d7c7183": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0d514ec9e814c92824c4f6a68c7b156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a15a04adf12b48efad01b7fa0b7255d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f9fa9c123bc48e9ad5bd353751fabd3",
       "IPY_MODEL_d75a9597cdbb46baa5f884dfa8e53534",
       "IPY_MODEL_1e857ff5c1bf48279e22b290ac6d79c3"
      ],
      "layout": "IPY_MODEL_b65e4c0426e14d98a20ad0e3cb7aafea"
     }
    },
    "a21e7415de074d4d8f870d177284a149": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec80fceb38414763ac9378e6816de4d4",
       "IPY_MODEL_9321d237746c49a78ee667d1463d60e4",
       "IPY_MODEL_f055a648c7ad45039b0fda5342ab2d31"
      ],
      "layout": "IPY_MODEL_b19d5a84e03e4095b56425d25bbb7451"
     }
    },
    "a288b7b466f74da6ba9b7d4e1019964c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2a9ef2097334ec3908420f884904ed3",
       "IPY_MODEL_239eaecaa4cd4c588da35ca082fd1243",
       "IPY_MODEL_55f37e201126405ab04cb246ad106844"
      ],
      "layout": "IPY_MODEL_dbefd2df3ee34540be2f9da9c8440585"
     }
    },
    "a41c6191069d4c4481627914df61787b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a520d796f98443c89ee053be62785757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66a6fb8b27b47fe98349758b787c090": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a91d7c5d6faa4fc8bddfbbd7ab4b8dd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa9e005cd4584008adfdca5bb8ccb1fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f9e7f724d534eba8345d45d4fbe4536",
       "IPY_MODEL_dead70fc1bf84cc4bcb9cb17ebedde93",
       "IPY_MODEL_2f6d2f6081cb4ec995ae066f78bb5e1e"
      ],
      "layout": "IPY_MODEL_f11618dabcab49c59ffe576a6999a857"
     }
    },
    "ac99799583d84ee7a969b3b0f9a453c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb182a14c1d34befab2cabb428b6106f",
      "placeholder": "​",
      "style": "IPY_MODEL_205638f366754ddca767e454e7f209bc",
      "value": " 173/173 [00:00&lt;00:00, 6.94kB/s]"
     }
    },
    "ad17e33c69024c17a1f7da4de347d085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ada66b8623a14087949b4ceed1e15be6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae86c5e1a7874217be829fb3d987999f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b19d5a84e03e4095b56425d25bbb7451": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b36ba57a89c14ee7994e8bf0f57cddee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b48d3a55910b4974a59161d531843a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65e4c0426e14d98a20ad0e3cb7aafea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b714d0b7f20f420db7b9a46cd6d7f4c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b828f116ae38428c8d338505a8c81b70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dc22060108242e1ab1ebc6f7a57ce73",
      "max": 241171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8ce996dce3747c8b2a31130b688387a",
      "value": 241171
     }
    },
    "b9664c0df51a4cb59625224480c34097": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba6f17a1420b4f88b96756692882e633": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bacdb1634cd44a1babd19e8f0b2ac854": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baebb2960f034c9386c212878a4b0fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c57fe9701ae749d99f8329d86ca05d60",
       "IPY_MODEL_84da553a82da4135a4c51afce89bab80",
       "IPY_MODEL_1b2e7911666f45de85b77520f613ff42"
      ],
      "layout": "IPY_MODEL_18d95ff2cb2b4ca38da9f57082a2c3ed"
     }
    },
    "bb182a14c1d34befab2cabb428b6106f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc454a9290d443dbb32368a9c48b5dab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f8c2ccf496b4aa8812d33c4c7b02604",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a41c6191069d4c4481627914df61787b",
      "value": 751504
     }
    },
    "bc941dd085ea448a9119a81a7b49ba9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2616fd77810047969bd97cd6cd7cda76",
       "IPY_MODEL_305dee1e9cd143679778ae98a15b69b3",
       "IPY_MODEL_39edf1f6a9b542138ffe4beb4458a606"
      ],
      "layout": "IPY_MODEL_0df27d717cc64026b6fa6745f1b74341"
     }
    },
    "be491d7ae3cf4f739aafcdbef9ccedff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfaa62780356469a8b3b219ac0972569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfb36c97ff72495380b42a8a8988b2c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfbf9a8fa1cf4d978fe64a188389817d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39f683768b9740aeb86bcf4b1cd59c15",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a50334fed014d3fa0884042d9a7fb51",
      "value": 173
     }
    },
    "c03137af8bcd45988dd0cefcbc909e68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3e2bc48f34b49719fc901949865f305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40ac814faa14a738a4df4b493fcdd0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3cd89c129644dab97380cb1d5953c9d",
       "IPY_MODEL_2127645f0b7041f6ad0cafe01c9550ec",
       "IPY_MODEL_1a193511bb3a4f889f2cff8c17b67050"
      ],
      "layout": "IPY_MODEL_0c77fbd4922c4bcbb0ca09b48c1d4ea8"
     }
    },
    "c494c03c69044acc85eef383f007b556": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c54ce25c7e964e45a7e295c1fdb009c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_deb88077950b4175920722ba0567b2c3",
      "placeholder": "​",
      "style": "IPY_MODEL_3f349e96009b4660bba2fcf543c2c29f",
      "value": "Downloading: 100%"
     }
    },
    "c56ab1282aab45c3b631ef8e6750e4fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_779b06eab63c4de288b7b6686ea44c6a",
      "placeholder": "​",
      "style": "IPY_MODEL_4a579b03570d41ab9427600643bea5df",
      "value": "Downloading: 100%"
     }
    },
    "c57fe9701ae749d99f8329d86ca05d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfaa62780356469a8b3b219ac0972569",
      "placeholder": "​",
      "style": "IPY_MODEL_e68712119a84476eb27315af20145ba0",
      "value": "Downloading: 100%"
     }
    },
    "c809a39e2d5c4a5aa591ed6901d17ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d4e708d994c430b94d365c2b2fbf99e",
      "placeholder": "​",
      "style": "IPY_MODEL_77ed642bdced46f6845c096003a33027",
      "value": " 373/373 [00:00&lt;00:00, 15.0kB/s]"
     }
    },
    "c8ce996dce3747c8b2a31130b688387a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca165a4a073c4355bbb003ac2cace739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98484095a7914b19adde8b70b67e5af9",
      "placeholder": "​",
      "style": "IPY_MODEL_0b1efdf5bb8e4164a26dea0c47a59526",
      "value": " 61.0/61.0 [00:00&lt;00:00, 2.22kB/s]"
     }
    },
    "cd38c3b323934ea2b49fd712b8362804": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ced45f67ff3848449911db2f6265aa24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2a9ef2097334ec3908420f884904ed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5722b61f9f74fd59faadb5938da7e9c",
      "placeholder": "​",
      "style": "IPY_MODEL_b36ba57a89c14ee7994e8bf0f57cddee",
      "value": "Downloading: 100%"
     }
    },
    "d36477a8ede14ddebddc0e004dce4f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3815e6757414b64b03c0e38cfab8c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_712fa8c8869140a4829adbd8fbe46db1",
      "max": 169,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26cca8cec1f5470191af88c0f0680a20",
      "value": 169
     }
    },
    "d411ff164df64dc0b4272493c6e3cc6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d561f326caaa4d3abb9cd619a1975113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5722b61f9f74fd59faadb5938da7e9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d75a9597cdbb46baa5f884dfa8e53534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f721ccfc1e047f399bb5d8747674008",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_150cb5182be449baa178ee7137800711",
      "value": 1346930258
     }
    },
    "d8b7d504deb24cdab527596aaa705aec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c0f308efd744bab94187c87d52f852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbefd2df3ee34540be2f9da9c8440585": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddbd1da2072b4afab86c714b2904c75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07bce04cf9334305aa95a2a915457b90",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a91d7c5d6faa4fc8bddfbbd7ab4b8dd6",
      "value": 547
     }
    },
    "de237a43032744ff9efca2e196903a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dead70fc1bf84cc4bcb9cb17ebedde93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd38c3b323934ea2b49fd712b8362804",
      "max": 451741507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e11b3c1246b74247ba0393805d178696",
      "value": 451741507
     }
    },
    "deb88077950b4175920722ba0567b2c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e11b3c1246b74247ba0393805d178696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e44fb34e24b74d11b242676d09b1f31d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_466d04a61e17412dafad0c9905e03d44",
      "max": 373,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a9fae08e09c481c80bcbe37812e1cb1",
      "value": 373
     }
    },
    "e68712119a84476eb27315af20145ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e69f12b2212b4100a6f163b90b44266b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89518e6106f48aead64f1562dac4e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e92ddd30ded04dc7be218d8183afddbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea45eff878c44029b1c18db0cac12081": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_435bc40ebcce45fb844438a716be3aed",
      "placeholder": "​",
      "style": "IPY_MODEL_a018ede9e8a449588392d56657dff54f",
      "value": "Downloading: 100%"
     }
    },
    "ec80fceb38414763ac9378e6816de4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3036b535e9c24d56819388cb011c1cc3",
      "placeholder": "​",
      "style": "IPY_MODEL_52a8c843f8a3434e938f99ca87c256f5",
      "value": "Downloading: 100%"
     }
    },
    "ed9a6e9e3e934ffbb56420ceacc09b94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f055a648c7ad45039b0fda5342ab2d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9664c0df51a4cb59625224480c34097",
      "placeholder": "​",
      "style": "IPY_MODEL_3f78041ec0ca4345a2680c7a94f6cf15",
      "value": " 684/684 [00:00&lt;00:00, 27.3kB/s]"
     }
    },
    "f11618dabcab49c59ffe576a6999a857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3b281645c744c82ac159c3dad746e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c54ce25c7e964e45a7e295c1fdb009c9",
       "IPY_MODEL_590a832ca17c4c7aa4e8c52f98de7903",
       "IPY_MODEL_ca165a4a073c4355bbb003ac2cace739"
      ],
      "layout": "IPY_MODEL_09431b70b47643f8b74e68852a302c36"
     }
    },
    "f3cd89c129644dab97380cb1d5953c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ced45f67ff3848449911db2f6265aa24",
      "placeholder": "​",
      "style": "IPY_MODEL_9942dcc5f39445cea78b550a005b23f6",
      "value": "Downloading: 100%"
     }
    },
    "f6294ecb476e488ea96b72a4e1088f0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8b45fdc57244471a76e8c07da60d7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfb36c97ff72495380b42a8a8988b2c8",
      "max": 491774,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ff8e203373343f2a2963f291d48966b",
      "value": 491774
     }
    },
    "fa97bec0381149f5a8f8b8f44045ed8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c6cdd4950c148ff9ede164046b1c3d7",
      "placeholder": "​",
      "style": "IPY_MODEL_d36477a8ede14ddebddc0e004dce4f3f",
      "value": " 547/547 [00:00&lt;00:00, 19.3kB/s]"
     }
    },
    "faf004f3e57941b6a680e6af34a23c40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb0cf5e813ba46518a543599551df12c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2623322ba8014e8abfd528f6f0c9c0ac",
       "IPY_MODEL_f8b45fdc57244471a76e8c07da60d7ea",
       "IPY_MODEL_4b26321fa2f449bd858e1d90181a7912"
      ],
      "layout": "IPY_MODEL_d561f326caaa4d3abb9cd619a1975113"
     }
    },
    "fbafeb7f009d4f8cb329c9a37134a324": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}