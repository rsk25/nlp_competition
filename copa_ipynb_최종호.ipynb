{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c2c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install BackTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27036e06",
   "metadata": {},
   "source": [
    "## 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae7df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from time import sleep\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertPreTrainedModel,\n",
    "    ElectraModel,\n",
    "    ElectraPreTrainedModel,\n",
    "    XLMRobertaModel,\n",
    "    BartModel,\n",
    "    BartPretrainedModel,\n",
    "    T5Model,\n",
    "    RobertaModel,\n",
    ")\n",
    "from transformers import MBartModel, MBartConfig\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from BackTranslation import BackTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b65e38",
   "metadata": {},
   "source": [
    "## Data Augmentation by Backtranslation\n",
    "---\n",
    "- Google Translation 사용\n",
    "- 아래 모듈 설치 필요\n",
    "- ```bash\n",
    "pip install BackTranslation\n",
    "```\n",
    "- 매우 오래걸리므로 전처리된 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276e2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = \"dataset/copa/SKT_COPA_Train.tsv\"\n",
    "augmented_train_data = \"dataset/copa/SKT_COPA_Train_aug.tsv\"\n",
    "valid_data = \"dataset/copa/SKT_COPA_Dev.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0641ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\n",
    "    original_train_data,\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"ID\", \"sentence\", \"question\", \"1\", \"2\", \"answer\"],\n",
    "    header=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2945f5",
   "metadata": {},
   "source": [
    "- 아래와 같은 코드를 사용하여 backtranslate하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445b4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_backtranslated = \"dataset/copa/en_new_sentences.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782e0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans = BackTranslation(url=['translate.google.co.kr',])\n",
    "# def augment_sentence(trans, s, tmp='en'):\n",
    "#     return trans.translate(s, src='ko', tmp=tmp).result_text\n",
    "# tmps = [en']\n",
    "# new_datasets = dict()\n",
    "# new_sentences = dict()\n",
    "\n",
    "# for tmp in tmps:\n",
    "#     new_dataset = copy.deepcopy(dataset)\n",
    "#     sentences = new_dataset['sentence'].tolist()\n",
    "#     new_sentences[tmp] = list()\n",
    "#     for sent in tqdm(sentences):\n",
    "#         new_sentences[tmp].append(augment_sentence(trans, sent, tmp=tmp))\n",
    "\n",
    "# torch.save(new_sentences, saved_backtranslated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b2c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_en = torch.load(saved_backtranslated)\n",
    "sent = dict()\n",
    "sent['en'] = sent_en['en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701d83c",
   "metadata": {},
   "source": [
    "## 원본 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a453fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이퀄라이저로 저음 음역대 소리 크기를 키웠다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>음료에 초콜렛 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>남자는 휴대폰을 호수에 빠뜨렸다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>옆 집 사람이 이사를 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                   sentence question                   1  \\\n",
       "0   1  이퀄라이저로 저음 음역대 소리 크기를 키웠다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1   2           음료에 초콜렛 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2   3         남자는 휴대폰을 호수에 빠뜨렸다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3   4           옆 집 사람이 이사를 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4   5                    문을 밀었다.       결과             문이 잠겼다.   \n",
       "\n",
       "                     2  answer  \n",
       "0  베이스 소리가 들리지 않게 되었다.       1  \n",
       "1          음료수가 차가워졌다.       1  \n",
       "2           휴대폰이 고장났다.       2  \n",
       "3    옆 집 사람은 계약을 연장했다.       1  \n",
       "4              문이 열렸다.       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5769d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = copy.deepcopy(dataset)\n",
    "new_dataset['ID'] += len(dataset)\n",
    "new_dataset['sentence'] = sent['en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd89c11",
   "metadata": {},
   "source": [
    "## BackTranslate로 augment한 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0958d811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3081</td>\n",
       "      <td>이퀄라이저는베이스 스캔의 사운드를 올렸습니다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3082</td>\n",
       "      <td>나는 음료에 초콜릿 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3083</td>\n",
       "      <td>그 남자는 호수에 휴대 전화를 넣었습니다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3084</td>\n",
       "      <td>집 옆에있는 사람이 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3085</td>\n",
       "      <td>나는 문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                   sentence question                   1  \\\n",
       "0  3081  이퀄라이저는베이스 스캔의 사운드를 올렸습니다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1  3082        나는 음료에 초콜릿 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2  3083    그 남자는 호수에 휴대 전화를 넣었습니다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3  3084            집 옆에있는 사람이 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4  3085                 나는 문을 밀었다.       결과             문이 잠겼다.   \n",
       "\n",
       "                     2  answer  \n",
       "0  베이스 소리가 들리지 않게 되었다.       1  \n",
       "1          음료수가 차가워졌다.       1  \n",
       "2           휴대폰이 고장났다.       2  \n",
       "3    옆 집 사람은 계약을 연장했다.       1  \n",
       "4              문이 열렸다.       2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa91a90",
   "metadata": {},
   "source": [
    "## 데이터 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885eb2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>question</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이퀄라이저로 저음 음역대 소리 크기를 키웠다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>베이스 소리가 잘 들리게 되었다.</td>\n",
       "      <td>베이스 소리가 들리지 않게 되었다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>음료에 초콜렛 시럽을 넣었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>음료수가 더 달아졌다.</td>\n",
       "      <td>음료수가 차가워졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>남자는 휴대폰을 호수에 빠뜨렸다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>휴대폰이 업그레이드 되었다.</td>\n",
       "      <td>휴대폰이 고장났다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>옆 집 사람이 이사를 나갔다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>옆 집 사람은 계약이 완료되었다.</td>\n",
       "      <td>옆 집 사람은 계약을 연장했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>문을 밀었다.</td>\n",
       "      <td>결과</td>\n",
       "      <td>문이 잠겼다.</td>\n",
       "      <td>문이 열렸다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>6156</td>\n",
       "      <td>계약자로 일한 남자들은 떠났다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>계약을 연장했다.</td>\n",
       "      <td>계약이 종료되었다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>6157</td>\n",
       "      <td>목 마른.</td>\n",
       "      <td>원인</td>\n",
       "      <td>물을 마시지 못했다.</td>\n",
       "      <td>텀블러를 샀다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>6158</td>\n",
       "      <td>나는 그 노래를 오랫동안 전화 했어.</td>\n",
       "      <td>결과</td>\n",
       "      <td>목이 아프다.</td>\n",
       "      <td>노래방이 폐업했다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>6159</td>\n",
       "      <td>사람들은 한 번 함께 일하고 있습니다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>우리나라 축구팀이 골을 넣었다.</td>\n",
       "      <td>우리나라 축구팀이 경기에서 패배했다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>6160</td>\n",
       "      <td>가수의 목이 쉬워졌습니다.</td>\n",
       "      <td>원인</td>\n",
       "      <td>가수가 3시간 동안 춤을 추었다.</td>\n",
       "      <td>가수가 3시간 동안 노래를 불렀다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                   sentence question                   1  \\\n",
       "0        1  이퀄라이저로 저음 음역대 소리 크기를 키웠다.       결과  베이스 소리가 잘 들리게 되었다.   \n",
       "1        2           음료에 초콜렛 시럽을 넣었다.       결과        음료수가 더 달아졌다.   \n",
       "2        3         남자는 휴대폰을 호수에 빠뜨렸다.       결과     휴대폰이 업그레이드 되었다.   \n",
       "3        4           옆 집 사람이 이사를 나갔다.       원인  옆 집 사람은 계약이 완료되었다.   \n",
       "4        5                    문을 밀었다.       결과             문이 잠겼다.   \n",
       "...    ...                        ...      ...                 ...   \n",
       "3075  6156          계약자로 일한 남자들은 떠났다.       원인           계약을 연장했다.   \n",
       "3076  6157                      목 마른.       원인         물을 마시지 못했다.   \n",
       "3077  6158       나는 그 노래를 오랫동안 전화 했어.       결과             목이 아프다.   \n",
       "3078  6159      사람들은 한 번 함께 일하고 있습니다.       원인   우리나라 축구팀이 골을 넣었다.   \n",
       "3079  6160             가수의 목이 쉬워졌습니다.       원인  가수가 3시간 동안 춤을 추었다.   \n",
       "\n",
       "                         2  answer  \n",
       "0      베이스 소리가 들리지 않게 되었다.       1  \n",
       "1              음료수가 차가워졌다.       1  \n",
       "2               휴대폰이 고장났다.       2  \n",
       "3        옆 집 사람은 계약을 연장했다.       1  \n",
       "4                  문이 열렸다.       2  \n",
       "...                    ...     ...  \n",
       "3075            계약이 종료되었다.       2  \n",
       "3076              텀블러를 샀다.       1  \n",
       "3077            노래방이 폐업했다.       1  \n",
       "3078  우리나라 축구팀이 경기에서 패배했다.       2  \n",
       "3079   가수가 3시간 동안 노래를 불렀다.       2  \n",
       "\n",
       "[6160 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.append(new_dataset)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "694f3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.to_csv(augmented_train_data, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df718ea",
   "metadata": {},
   "source": [
    "# COPA 학습 & Inference to json 코드\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3856b",
   "metadata": {},
   "source": [
    "## Transformers의 Wrapper Class와 일부 테스트 모델 선언 및 구현부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcef7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class PoolingHead(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim: int, inner_dim: int, pooler_dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, inner_dim)\n",
    "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = torch.tanh(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class Bert(BertPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Bert, self).__init__(config)\n",
    "        self.bert = BertModel(config=config)  # Load pretrained bert\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.bert(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class XLMRoberta(XLMRobertaModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(XLMRoberta, self).__init__(config)\n",
    "        self.xlmroberta = XLMRobertaModel.from_pretrained(\n",
    "            \"xlm-roberta-large\", config=config\n",
    "        )  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.xlmroberta(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.xlmroberta(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class Electra_BoolQ(ElectraPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Electra_BoolQ, self).__init__(config)\n",
    "\n",
    "        # self.num_labels = config.num_labels\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = ElectraModel.from_pretrained(\n",
    "            \"monologg/koelectra-base-v3-discriminator\", config=config\n",
    "        )\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "        # self.sparse = Sparsemax()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.model(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.model(\n",
    "            input_ids2, attention_mask=attention_mask2, token_type_ids=token_type_ids2\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class Roberta(RobertaModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(Roberta, self).__init__(config)\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            \"klue/roberta-large\", config=config\n",
    "        )  # Load pretrained Electra\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.pooling = PoolingHead(\n",
    "            input_dim=config.hidden_size,\n",
    "            inner_dim=config.hidden_size,\n",
    "            pooler_dropout=0.1,\n",
    "        )\n",
    "        self.qa_classifier = nn.Linear(config.hidden_size, self.num_labels - 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs2 = self.roberta(input_ids2, attention_mask=attention_mask2)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output2 = outputs2[0]\n",
    "        pooled_output = outputs[0][:, 0, :]  # [CLS]\n",
    "        pooled_output2 = outputs2[0][:, 0, :]\n",
    "\n",
    "        sentence_representation = torch.cat([pooled_output, pooled_output2], dim=1)\n",
    "\n",
    "        pooled_output = self.pooling(pooled_output)\n",
    "        pooled_output2 = self.pooling(pooled_output2)\n",
    "\n",
    "        logits1 = self.qa_classifier(pooled_output)\n",
    "        logits2 = self.qa_classifier(pooled_output2)\n",
    "\n",
    "        logits = torch.cat([logits1, logits2], dim=1)\n",
    "\n",
    "        outputs = (logits,) + outputs[\n",
    "            2:\n",
    "        ]  # add hidden states and attention if they are here\n",
    "\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a14d2",
   "metadata": {},
   "source": [
    "## 데이터 전처리부\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5845e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.tokenized_dataset.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def load_data(dataset_dir):\n",
    "    dataset = pd.read_csv(\n",
    "        dataset_dir,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"ID\", \"sentence\", \"question\", \"1\", \"2\", \"answer\"],\n",
    "        header=0,\n",
    "    )\n",
    "    dataset[\"label\"] = dataset[\"answer\"].astype(int) - 1\n",
    "\n",
    "    new_sentence1_1 = []\n",
    "    new_sentence1_2 = []\n",
    "    new_sentence2_1 = []\n",
    "    new_sentence2_2 = []\n",
    "    for i in range(len(dataset)):\n",
    "        s = dataset.iloc[i][\"sentence\"]\n",
    "        q = dataset.iloc[i][\"question\"]\n",
    "        s1 = dataset.iloc[i][\"1\"]\n",
    "        s2 = dataset.iloc[i][\"2\"]\n",
    "        lb = dataset.iloc[i][\"label\"]\n",
    "        if q == \"결과\":\n",
    "            new_sentence1_1.append(\"[결과]\" + s)\n",
    "            # new_sentence1_1.append(s)\n",
    "            new_sentence1_2.append(s1)\n",
    "            new_sentence2_1.append(\"[결과]\" + s)\n",
    "            # new_sentence2_1.append(s)\n",
    "            new_sentence2_2.append(s2)\n",
    "\n",
    "        else:\n",
    "            new_sentence1_1.append(\"[원인]\" + s1)\n",
    "            # new_sentence1_1.append(s1)\n",
    "            new_sentence1_2.append(s)\n",
    "            new_sentence2_1.append(\"[원인]\" + s2)\n",
    "            # new_sentence2_1.append(s2)\n",
    "            new_sentence2_2.append(s)\n",
    "\n",
    "    dataset[\"new_sentence1_1\"] = new_sentence1_1\n",
    "    dataset[\"new_sentence1_2\"] = new_sentence1_2\n",
    "    dataset[\"new_sentence2_1\"] = new_sentence2_1\n",
    "    dataset[\"new_sentence2_2\"] = new_sentence2_2\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenized_dataset(dataset, tokenizer, arch=\"encoder\"):\n",
    "    sentence1_1 = dataset[\"new_sentence1_1\"].tolist()\n",
    "    sentence1_2 = dataset[\"new_sentence1_2\"].tolist()\n",
    "    sentence2_1 = dataset[\"new_sentence2_1\"].tolist()\n",
    "    sentence2_2 = dataset[\"new_sentence2_2\"].tolist()\n",
    "\n",
    "    tokenized_sentences = tokenizer(\n",
    "        sentence1_1,\n",
    "        sentence1_2,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=150,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    tokenized_sentences2 = tokenizer(\n",
    "        sentence2_1,\n",
    "        sentence2_2,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=150,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    for key, value in tokenized_sentences2.items():\n",
    "        tokenized_sentences[key + \"2\"] = value\n",
    "\n",
    "    return tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046a4c9",
   "metadata": {},
   "source": [
    "## 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccaa0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_arch(model_type):\n",
    "    archs = {\n",
    "        \"encoder\": [\"Bert\", \"Electra\", \"XLMRoberta\", \"Electra_BoolQ\", \"Roberta\"],\n",
    "        \"encoder-decoder\": [\"T5\", \"Bart\", \"Bart_BoolQ\"],\n",
    "    }\n",
    "    for arch in archs:\n",
    "        if model_type in archs[arch]:\n",
    "            return arch\n",
    "    raise ValueError(f\"Model [{model_type}] no defined archtecture\")\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }\n",
    "\n",
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "    path = Path(output_path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\"\n",
    "\n",
    "def train(model_dir, args):\n",
    "\n",
    "    seed_everything(args.seed)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"device(GPU) : {torch.cuda.is_available()}\")\n",
    "    num_classes = 2\n",
    "\n",
    "    # load model and tokenizerƒ\n",
    "    MODEL_NAME = args.pretrained_model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # load dataset\n",
    "    train_dataset = load_data(augmented_train_data)\n",
    "    val_dataset = load_data(valid_data)\n",
    "\n",
    "    train_label = train_dataset[\"label\"].values\n",
    "    val_label = val_dataset[\"label\"].values\n",
    "\n",
    "    # tokenizing dataset\n",
    "    tokenized_train = tokenized_dataset(\n",
    "        train_dataset, tokenizer, check_arch(args.model_type)\n",
    "    )\n",
    "    tokenized_val = tokenized_dataset(\n",
    "        val_dataset, tokenizer, check_arch(args.model_type)\n",
    "    )\n",
    "\n",
    "    # make dataset for pytorch.\n",
    "    train_dataset = CustomDataset(tokenized_train, train_label)\n",
    "    val_dataset = CustomDataset(tokenized_val, val_label)\n",
    "    # -- data_loader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=args.valid_batch_size, shuffle=False, drop_last=False,\n",
    "    )\n",
    "\n",
    "    # setting model hyperparameter\n",
    "    if args.model_type == \"Electra_BoolQ\":\n",
    "        config_module = ElectraConfig\n",
    "    else:\n",
    "        config_module = getattr(\n",
    "            import_module(\"transformers\"), args.model_type + \"Config\"\n",
    "        )\n",
    "\n",
    "    model_config = config_module.from_pretrained(MODEL_NAME)\n",
    "    model_config.num_labels = 2\n",
    "\n",
    "    model_module = eval(args.model_type)\n",
    "\n",
    "    if args.model_type in [\"BERT\", \"Electra\"]:\n",
    "        model = model_module.from_pretrained(\n",
    "            MODEL_NAME, config=model_config, args=args\n",
    "        )\n",
    "    else:\n",
    "        model = model_module(config=model_config, args=args)\n",
    "\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "    save_dir = increment_output_dir(os.path.join(model_dir, args.name, str(args.kfold)))\n",
    "\n",
    "    # Freeze Parameter\n",
    "    for name, param in model.named_parameters():\n",
    "        if (\"cls_fc_layer\" not in name) and (\n",
    "            \"label_classifier\" not in name\n",
    "        ):  # classifier layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # -- loss & metric\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    opt_module = getattr(import_module(\"transformers\"), args.optimizer)\n",
    "    optimizer = opt_module(\n",
    "        model.parameters(), lr=args.lr, weight_decay=args.weight_decay, eps=1e-8\n",
    "    )\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=args.warmup_steps,\n",
    "        num_training_steps=len(train_loader) * args.epochs,\n",
    "        last_epoch=-1,\n",
    "    )\n",
    "\n",
    "    # -- logging\n",
    "    start_time = time.time()\n",
    "    logger = SummaryWriter(log_dir=save_dir)\n",
    "    with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(vars(args), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(args.epochs):\n",
    "        # train loop\n",
    "        # unFreeze parameters\n",
    "        if epoch == args.freeze_epoch:\n",
    "            for name, param in model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, items in enumerate(train_loader):\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(**item)\n",
    "            loss = criterion(outs[0], item[\"labels\"])\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == item[\"labels\"]).sum().item()\n",
    "            if (idx + 1) % args.log_interval == 0:\n",
    "                train_loss = loss_value / args.log_interval\n",
    "                train_acc = matches / args.batch_size / args.log_interval\n",
    "                current_lr = get_lr(optimizer)\n",
    "                print(\n",
    "                    f\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "                )\n",
    "\n",
    "                logger.add_scalar(\n",
    "                    \"Train/loss\", train_loss, epoch * len(train_loader) + idx\n",
    "                )\n",
    "                logger.add_scalar(\n",
    "                    \"Train/accuracy\", train_acc, epoch * len(train_loader) + idx\n",
    "                )\n",
    "                logger.add_scalar(\"LR\", current_lr, epoch * len(train_loader) + idx)\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "\n",
    "        # val loop\n",
    "        with torch.no_grad():\n",
    "            print(\"Calculating validation results...\")\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items = []\n",
    "            acc_okay = 0\n",
    "            count_all = 0\n",
    "            for idx, items in enumerate(tqdm(val_loader)):\n",
    "                sleep(0.01)\n",
    "                item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "                outs = model(**item)\n",
    "\n",
    "                preds = torch.argmax(outs[0], dim=-1)\n",
    "                loss = criterion(outs[0], item[\"labels\"]).item()\n",
    "\n",
    "                acc_item = (item[\"labels\"] == preds).sum().item()\n",
    "\n",
    "                val_loss_items.append(loss)\n",
    "                val_acc_items.append(acc_item)\n",
    "                acc_okay += acc_item\n",
    "                count_all += len(preds)\n",
    "\n",
    "            val_loss = np.sum(val_loss_items) / len(val_loss_items)\n",
    "            val_acc = acc_okay / count_all\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                print(\n",
    "                    f\"New best model for val acc : {val_acc:4.2%}! saving the best model..\"\n",
    "                )\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "                torch.save(args, os.path.join(f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "            print(\n",
    "                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.4}|| \"\n",
    "                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.4}\"\n",
    "            )\n",
    "\n",
    "            logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "            logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "            s = f\"Time elapsed: {(time.time() - start_time)/60: .2f} min\"\n",
    "            print(s)\n",
    "            print()\n",
    "            if epoch > 24:\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "                torch.save(args, os.path.join(f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "                break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb487ed6",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "---\n",
    "1. Roberta-large pretrained model 사용하여 fine-tune\n",
    "2. 10epoch 내외로 수렴하는 것을 확인해서 15epoch만 돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674ed2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "args  = EasyDict(dict(\n",
    "    epochs = 15,\n",
    "    model_type = \"Roberta\",\n",
    "    pretrained_model = \"klue/roberta-large\",\n",
    "    lr = 8e-6,\n",
    "    batch_size = 32,\n",
    "    freeze_epoch = 0,\n",
    "    valid_batch_size = 128,\n",
    "    val_ratio = 0.2,\n",
    "    dropout_rate = 0.1,\n",
    "    criterion = 'cross_entropy',\n",
    "    optimizer = 'AdamW',\n",
    "    weight_decay = 0.01,\n",
    "    warmup_steps = 500,\n",
    "    seed = 42,\n",
    "    log_interval = 20,\n",
    "    kfold = 1,\n",
    "    model_dir = \"./copa_data_results/results\",\n",
    "))\n",
    "    \n",
    "    \n",
    "    \n",
    "args.name = f'TrainAll_{args.model_type}_{args.lr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3b9cc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6cccef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device(GPU) : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/15](20/192) || training loss 0.6938 || training accuracy 50.62% || lr 3.2e-07\n",
      "Epoch[0/15](40/192) || training loss 0.6936 || training accuracy 48.44% || lr 6.4e-07\n",
      "Epoch[0/15](60/192) || training loss 0.6956 || training accuracy 47.34% || lr 9.6e-07\n",
      "Epoch[0/15](80/192) || training loss 0.6906 || training accuracy 52.81% || lr 1.28e-06\n",
      "Epoch[0/15](100/192) || training loss 0.6913 || training accuracy 54.22% || lr 1.6e-06\n",
      "Epoch[0/15](120/192) || training loss 0.6918 || training accuracy 53.59% || lr 1.92e-06\n",
      "Epoch[0/15](140/192) || training loss 0.6883 || training accuracy 56.41% || lr 2.24e-06\n",
      "Epoch[0/15](160/192) || training loss 0.6875 || training accuracy 54.53% || lr 2.56e-06\n",
      "Epoch[0/15](180/192) || training loss 0.6704 || training accuracy 61.09% || lr 2.88e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5386d635dcc4d9aa8b4705ed887c2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model for val acc : 78.80%! saving the best model..\n",
      "[Val] acc : 78.80%, loss: 0.4907|| best acc : 78.80%, best loss: 0.4907\n",
      "Time elapsed:  1.08 min\n",
      "\n",
      "Epoch[1/15](20/192) || training loss 0.4782 || training accuracy 77.50% || lr 3.392e-06\n",
      "Epoch[1/15](40/192) || training loss 0.381 || training accuracy 84.06% || lr 3.712e-06\n",
      "Epoch[1/15](60/192) || training loss 0.4154 || training accuracy 82.19% || lr 4.032e-06\n",
      "Epoch[1/15](80/192) || training loss 0.3368 || training accuracy 85.62% || lr 4.352e-06\n",
      "Epoch[1/15](100/192) || training loss 0.3439 || training accuracy 85.47% || lr 4.6719999999999995e-06\n",
      "Epoch[1/15](120/192) || training loss 0.3751 || training accuracy 82.97% || lr 4.992e-06\n",
      "Epoch[1/15](140/192) || training loss 0.2885 || training accuracy 88.28% || lr 5.312e-06\n",
      "Epoch[1/15](160/192) || training loss 0.2783 || training accuracy 86.72% || lr 5.632e-06\n",
      "Epoch[1/15](180/192) || training loss 0.3064 || training accuracy 87.81% || lr 5.952e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feb5b838e38464dbf00014380d5eec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model for val acc : 91.20%! saving the best model..\n",
      "[Val] acc : 91.20%, loss: 0.2792|| best acc : 91.20%, best loss: 0.2792\n",
      "Time elapsed:  2.26 min\n",
      "\n",
      "Epoch[2/15](20/192) || training loss 0.1712 || training accuracy 93.28% || lr 6.464e-06\n",
      "Epoch[2/15](40/192) || training loss 0.1538 || training accuracy 92.97% || lr 6.784e-06\n",
      "Epoch[2/15](60/192) || training loss 0.1435 || training accuracy 94.38% || lr 7.104e-06\n",
      "Epoch[2/15](80/192) || training loss 0.1839 || training accuracy 92.50% || lr 7.424e-06\n",
      "Epoch[2/15](100/192) || training loss 0.1547 || training accuracy 94.38% || lr 7.743999999999999e-06\n",
      "Epoch[2/15](120/192) || training loss 0.1975 || training accuracy 92.81% || lr 7.986554621848738e-06\n",
      "Epoch[2/15](140/192) || training loss 0.1413 || training accuracy 95.00% || lr 7.919327731092437e-06\n",
      "Epoch[2/15](160/192) || training loss 0.141 || training accuracy 95.16% || lr 7.852100840336134e-06\n",
      "Epoch[2/15](180/192) || training loss 0.1112 || training accuracy 95.47% || lr 7.784873949579831e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0195235b67420d91d981cf78fa599e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model for val acc : 91.60%! saving the best model..\n",
      "[Val] acc : 91.60%, loss: 0.3272|| best acc : 91.60%, best loss: 0.2792\n",
      "Time elapsed:  3.43 min\n",
      "\n",
      "Epoch[3/15](20/192) || training loss 0.06428 || training accuracy 97.34% || lr 7.677310924369748e-06\n",
      "Epoch[3/15](40/192) || training loss 0.066 || training accuracy 97.97% || lr 7.610084033613444e-06\n",
      "Epoch[3/15](60/192) || training loss 0.06924 || training accuracy 97.97% || lr 7.542857142857142e-06\n",
      "Epoch[3/15](80/192) || training loss 0.05448 || training accuracy 98.28% || lr 7.47563025210084e-06\n",
      "Epoch[3/15](100/192) || training loss 0.05794 || training accuracy 97.97% || lr 7.408403361344538e-06\n",
      "Epoch[3/15](120/192) || training loss 0.0687 || training accuracy 97.66% || lr 7.341176470588234e-06\n",
      "Epoch[3/15](140/192) || training loss 0.04584 || training accuracy 99.06% || lr 7.273949579831932e-06\n",
      "Epoch[3/15](160/192) || training loss 0.03607 || training accuracy 99.06% || lr 7.20672268907563e-06\n",
      "Epoch[3/15](180/192) || training loss 0.05669 || training accuracy 98.12% || lr 7.139495798319327e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e04832952a74a1fadcd92098cffc955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 90.60%, loss: 0.4094|| best acc : 91.60%, best loss: 0.2792\n",
      "Time elapsed:  4.46 min\n",
      "\n",
      "Epoch[4/15](20/192) || training loss 0.04117 || training accuracy 98.59% || lr 7.031932773109243e-06\n",
      "Epoch[4/15](40/192) || training loss 0.03569 || training accuracy 98.75% || lr 6.964705882352941e-06\n",
      "Epoch[4/15](60/192) || training loss 0.02685 || training accuracy 99.06% || lr 6.897478991596638e-06\n",
      "Epoch[4/15](80/192) || training loss 0.03934 || training accuracy 98.12% || lr 6.830252100840335e-06\n",
      "Epoch[4/15](100/192) || training loss 0.02512 || training accuracy 99.22% || lr 6.763025210084033e-06\n",
      "Epoch[4/15](120/192) || training loss 0.02224 || training accuracy 99.38% || lr 6.695798319327731e-06\n",
      "Epoch[4/15](140/192) || training loss 0.02148 || training accuracy 99.69% || lr 6.628571428571428e-06\n",
      "Epoch[4/15](160/192) || training loss 0.02032 || training accuracy 99.06% || lr 6.5613445378151255e-06\n",
      "Epoch[4/15](180/192) || training loss 0.02397 || training accuracy 99.38% || lr 6.4941176470588234e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937eb1dd6b4e41e28d12ce99fc6679f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model for val acc : 92.00%! saving the best model..\n",
      "[Val] acc : 92.00%, loss: 0.3837|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  5.64 min\n",
      "\n",
      "Epoch[5/15](20/192) || training loss 0.02074 || training accuracy 99.06% || lr 6.386554621848739e-06\n",
      "Epoch[5/15](40/192) || training loss 0.01713 || training accuracy 99.53% || lr 6.319327731092436e-06\n",
      "Epoch[5/15](60/192) || training loss 0.02199 || training accuracy 99.22% || lr 6.252100840336134e-06\n",
      "Epoch[5/15](80/192) || training loss 0.02969 || training accuracy 98.75% || lr 6.184873949579832e-06\n",
      "Epoch[5/15](100/192) || training loss 0.01875 || training accuracy 99.69% || lr 6.1176470588235285e-06\n",
      "Epoch[5/15](120/192) || training loss 0.0256 || training accuracy 98.91% || lr 6.0504201680672265e-06\n",
      "Epoch[5/15](140/192) || training loss 0.02173 || training accuracy 99.69% || lr 5.9831932773109244e-06\n",
      "Epoch[5/15](160/192) || training loss 0.01657 || training accuracy 99.53% || lr 5.9159663865546215e-06\n",
      "Epoch[5/15](180/192) || training loss 0.022 || training accuracy 99.22% || lr 5.848739495798319e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd4f1a66e744db19fbe0ab74ba77703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.20%, loss: 0.4203|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  6.66 min\n",
      "\n",
      "Epoch[6/15](20/192) || training loss 0.01329 || training accuracy 99.69% || lr 5.741176470588235e-06\n",
      "Epoch[6/15](40/192) || training loss 0.02177 || training accuracy 99.69% || lr 5.6739495798319324e-06\n",
      "Epoch[6/15](60/192) || training loss 0.01304 || training accuracy 99.69% || lr 5.6067226890756295e-06\n",
      "Epoch[6/15](80/192) || training loss 0.009519 || training accuracy 99.84% || lr 5.5394957983193275e-06\n",
      "Epoch[6/15](100/192) || training loss 0.01774 || training accuracy 99.53% || lr 5.472268907563025e-06\n",
      "Epoch[6/15](120/192) || training loss 0.01284 || training accuracy 99.69% || lr 5.4050420168067225e-06\n",
      "Epoch[6/15](140/192) || training loss 0.008861 || training accuracy 99.69% || lr 5.33781512605042e-06\n",
      "Epoch[6/15](160/192) || training loss 0.009139 || training accuracy 99.84% || lr 5.2705882352941176e-06\n",
      "Epoch[6/15](180/192) || training loss 0.01358 || training accuracy 99.53% || lr 5.203361344537815e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe25dfb07bf49de8fc8e5d4ecc9e752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.80%, loss: 0.4458|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  7.69 min\n",
      "\n",
      "Epoch[7/15](20/192) || training loss 0.01839 || training accuracy 99.22% || lr 5.0957983193277305e-06\n",
      "Epoch[7/15](40/192) || training loss 0.01006 || training accuracy 99.69% || lr 5.0285714285714285e-06\n",
      "Epoch[7/15](60/192) || training loss 0.009921 || training accuracy 99.84% || lr 4.9613445378151256e-06\n",
      "Epoch[7/15](80/192) || training loss 0.006946 || training accuracy 99.84% || lr 4.8941176470588235e-06\n",
      "Epoch[7/15](100/192) || training loss 0.01625 || training accuracy 99.53% || lr 4.826890756302521e-06\n",
      "Epoch[7/15](120/192) || training loss 0.009226 || training accuracy 99.69% || lr 4.7596638655462185e-06\n",
      "Epoch[7/15](140/192) || training loss 0.01174 || training accuracy 99.69% || lr 4.692436974789916e-06\n",
      "Epoch[7/15](160/192) || training loss 0.005835 || training accuracy 100.00% || lr 4.625210084033614e-06\n",
      "Epoch[7/15](180/192) || training loss 0.007438 || training accuracy 99.84% || lr 4.557983193277311e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61da387e7a4448bb10ca7f32f39450f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.80%, loss: 0.4472|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  8.72 min\n",
      "\n",
      "Epoch[8/15](20/192) || training loss 0.006374 || training accuracy 100.00% || lr 4.4504201680672266e-06\n",
      "Epoch[8/15](40/192) || training loss 0.006707 || training accuracy 99.84% || lr 4.3831932773109245e-06\n",
      "Epoch[8/15](60/192) || training loss 0.006601 || training accuracy 99.84% || lr 4.315966386554622e-06\n",
      "Epoch[8/15](80/192) || training loss 0.007672 || training accuracy 99.84% || lr 4.2487394957983195e-06\n",
      "Epoch[8/15](100/192) || training loss 0.005372 || training accuracy 99.84% || lr 4.181512605042017e-06\n",
      "Epoch[8/15](120/192) || training loss 0.008952 || training accuracy 99.69% || lr 4.114285714285714e-06\n",
      "Epoch[8/15](140/192) || training loss 0.006693 || training accuracy 99.69% || lr 4.047058823529412e-06\n",
      "Epoch[8/15](160/192) || training loss 0.004281 || training accuracy 100.00% || lr 3.979831932773109e-06\n",
      "Epoch[8/15](180/192) || training loss 0.003682 || training accuracy 100.00% || lr 3.912605042016807e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4ab561033e4b8eb6259513978e0826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 92.00%, loss: 0.483|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  9.74 min\n",
      "\n",
      "Epoch[9/15](20/192) || training loss 0.002338 || training accuracy 100.00% || lr 3.805042016806722e-06\n",
      "Epoch[9/15](40/192) || training loss 0.003144 || training accuracy 100.00% || lr 3.73781512605042e-06\n",
      "Epoch[9/15](60/192) || training loss 0.001843 || training accuracy 100.00% || lr 3.670588235294117e-06\n",
      "Epoch[9/15](80/192) || training loss 0.009822 || training accuracy 99.53% || lr 3.603361344537815e-06\n",
      "Epoch[9/15](100/192) || training loss 0.007631 || training accuracy 99.69% || lr 3.5361344537815122e-06\n",
      "Epoch[9/15](120/192) || training loss 0.00453 || training accuracy 100.00% || lr 3.46890756302521e-06\n",
      "Epoch[9/15](140/192) || training loss 0.002018 || training accuracy 100.00% || lr 3.4016806722689073e-06\n",
      "Epoch[9/15](160/192) || training loss 0.005038 || training accuracy 100.00% || lr 3.3344537815126052e-06\n",
      "Epoch[9/15](180/192) || training loss 0.01228 || training accuracy 99.69% || lr 3.2672268907563023e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20631899fd4d433796ae354fd75fa3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 90.40%, loss: 0.4537|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  10.77 min\n",
      "\n",
      "Epoch[10/15](20/192) || training loss 0.001722 || training accuracy 100.00% || lr 3.159663865546218e-06\n",
      "Epoch[10/15](40/192) || training loss 0.004434 || training accuracy 100.00% || lr 3.092436974789916e-06\n",
      "Epoch[10/15](60/192) || training loss 0.004272 || training accuracy 99.84% || lr 3.0252100840336132e-06\n",
      "Epoch[10/15](80/192) || training loss 0.002358 || training accuracy 100.00% || lr 2.9579831932773108e-06\n",
      "Epoch[10/15](100/192) || training loss 0.001988 || training accuracy 100.00% || lr 2.8907563025210083e-06\n",
      "Epoch[10/15](120/192) || training loss 0.005524 || training accuracy 99.84% || lr 2.823529411764706e-06\n",
      "Epoch[10/15](140/192) || training loss 0.001401 || training accuracy 100.00% || lr 2.7563025210084033e-06\n",
      "Epoch[10/15](160/192) || training loss 0.005311 || training accuracy 99.84% || lr 2.689075630252101e-06\n",
      "Epoch[10/15](180/192) || training loss 0.002814 || training accuracy 100.00% || lr 2.6218487394957984e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf7883e0ed74524a6500c5385d1507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 90.80%, loss: 0.4928|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  11.79 min\n",
      "\n",
      "Epoch[11/15](20/192) || training loss 0.006685 || training accuracy 99.53% || lr 2.5142857142857142e-06\n",
      "Epoch[11/15](40/192) || training loss 0.001531 || training accuracy 100.00% || lr 2.4470588235294118e-06\n",
      "Epoch[11/15](60/192) || training loss 0.002856 || training accuracy 99.84% || lr 2.3798319327731093e-06\n",
      "Epoch[11/15](80/192) || training loss 0.004037 || training accuracy 99.84% || lr 2.312605042016807e-06\n",
      "Epoch[11/15](100/192) || training loss 0.003251 || training accuracy 100.00% || lr 2.2453781512605043e-06\n",
      "Epoch[11/15](120/192) || training loss 0.007113 || training accuracy 99.84% || lr 2.1781512605042014e-06\n",
      "Epoch[11/15](140/192) || training loss 0.001861 || training accuracy 100.00% || lr 2.110924369747899e-06\n",
      "Epoch[11/15](160/192) || training loss 0.001811 || training accuracy 100.00% || lr 2.0436974789915965e-06\n",
      "Epoch[11/15](180/192) || training loss 0.001926 || training accuracy 100.00% || lr 1.976470588235294e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139242c988fb488195159e6ac47e71cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 90.80%, loss: 0.4789|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  12.82 min\n",
      "\n",
      "Epoch[12/15](20/192) || training loss 0.002779 || training accuracy 99.84% || lr 1.86890756302521e-06\n",
      "Epoch[12/15](40/192) || training loss 0.00307 || training accuracy 100.00% || lr 1.8016806722689076e-06\n",
      "Epoch[12/15](60/192) || training loss 0.003593 || training accuracy 99.84% || lr 1.734453781512605e-06\n",
      "Epoch[12/15](80/192) || training loss 0.003506 || training accuracy 100.00% || lr 1.6672268907563026e-06\n",
      "Epoch[12/15](100/192) || training loss 0.00425 || training accuracy 100.00% || lr 1.6e-06\n",
      "Epoch[12/15](120/192) || training loss 0.001967 || training accuracy 100.00% || lr 1.5327731092436974e-06\n",
      "Epoch[12/15](140/192) || training loss 0.004414 || training accuracy 99.84% || lr 1.4655462184873948e-06\n",
      "Epoch[12/15](160/192) || training loss 0.002093 || training accuracy 100.00% || lr 1.3983193277310923e-06\n",
      "Epoch[12/15](180/192) || training loss 0.005751 || training accuracy 99.84% || lr 1.3310924369747898e-06\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c676344a0dc94952b9234873de66386c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.40%, loss: 0.479|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  13.85 min\n",
      "\n",
      "Epoch[13/15](20/192) || training loss 0.001776 || training accuracy 100.00% || lr 1.2235294117647059e-06\n",
      "Epoch[13/15](40/192) || training loss 0.001028 || training accuracy 100.00% || lr 1.1563025210084034e-06\n",
      "Epoch[13/15](60/192) || training loss 0.002657 || training accuracy 100.00% || lr 1.0890756302521007e-06\n",
      "Epoch[13/15](80/192) || training loss 0.0009199 || training accuracy 100.00% || lr 1.0218487394957982e-06\n",
      "Epoch[13/15](100/192) || training loss 0.004904 || training accuracy 99.84% || lr 9.546218487394957e-07\n",
      "Epoch[13/15](120/192) || training loss 0.001452 || training accuracy 100.00% || lr 8.873949579831932e-07\n",
      "Epoch[13/15](140/192) || training loss 0.002073 || training accuracy 100.00% || lr 8.201680672268907e-07\n",
      "Epoch[13/15](160/192) || training loss 0.002645 || training accuracy 100.00% || lr 7.529411764705882e-07\n",
      "Epoch[13/15](180/192) || training loss 0.00177 || training accuracy 100.00% || lr 6.857142857142857e-07\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fe06e1941041d4b2b668d6eafa9af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.00%, loss: 0.4957|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  14.88 min\n",
      "\n",
      "Epoch[14/15](20/192) || training loss 0.0006829 || training accuracy 100.00% || lr 5.781512605042017e-07\n",
      "Epoch[14/15](40/192) || training loss 0.005888 || training accuracy 99.84% || lr 5.109243697478991e-07\n",
      "Epoch[14/15](60/192) || training loss 0.004824 || training accuracy 99.69% || lr 4.436974789915966e-07\n",
      "Epoch[14/15](80/192) || training loss 0.001067 || training accuracy 100.00% || lr 3.764705882352941e-07\n",
      "Epoch[14/15](100/192) || training loss 0.003102 || training accuracy 100.00% || lr 3.0924369747899157e-07\n",
      "Epoch[14/15](120/192) || training loss 0.001379 || training accuracy 100.00% || lr 2.4201680672268904e-07\n",
      "Epoch[14/15](140/192) || training loss 0.001097 || training accuracy 100.00% || lr 1.7478991596638653e-07\n",
      "Epoch[14/15](160/192) || training loss 0.002399 || training accuracy 100.00% || lr 1.0756302521008403e-07\n",
      "Epoch[14/15](180/192) || training loss 0.0005987 || training accuracy 100.00% || lr 4.033613445378151e-08\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaf93bbc06045c7876a9c294c17a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc : 91.00%, loss: 0.4968|| best acc : 92.00%, best loss: 0.2792\n",
      "Time elapsed:  15.91 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(args.model_dir, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8889d4",
   "metadata": {},
   "source": [
    "## Inference : \n",
    "---\n",
    "- target_dir(Best Val Accuracy model) 를 상황에 맞게 수정해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3114bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_dir = \"copa_data_results/results/TrainAll_Roberta_8e-06/1/best\"\n",
    "model_module = eval(args.model_type)\n",
    "model = model_module.from_pretrained(target_dir, args=args)\n",
    "model.parameters\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238efbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "dataset = load_data(valid_data)\n",
    "test_label = dataset[\"label\"].values\n",
    "\n",
    "tokenized_test = tokenized_dataset(dataset, tokenizer, check_arch(args.model_type))\n",
    "test_dataset = CustomDataset(tokenized_test, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8314d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, tokenized_sent, device):\n",
    "    dataloader = DataLoader(tokenized_sent, batch_size=8, shuffle=False)\n",
    "    model.eval()\n",
    "    results = []\n",
    "    preds = []\n",
    "\n",
    "    for i, items in enumerate(tqdm(dataloader)):\n",
    "        item = {key: val.to(device) for key, val in items.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**item)\n",
    "        logits = outputs[0]\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(logits)\n",
    "        logits = logits.detach().cpu().numpy()  # (Batch_size, 5)  5개의 클래스 확률형태\n",
    "        pred = logits[:, 1]\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "        results += result.tolist()\n",
    "        preds += pred.tolist()\n",
    "\n",
    "    return np.array(results).flatten(), np.array(preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "462c7498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1964b96cd7a4551862dd950f42b57eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_answer, preds = inference(model, tokenized_sent=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e840ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make json\n",
    "submission_json = {\"copa\": []}\n",
    "for i, pred in enumerate(pred_answer.tolist()):\n",
    "    submission_json[\"copa\"].append({\"idx\": i, \"label\": int(pred + 1)})\n",
    "with open(\"submission.json\", \"w\") as fp:\n",
    "    json.dump(submission_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc4bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"model_answer\"] = pred_answer\n",
    "dataset[\"model_pred\"] = preds\n",
    "dataset.to_csv(\"copa_result.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d0b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
