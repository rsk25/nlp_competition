{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from g2pk import G2p\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data_dir = Path(\"./dataset/cola/\") / filename\n",
    "    dataset = pd.read_csv(\n",
    "        data_dir, \n",
    "        sep=\"\\t\", \n",
    "        header=0, \n",
    "        encoding='utf-8', \n",
    "        names=['source', 'acceptability_label', 'source_annotation', 'sentence']\n",
    "    )\n",
    "    dataset['label'] = dataset['acceptability_label'].astype(int)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def augment_data(dataset):\n",
    "    tmp_data_holder = {'source':[], 'label':[], 'source_annotation':[], 'sentence':[]}\n",
    "    for _, row in dataset[dataset['label'] == 1].iterrows():\n",
    "        tmp_data_holder['source'].append(row['source'])\n",
    "        tmp_data_holder['label'].append(0)\n",
    "        tmp_data_holder['source_annotation'].append('')\n",
    "        tmp_data_holder['sentence'].append(g2p(row['sentence']))\n",
    "\n",
    "    dataset = pd.DataFrame(tmp_data_holder)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "def multiprocess_aug(dataset):\n",
    "    num_process = multiprocessing.cpu_count()\n",
    "    chunk_size = int(dataset.shape[0] / num_process)\n",
    "    chunks = [dataset.iloc[dataset.index[i:i+chunk_size]] for i in range(0, dataset.shape[0], chunk_size)]\n",
    "    assert len(chunks) != 0\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_process)\n",
    "    results = pool.map(augment_data, chunks)\n",
    "    \n",
    "    new_dataset = pd.concat(results)\n",
    "    dataset = pd.concat([dataset, new_dataset])\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenize_datasets(dataset, tokenizer, arch=\"encoder\"):\n",
    "    sentence = dataset['sentence'].tolist()\n",
    "    tokenize_sent = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 150,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids = True\n",
    "    )\n",
    "\n",
    "    return tokenize_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>acceptability_label</th>\n",
       "      <th>source_annotation</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>높은 달이 떴다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>*</td>\n",
       "      <td>달이 뜸이 높았다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T00002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>실없는 사람이 까불까불한다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T00003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>나는 철수에게 공을 던졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>내가 순이와 둘이서 다툰다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>T09994</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>밤새 그 수를 다 머건는 게다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>T09996</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>수호는 지베 아 노지 아낟따.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>T09998</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>철수느 녕이가 아주 어려운 논무느 렬심히 일걷따고 생가캗따.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T09999</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>선생니미 순히에게 채그 릴께 하시나 순히는 채그 릭찌 안는다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>그의 부주의로 말미아마 사거니 터젇따.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source  acceptability_label source_annotation  \\\n",
       "0    T00001                  1.0               NaN   \n",
       "1    T00001                  0.0                 *   \n",
       "2    T00002                  1.0               NaN   \n",
       "3    T00003                  1.0               NaN   \n",
       "4    T00004                  1.0               NaN   \n",
       "..      ...                  ...               ...   \n",
       "118  T09994                  NaN                     \n",
       "119  T09996                  NaN                     \n",
       "120  T09998                  NaN                     \n",
       "0    T09999                  NaN                     \n",
       "1    T10000                  NaN                     \n",
       "\n",
       "                               sentence  label  \n",
       "0                             높은 달이 떴다.      1  \n",
       "1                            달이 뜸이 높았다.      0  \n",
       "2                       실없는 사람이 까불까불한다.      1  \n",
       "3                       나는 철수에게 공을 던졌다.      1  \n",
       "4                       내가 순이와 둘이서 다툰다.      1  \n",
       "..                                  ...    ...  \n",
       "118                   밤새 그 수를 다 머건는 게다.      0  \n",
       "119                    수호는 지베 아 노지 아낟따.      0  \n",
       "120   철수느 녕이가 아주 어려운 논무느 렬심히 일걷따고 생가캗따.      0  \n",
       "0    선생니미 순히에게 채그 릴께 하시나 순히는 채그 릭찌 안는다.      0  \n",
       "1                 그의 부주의로 말미아마 사거니 터젇따.      0  \n",
       "\n",
       "[23788 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_data(\"./NIKL_CoLA_train.tsv\")\n",
    "train_dataset = multiprocess_aug(train_dataset)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels= None, test=False):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, ElectraPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Electra(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(Electra, self).__init__(config)\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.electra(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        output = outputs[0][:, 0, :]\n",
    "        output = self.linear(self.dropout(output))\n",
    "        output = torch.tanh(output)\n",
    "        logits = self.classifier(output)\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        \"\"\"\n",
    "        :param inputs: predictions\n",
    "        :param target: target labels\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        # target = torch.argmax(target, dim=-1)\n",
    "        loss = self.CE(inputs, target)\n",
    "        return loss\n",
    "\n",
    "_criterion_entrypoints = {\n",
    "    'cross_entropy': CrossEntropy,\n",
    "}\n",
    "\n",
    "def criterion_entrypoint(criterion_name):\n",
    "    return _criterion_entrypoints[criterion_name]\n",
    "\n",
    "def is_criterion(criterion_name):\n",
    "    return criterion_name in _criterion_entrypoints\n",
    "\n",
    "def create_criterion(criterion_name, **kwargs):\n",
    "    if is_criterion(criterion_name):\n",
    "        create_fn = criterion_entrypoint(criterion_name)\n",
    "        criterion = create_fn(**kwargs)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_arch(model_type):\n",
    "  archs = {\n",
    "    \"encoder\" : [\"Bert\", \"Electra\", \"XLMRoberta\", \"Electra_BoolQ\", \"Roberta\"],\n",
    "    \"encoder-decoder\" : [\"T5\", \"Bart\", \"Bart_BoolQ\"]\n",
    "  }\n",
    "  for arch in archs:\n",
    "    if model_type in archs[arch]:\n",
    "      return arch\n",
    "  raise ValueError(f\"Model [{model_type}] no defined archtecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "def output_dir(output_path, exist_ok = False):\n",
    "    path = Path(output_path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    model_dir = args.model_dir\n",
    "    set_seed()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    # tokenizer\n",
    "    MODEL_NAME=args.pretrained_model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # load dataset\n",
    "    datasets_ = load_data(\"./NIKL_CoLA_train.tsv\")\n",
    "    datasets_ = multiprocess_aug(datasets_) # augment training data\n",
    "    labels_ = datasets_[\"label\"]\n",
    "    \n",
    "\n",
    "    length = len(labels_)\n",
    "    kf = args.kfold\n",
    "    class_indexs = defaultdict(list)\n",
    "    for i, label_ in enumerate(labels_):\n",
    "        class_indexs[np.argmax(label_)].append(i) #  class index [0] = [2,3,5,6], class index[1]=[나머지]\n",
    "    val_indices = set()\n",
    "    for index in class_indexs: # stratified: key : 0, 1 classindex[0][0/5:1/5]\n",
    "        val_indices = (val_indices | set(class_indexs[index][int(len(class_indexs[index])*(kf-1)/9) : int(len(class_indexs[index])*kf/9)]))\n",
    "    train_indices = set(range(length)) - val_indices\n",
    "\n",
    "    train_dataset = datasets_.loc[np.array(list(train_indices))]\n",
    "    val_dataset = datasets_.loc[np.array(list(val_indices))]\n",
    "\n",
    "    train_label = train_dataset['label'].values\n",
    "    val_label = val_dataset['label'].values\n",
    "\n",
    "    tokenized_train = tokenize_datasets(train_dataset, tokenizer, check_arch(args.model_type))\n",
    "    tokenized_val = tokenize_datasets(val_dataset, tokenizer, check_arch(args.model_type))\n",
    "\n",
    "    train_dataset = ColaDataset(tokenized_train, train_label)\n",
    "    val_dataset = ColaDataset(tokenized_val, val_label)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.valid_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    config_module = getattr(import_module(\"transformers\"), args.model_type + \"Config\")\n",
    "    \n",
    "    model_config = config_module.from_pretrained(MODEL_NAME)\n",
    "    model_config.num_labels = 2\n",
    "\n",
    "    model = Electra.from_pretrained(MODEL_NAME, config=model_config)\n",
    "\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "\n",
    "    save_dir = output_dir(os.path.join(model_dir, args.name, str(args.kfold)))\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if ('cls_fc_layer' not in name) and ('label_classifier' not in name): # classifier layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "    criterion = create_criterion(args.criterion)  # default: cross_entropy\n",
    "    opt_module = getattr(import_module(\"transformers\"), args.optimizer)\n",
    "    optimizer = opt_module(\n",
    "        model.parameters(),\n",
    "        lr=args.lr,\n",
    "        weight_decay=args.weight_decay,\n",
    "        eps = 1e-8\n",
    "    )\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=args.warmup_steps, \n",
    "        num_training_steps=len(train_loader) * args.epochs, \n",
    "        last_epoch=- 1\n",
    "    )   \n",
    "\n",
    "    ## logging\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_mcc = -1\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(args.epochs):\n",
    "        pbar = tqdm(train_loader, dynamic_ncols=True)\n",
    "        if epoch == args.freeze_epoch:\n",
    "            for name, param in model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, items in enumerate(pbar):\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(**item)\n",
    "            loss = criterion(outs[0], item['labels'])\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == item['labels']).sum().item()\n",
    "            if (idx + 1) % args.log_interval == 0:\n",
    "                train_loss = loss_value / args.log_interval\n",
    "                train_acc = matches / args.batch_size / args.log_interval\n",
    "                current_lr = get_lr(optimizer)\n",
    "                pbar.set_description(f\"Epoch: [{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || loss: {train_loss:4.4} || acc: {train_acc:4.2%} || lr {current_lr:4.4}\")\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0     \n",
    "\n",
    "    ## validation\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, dynamic_ncols=True)\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        acc_okay = 0\n",
    "        count_all = 0\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        eps = 1e-9\n",
    "        for idx, items in enumerate(pbar):\n",
    "            sleep(0.01)\n",
    "            item = {key: val.to(device) for key, val in items.items()}\n",
    "\n",
    "            outs = model(**item)\n",
    "\n",
    "            preds = torch.argmax(outs[0], dim=-1)\n",
    "            loss = criterion(outs[0], item['labels']).item()\n",
    "\n",
    "            acc_item = (item['labels'] == preds).sum().item()\n",
    "\n",
    "            TRUE = (item['labels'] == preds)\n",
    "            FALSE = (item['labels'] != preds)\n",
    "\n",
    "            TP += (TRUE * preds).sum().item()\n",
    "            TN += (TRUE * (preds==0)).sum().item()\n",
    "            FP += (FALSE * preds).sum().item()\n",
    "            FN += (FALSE * (preds==0)).sum().item()\n",
    "\n",
    "            val_loss_items.append(loss)\n",
    "            val_acc_items.append(acc_item)\n",
    "            acc_okay += acc_item\n",
    "            count_all += len(preds)\n",
    "\n",
    "            MCC = ((TP*TN) - (FP*FN)) / (((TP+FP+eps)*(TP+FN+eps)*(TN+FP+eps)*(TN+FN+eps))**0.5)\n",
    "\n",
    "            pbar.set_description(f\"Epoch: [{epoch}/{args.epochs}]({idx + 1}/{len(val_loader)}) || val_loss: {loss:4.4} || acc: {acc_okay/count_all:4.2%} || MCC: {MCC:4.2%}\")\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loss_items)\n",
    "        val_acc = acc_okay / count_all\n",
    "\n",
    "        if MCC > best_val_mcc:\n",
    "            print(f\"New best model for val mcc : {MCC:4.2%}! saving the best model..\")\n",
    "            model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "            model_to_save.save_pretrained(f\"{save_dir}/best\")\n",
    "            torch.save(args, os.path.join(f\"{save_dir}/best\", \"training_args.bin\"))\n",
    "            best_val_mcc = MCC\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.4}|| \"\n",
    "            f\"best mcc : {best_val_mcc:4.2%}, best loss: {best_val_loss:4.4}|| \"\n",
    "            f\"MCC : {MCC:4.2%}|| \"\n",
    "            f\"TP:{TP} / TN:{TN} / FP:{FP} / FN:{FN}\"\n",
    "        )\n",
    "    \n",
    "    time.sleep(5)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training args\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1,2,3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "args = argparse.Namespace(\n",
    "    seed = 42,\n",
    "    epochs = 30,\n",
    "    freeze_epoch=0,\n",
    "    optimizer = 'AdamW',\n",
    "    weight_decay = 0.01,\n",
    "    warmup_steps = 500,\n",
    "    log_interval = 20,\n",
    "    kfold = 9,\n",
    "\n",
    "    criterion = 'cross_entropy',\n",
    "    dropout_rate = 0.2,\n",
    "    model_type = \"Electra\",\n",
    "    pretrained_model = \"monologg/koelectra-base-v3-discriminator\",\n",
    "    lr = 4e-6,\n",
    "    batch_size = 32,\n",
    "    valid_batch_size = 128,\n",
    "\n",
    "    val_ratio=0.2,\n",
    "    name = 'exp',\n",
    "    model_dir = os.environ.get('SM_MODEL_DIR', './results'),\n",
    "    custompretrain = \"\"\n",
    ")\n",
    "\n",
    "args.name = f'{args.model_type}V3_{args.lr}_9k{args.kfold}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*40)\n",
    "print(f\"k-fold num : {args.kfold}\")\n",
    "print('='*40)\n",
    "\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval args\n",
    "args = argparse.Namespace(\n",
    "    model_type = \"Electra\",\n",
    "    pretrained_model = \"monologg/koelectra-base-v3-discriminator\",\n",
    "    dropout_rate = 0,\n",
    "    model_dir = './results/ElectraV3_4e-06_9k9/95/best',\n",
    "    criterion = 'cross_entropy',\n",
    "    num_labels=2,\n",
    "\n",
    "    test_batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "    file = 'NIKL_CoLA_dev.tsv'\n",
    "    dataset = load_data(file)\n",
    "    tokenized_test = tokenize_datasets(dataset, tokenizer)\n",
    "    test_label = dataset['label'].values\n",
    "    test_dataset = ColaDataset(tokenized_test, test_label)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = Electra.from_pretrained(args.model_dir) \n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(test_loader)\n",
    "    print(\"Calculating validation results...\")\n",
    "    test_loss_items = []\n",
    "    test_acc_items = []\n",
    "    acc_okay = 0\n",
    "    count_all = 0\n",
    "    # results = []\n",
    "    # preds = []\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    eps = 1e-9\n",
    "\n",
    "    for idx, items in enumerate(pbar):\n",
    "        sleep(0.01)\n",
    "    #     item = {key: val.to(device) for key, val in items.items()}\n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = model(**item)\n",
    "    #     logits = outputs[0]\n",
    "    #     m = nn.Softmax(dim=1)\n",
    "    #     logits = m(logits)\n",
    "    #     logits = logits.detach().cpu().numpy()   # (Batch_size, 5)  5개의 클래스 확률형태\n",
    "    #     pred = logits[:,1]\n",
    "    #     result = np.argmax(logits, axis=-1)\n",
    "    #     results += result.tolist()\n",
    "    #     preds += pred.tolist()\n",
    "    \n",
    "    # pred_answer = np.array(results).flatten()\n",
    "    # preds = np.array(preds).flatten()\n",
    "\n",
    "        item = {key: val.to(device) for key, val in items.items()}\n",
    "        with torch.no_grad():\n",
    "            outs = model(**item)\n",
    "\n",
    "        preds = torch.argmax(outs[0], dim=-1)\n",
    "        criterion = create_criterion(args.criterion)\n",
    "        labels = item['labels']\n",
    "        loss = criterion(outs[0], labels).item()\n",
    "\n",
    "        acc_item = (labels == preds).sum().item()\n",
    "\n",
    "        TRUE = (labels == preds)\n",
    "        FALSE = (labels != preds)\n",
    "\n",
    "        TP += (TRUE * preds).sum().item()\n",
    "        TN += (TRUE * (preds==0)).sum().item()\n",
    "        FP += (FALSE * preds).sum().item()\n",
    "        FN += (FALSE * (preds==0)).sum().item()\n",
    "\n",
    "        MCC = ((TP*TN) - (FP*FN)) / (((TP+FP+eps)*(TP+FN+eps)*(TN+FP+eps)*(TN+FN+eps))**0.5)\n",
    "\n",
    "        test_loss_items.append(loss)\n",
    "        test_acc_items.append(acc_item)\n",
    "        acc_okay += acc_item\n",
    "        count_all += len(preds)\n",
    "\n",
    "        pbar.set_description(f\"({idx + 1}/{len(test_loader)}) || test_loss: {loss:4.4} || acc: {acc_okay/count_all:4.2%} || MCC: {MCC:4.2%}\")\n",
    "\n",
    "        test_loss = np.sum(test_loss_items) / len(test_loss_items)\n",
    "        test_acc = acc_okay / count_all\n",
    "\n",
    "        print(\n",
    "            f\"[Val] acc : {test_acc:4.2%}, loss: {test_loss:4.4}|| \"\n",
    "            f\"MCC : {MCC:4.2%}|| \"\n",
    "            f\"TP:{TP} / TN:{TN} / FP:{FP} / FN:{FN}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./results/ElectraV3_4e-06_9k9/95/best were not used when initializing Electra: ['pooling.dense.bias', 'pooling.dense.weight']\n",
      "- This IS expected if you are initializing Electra from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Electra from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Electra were not initialized from the model checkpoint at ./results/ElectraV3_4e-06_9k9/95/best and are newly initialized: ['linear.bias', 'linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating validation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/254 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2139563/3224367201.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2139563/914192882.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'criterion'"
     ]
    }
   ],
   "source": [
    "evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad783e95c017c6a0ffc7d9d3277599f38f5f101d4b63a62b683952e68d1e005f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
